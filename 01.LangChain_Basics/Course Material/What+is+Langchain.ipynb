{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d65ceb",
   "metadata": {},
   "source": [
    "# Installing Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89ba9f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (0.0.247)\n",
      "Requirement already satisfied: openai in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (0.5.13)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (0.0.15)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: tqdm in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/damienbenveniste/anaconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf3224f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3e1f9",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "197c797a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI'm doing well, thank you. How about you?\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "llm.predict('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df87ec06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have feelings, but I'm here to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "chat_model.predict('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a933941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I am an AI language model and I don't have access to your previous questions.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict('What was my previous question?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acd4b75",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21009f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How are you today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm an AI, so I don't have feelings or emotions like humans do. However, I'm functioning optimally and ready to assist you with any questions or tasks you may have. How can I help you today?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('How are you today?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "693ec706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you today?\n",
      "AI: I'm an AI, so I don't have feelings or emotions like humans do. However, I'm functioning optimally and ready to assist you with any questions or tasks you may have. How can I help you today?\n",
      "Human: What was my previous question?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your previous question was \"How are you today?\"'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run('What was my previous question?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b00466",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763a7bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['category'], output_parser=None, partial_variables={}, template='\\nReturn all the subcategories of the following category\\n\\n{category}\\n', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Return all the subcategories of the following category\n",
    "\n",
    "{category}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['category'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd070513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Return all the subcategories of the following category\n",
      "\n",
      "Machine Learning\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- Supervised Learning\\n- Unsupervised Learning\\n- Reinforcement Learning\\n- Deep Learning\\n- Natural Language Processing\\n- Computer Vision\\n- Neural Networks\\n- Decision Trees\\n- Support Vector Machines\\n- Clustering Algorithms\\n- Dimensionality Reduction\\n- Ensemble Methods\\n- Bayesian Networks\\n- Genetic Algorithms\\n- Reinforcement Learning\\n- Transfer Learning\\n- Self-supervised Learning\\n- Semi-supervised Learning\\n- Online Learning\\n- Instance-based Learning\\n- Inductive Learning\\n- Transductive Learning\\n- Active Learning\\n- Meta-learning\\n- Model-based Learning\\n- Probabilistic Learning\\n- Symbolic Learning\\n- Analogical Learning'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a07acc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='\\nYou are a helpful assistant who generate comma separated lists.\\nA user will only pass a category and you should generate subcategories of that category in a comma separated list.\\nONLY return comma separated and nothing more!\\n', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a helpful assistant who generate comma separated lists.\n",
    "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
    "ONLY return comma separated and nothing more!\n",
    "\"\"\"\n",
    "\n",
    "human_template = '{category}'\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    system_template\n",
    ")\n",
    "sytem_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a03819ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['category'], output_parser=None, partial_variables={}, template='{category}', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    human_template\n",
    ")\n",
    "\n",
    "human_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce86e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: Machine Learning\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Supervised Learning, Unsupervised Learning, Reinforcement Learning, Deep Learning, Natural Language Processing, Computer Vision, Decision Trees, Random Forests, Support Vector Machines, Neural Networks'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    sytem_message, human_message   \n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fe368",
   "metadata": {},
   "source": [
    "# Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b56d7eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Return all the subcategories of the following category\n",
      "\n",
      "Machine Learning\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['- Supervised Learning\\n- Unsupervised Learning\\n- Reinforcement Learning\\n- Deep Learning\\n- Natural Language Processing\\n- Computer Vision\\n- Recommender Systems\\n- Transfer Learning\\n- Generative Adversarial Networks (GANs)\\n- Support Vector Machines (SVM)\\n- Decision Trees\\n- Random Forests\\n- Neural Networks\\n- Bayesian Networks\\n- Clustering Algorithms\\n- Dimensionality Reduction\\n- Ensemble Methods\\n- Regression Analysis\\n- Pattern Recognition\\n- Data Mining\\n- Time Series Analysis\\n- Anomaly Detection\\n- Model Evaluation and Validation\\n- Model Selection\\n- Model Deployment\\n- Interpretability and Explainability in Machine Learning\\n- Bias and Fairness in Machine Learning\\n- Privacy and Security in Machine Learning']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaSeparatedParser(BaseOutputParser):\n",
    "    \n",
    "    def parse(self, text):\n",
    "        output = text.strip().split(',')\n",
    "        output = [o.strip() for o in output]\n",
    "        return output\n",
    "    \n",
    "chain = LLMChain(\n",
    "    llm=chat_model,\n",
    "    prompt=prompt,\n",
    "    output_parser=CommaSeparatedParser(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee909622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.272'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1aa0f8d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: food\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: country\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant who generate comma separated lists.\n",
      "A user will only pass a category and you should generate subcategories of that category in a comma separated list.\n",
      "ONLY return comma separated and nothing more!\n",
      "\n",
      "Human: colors\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': ['fruits',\n",
       "   'vegetables',\n",
       "   'meat',\n",
       "   'dairy',\n",
       "   'grains',\n",
       "   'seafood',\n",
       "   'snacks',\n",
       "   'beverages']},\n",
       " {'text': ['Afghanistan',\n",
       "   'Albania',\n",
       "   'Algeria',\n",
       "   'Andorra',\n",
       "   'Angola',\n",
       "   'Antigua and Barbuda',\n",
       "   'Argentina',\n",
       "   'Armenia',\n",
       "   'Australia',\n",
       "   'Austria',\n",
       "   'Azerbaijan',\n",
       "   'Bahamas',\n",
       "   'Bahrain',\n",
       "   'Bangladesh',\n",
       "   'Barbados',\n",
       "   'Belarus',\n",
       "   'Belgium',\n",
       "   'Belize',\n",
       "   'Benin',\n",
       "   'Bhutan',\n",
       "   'Bolivia',\n",
       "   'Bosnia and Herzegovina',\n",
       "   'Botswana',\n",
       "   'Brazil',\n",
       "   'Brunei',\n",
       "   'Bulgaria',\n",
       "   'Burkina Faso',\n",
       "   'Burundi',\n",
       "   'Cabo Verde',\n",
       "   'Cambodia',\n",
       "   'Cameroon',\n",
       "   'Canada',\n",
       "   'Central African Republic',\n",
       "   'Chad',\n",
       "   'Chile',\n",
       "   'China',\n",
       "   'Colombia',\n",
       "   'Comoros',\n",
       "   'Congo',\n",
       "   'Costa Rica',\n",
       "   'Croatia',\n",
       "   'Cuba',\n",
       "   'Cyprus',\n",
       "   'Czech Republic',\n",
       "   'Denmark',\n",
       "   'Djibouti',\n",
       "   'Dominica',\n",
       "   'Dominican Republic',\n",
       "   'East Timor',\n",
       "   'Ecuador',\n",
       "   'Egypt',\n",
       "   'El Salvador',\n",
       "   'Equatorial Guinea',\n",
       "   'Eritrea',\n",
       "   'Estonia',\n",
       "   'Eswatini',\n",
       "   'Ethiopia',\n",
       "   'Fiji',\n",
       "   'Finland',\n",
       "   'France',\n",
       "   'Gabon',\n",
       "   'Gambia',\n",
       "   'Georgia',\n",
       "   'Germany',\n",
       "   'Ghana',\n",
       "   'Greece',\n",
       "   'Grenada',\n",
       "   'Guatemala',\n",
       "   'Guinea',\n",
       "   'Guinea-Bissau',\n",
       "   'Guyana',\n",
       "   'Haiti',\n",
       "   'Honduras',\n",
       "   'Hungary',\n",
       "   'Iceland',\n",
       "   'India',\n",
       "   'Indonesia',\n",
       "   'Iran',\n",
       "   'Iraq',\n",
       "   'Ireland',\n",
       "   'Israel',\n",
       "   'Italy',\n",
       "   'Jamaica',\n",
       "   'Japan',\n",
       "   'Jordan',\n",
       "   'Kazakhstan',\n",
       "   'Kenya',\n",
       "   'Kiribati',\n",
       "   'Korea',\n",
       "   'Kosovo',\n",
       "   'Kuwait',\n",
       "   'Kyrgyzstan',\n",
       "   'Laos',\n",
       "   'Latvia',\n",
       "   'Lebanon',\n",
       "   'Lesotho',\n",
       "   'Liberia',\n",
       "   'Libya',\n",
       "   'Liechtenstein',\n",
       "   'Lithuania',\n",
       "   'Luxembourg',\n",
       "   'Madagascar',\n",
       "   'Malawi',\n",
       "   'Malaysia',\n",
       "   'Maldives',\n",
       "   'Mali',\n",
       "   'Malta',\n",
       "   'Marshall Islands',\n",
       "   'Mauritania',\n",
       "   'Mauritius',\n",
       "   'Mexico',\n",
       "   'Micronesia',\n",
       "   'Moldova',\n",
       "   'Monaco',\n",
       "   'Mongolia',\n",
       "   'Montenegro',\n",
       "   'Morocco',\n",
       "   'Mozambique',\n",
       "   'Myanmar',\n",
       "   'Namibia',\n",
       "   'Nauru',\n",
       "   'Nepal',\n",
       "   'Netherlands',\n",
       "   'New Zealand',\n",
       "   'Nicaragua',\n",
       "   'Niger',\n",
       "   'Nigeria',\n",
       "   'North Macedonia',\n",
       "   'Norway',\n",
       "   'Oman',\n",
       "   'Pakistan',\n",
       "   'Palau',\n",
       "   'Panama',\n",
       "   'Papua New Guinea',\n",
       "   'Paraguay',\n",
       "   'Peru',\n",
       "   'Philippines',\n",
       "   'Poland',\n",
       "   'Portugal',\n",
       "   'Qatar',\n",
       "   'Romania',\n",
       "   'Russia',\n",
       "   'Rwanda',\n",
       "   'Saint Kitts and Nevis',\n",
       "   'Saint Lucia',\n",
       "   'Saint Vincent and the Grenadines',\n",
       "   'Samoa',\n",
       "   'San Marino',\n",
       "   'Sao Tome and Principe',\n",
       "   'Saudi Arabia',\n",
       "   'Senegal',\n",
       "   'Serbia',\n",
       "   'Seychelles',\n",
       "   'Sierra Leone',\n",
       "   'Singapore',\n",
       "   'Slovakia',\n",
       "   'Slovenia',\n",
       "   'Solomon Islands',\n",
       "   'Somalia',\n",
       "   'South Africa',\n",
       "   'South Sudan',\n",
       "   'Spain',\n",
       "   'Sri Lanka',\n",
       "   'Sudan',\n",
       "   'Suriname',\n",
       "   'Sweden',\n",
       "   'Switzerland',\n",
       "   'Syria',\n",
       "   'Taiwan',\n",
       "   'Tajikistan',\n",
       "   'Tanzania',\n",
       "   'Thailand',\n",
       "   'Togo',\n",
       "   'Tonga',\n",
       "   'Trinidad and Tobago',\n",
       "   'Tunisia',\n",
       "   'Turkey',\n",
       "   'Turkmenistan',\n",
       "   'Tuvalu',\n",
       "   'Uganda',\n",
       "   'Ukraine',\n",
       "   'United Arab Emirates',\n",
       "   'United Kingdom',\n",
       "   'United States',\n",
       "   'Uruguay',\n",
       "   'Uzbekistan',\n",
       "   'Vanuatu',\n",
       "   'Vatican City',\n",
       "   'Venezuela',\n",
       "   'Vietnam',\n",
       "   'Yemen',\n",
       "   'Zambia',\n",
       "   'Zimbabwe']},\n",
       " {'text': ['red',\n",
       "   'blue',\n",
       "   'green',\n",
       "   'yellow',\n",
       "   'orange',\n",
       "   'purple',\n",
       "   'pink',\n",
       "   'brown',\n",
       "   'black',\n",
       "   'white',\n",
       "   'gray']}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\n",
    "    {'category': 'food'},\n",
    "    {'category': 'country'},\n",
    "    {'category': 'colors'}\n",
    "]\n",
    "\n",
    "response = chain.apply(input_list)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "708f4719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'brown',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[2]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efaa3e",
   "metadata": {},
   "source": [
    "# Simple Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea8f7e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"The Algorithmic Adventure: A Machine Learning Marvel\"'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_template = \"\"\"\n",
    "You are a writer. Given a subject, \n",
    "your job is to return a fun title for a play.\n",
    "\n",
    "Subject: {subject}\n",
    "Title:\"\"\"\n",
    "\n",
    "title_chain = LLMChain.from_string(\n",
    "    llm=chat_model,\n",
    "    template=title_template\n",
    ")\n",
    "\n",
    "title_chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33fa990e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a not-so-distant future where artificial intelligence has become an integral part of everyday life, \"The Algorithmic Adventure: A Machine Learning Marvel\" takes us on a captivating journey through the world of advanced technology and its impact on society. The play revolves around a brilliant but socially awkward computer scientist named Alex, who has dedicated his life to developing a groundbreaking machine learning algorithm.\\n\\nAs the story unfolds, we witness Alex\\'s struggles to find recognition for his invention, which has the potential to revolutionize various industries. Despite facing skepticism and resistance from his colleagues, Alex remains determined to prove the worth of his creation. With the help of his loyal friend and fellow researcher, Sarah, he embarks on an extraordinary adventure to showcase the capabilities of his algorithm.\\n\\nAs their journey unfolds, Alex and Sarah encounter a wide array of characters representing different aspects of society\\'s relationship with technology. From corporate executives seeking to exploit the algorithm for profit to activists warning of its potential dangers, each encounter challenges our protagonists\\' beliefs and forces them to confront the ethical implications of their creation.\\n\\nThrough a series of thought-provoking and emotionally charged encounters, \"The Algorithmic Adventure: A Machine Learning Marvel\" delves into the complexities of artificial intelligence, exploring themes of human connection, morality, and the balance between progress and responsibility. As the play reaches its climax, Alex and Sarah must confront their own biases and make difficult choices that will shape the future of technology and society.\\n\\n\"The Algorithmic Adventure: A Machine Learning Marvel\" is a compelling and timely exploration of the ethical dilemmas posed by the rapid advancement of artificial intelligence. With its blend of intellectual discourse, emotional depth, and a touch of humor, this thought-provoking play challenges audiences to reconsider their own relationship with technology and encourages them to engage in a broader conversation about the role of AI in our lives.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synopsis_template = \"\"\"\n",
    "You are a writer. \n",
    "Given a title, write a synopsis for a play.\n",
    "\n",
    "Title: {title}\n",
    "Synopsis:\"\"\"\n",
    "\n",
    "synopsis_chain = LLMChain.from_string(\n",
    "    llm=chat_model,\n",
    "    template=synopsis_template\n",
    ")\n",
    "\n",
    "title = \"The Algorithmic Adventure: A Machine Learning Marvel\"\n",
    "\n",
    "synopsis_chain.run(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9633b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[title_chain, synopsis_chain],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.run('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbc90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Anaconda Environment",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

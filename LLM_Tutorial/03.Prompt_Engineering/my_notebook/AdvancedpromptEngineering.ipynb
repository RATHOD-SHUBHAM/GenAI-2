{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmbX5HONwIES",
        "outputId": "e1e087e6-7cdd-4db5-b177-00ba1e71cb66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.0/237.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "MVaQ8ZmYwvRA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate the model"
      ],
      "metadata": {
        "id": "nuZAN0yNjd7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, openai_api_key = OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "WXkisi1JyZLx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read and load data - json"
      ],
      "metadata": {
        "id": "txZ-zBity6iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/cot.json'\n",
        "\n",
        "cot_df = pd.read_json(file_path)\n",
        "\n",
        "cot_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "cobpmgMUyews",
        "outputId": "cfd5f785-a7a1-44a8-d809-e37b5fcf04f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     407496   \\\n",
              "source     Article: Phytochemistry is a branch of plant b...   \n",
              "target                                           from plants   \n",
              "rationale  The article states that many medicinal and rec...   \n",
              "config                                                  none   \n",
              "task                                                squad_v1   \n",
              "prompt                                                     6   \n",
              "\n",
              "                                                     897822   \\\n",
              "source     In this task, you are provided with an article...   \n",
              "target                                            Regulation   \n",
              "rationale  This act has all the features of Regulation. T...   \n",
              "config                                              task_744   \n",
              "task                                                  eurlex   \n",
              "prompt                                                  none   \n",
              "\n",
              "                                                     1639180  \\\n",
              "source     What's the answer to that question: where did ...   \n",
              "target                      Battle of Appomattox Court House   \n",
              "rationale  The Battle of Appomattox Court House was a bat...   \n",
              "config                                                  none   \n",
              "task                                           web_questions   \n",
              "prompt                                      whats_the_answer   \n",
              "\n",
              "                                                     1268206  \\\n",
              "source     Extract the answer to the question from the fo...   \n",
              "target                                   major heart attacks   \n",
              "rationale  The answer is the number of major heart attack...   \n",
              "config                                                 dbert   \n",
              "task                                    adversarial_qa@dbert   \n",
              "prompt                                              based_on   \n",
              "\n",
              "                                                     112965   \\\n",
              "source     Which entity is this text about?\\n\\nRichard \"R...   \n",
              "target                                           Red Skelton   \n",
              "rationale  The text is about Red Skelton. The context des...   \n",
              "config                                                  none   \n",
              "task                                                    quac   \n",
              "prompt                                                     8   \n",
              "\n",
              "                                                     176714   \\\n",
              "source     The town lies along the stretch of coastline d...   \n",
              "target                                                    no   \n",
              "rationale  The paragraph doesn't mention the date of the ...   \n",
              "config                                                  none   \n",
              "task                                                     rte   \n",
              "prompt                                                     1   \n",
              "\n",
              "                                                     1365585  \\\n",
              "source     Two sisters went to the hospital. The medics r...   \n",
              "target                                                   Sue   \n",
              "rationale  Sickle cell trait is a hereditary disorder in ...   \n",
              "config                                                  none   \n",
              "task                                                   ropes   \n",
              "prompt                                   plain_no_background   \n",
              "\n",
              "                                                     1266292  \\\n",
              "source     Question: \"What else does the pigment make red...   \n",
              "target                                                  lips   \n",
              "rationale  The context mentions that the pigment pheomela...   \n",
              "config                                                 dbert   \n",
              "task                                    adversarial_qa@dbert   \n",
              "prompt                               question_context_answer   \n",
              "\n",
              "                                                     306879   \\\n",
              "source     \"Mama came over and sat down beside Alice. Gen...   \n",
              "target                                                    no   \n",
              "rationale  The premise states that Mama came over and sat...   \n",
              "config                                                  none   \n",
              "task                                                    wnli   \n",
              "prompt                                                     4   \n",
              "\n",
              "                                                     765453   ...  \\\n",
              "source     Given a travel related situation, and given a ...  ...   \n",
              "target     Where to watch German world cup soccer games i...  ...   \n",
              "rationale  The question asks for a location to watch Germ...  ...   \n",
              "config                                             task_1639  ...   \n",
              "task                                                    diqa  ...   \n",
              "prompt                                                  none  ...   \n",
              "\n",
              "                                                     561982   \\\n",
              "source     In this task, you're given five sentences, num...   \n",
              "target                                             Ugly Bike   \n",
              "rationale  The story is about how Neil got a bike and did...   \n",
              "config                                              task_219   \n",
              "task                                             roc_stories   \n",
              "prompt                                                  none   \n",
              "\n",
              "                                                     1281906  \\\n",
              "source     Extract the answer to the question from the fo...   \n",
              "target                                                  food   \n",
              "rationale  The question mentions a rat, cat and food.\\nIn...   \n",
              "config                                              droberta   \n",
              "task                                 adversarial_qa@droberta   \n",
              "prompt                                              based_on   \n",
              "\n",
              "                                                     83979    \\\n",
              "source     Answer the question...who composed the music t...   \n",
              "target                                         Jessica Curry   \n",
              "rationale  The answer is based on the fact that Jessica C...   \n",
              "config                                                  none   \n",
              "task                                       natural_questions   \n",
              "prompt                                                     5   \n",
              "\n",
              "                                                     763058   \\\n",
              "source     Given a paragraph about cooking, and a set of ...   \n",
              "target          I suggest using frozen, or even fresh fruits   \n",
              "rationale  The follow-up question is asking whether other...   \n",
              "config                                             task_1438   \n",
              "task                                                    diqa   \n",
              "prompt                                                  none   \n",
              "\n",
              "                                                     1059518  \\\n",
              "source     In this task, you need to reverse the order of...   \n",
              "target            town a in road a down going bikers of line   \n",
              "rationale  The required output is 'town a in road a down ...   \n",
              "config                                              task_376   \n",
              "task                                               synthetic   \n",
              "prompt                                                  none   \n",
              "\n",
              "                                                     1255117  \\\n",
              "source     Extract the answer to the question from the fo...   \n",
              "target     energy was stored as a charge in the carbon po...   \n",
              "rationale  The inventor of the low voltage electrolytic c...   \n",
              "config                                                dbidaf   \n",
              "task                                   adversarial_qa@dbidaf   \n",
              "prompt                                              based_on   \n",
              "\n",
              "                                                     970849   \\\n",
              "source     You are given a passage. Using the information...   \n",
              "target                                                     7   \n",
              "rationale  The lines are a part of the lyrics of the well...   \n",
              "config                                             task_1593   \n",
              "task                                    yahoo_answers_topics   \n",
              "prompt                                                  none   \n",
              "\n",
              "                                                     1239599  \\\n",
              "source     Determine the topic of the question.\\nQuestion...   \n",
              "target                                            Trojan War   \n",
              "rationale  The topic of this question is the Trojan War.\\...   \n",
              "config                                                  none   \n",
              "task                                                 wiki_qa   \n",
              "prompt                      Topic Prediction - Question Only   \n",
              "\n",
              "                                                     719627   \\\n",
              "source     You are given a sentence from a conversation b...   \n",
              "target                                                 OFFER   \n",
              "rationale  The given sentence is offering information abo...   \n",
              "config                                              task_880   \n",
              "task                                     schema_guided_dstc8   \n",
              "prompt                                                  none   \n",
              "\n",
              "                                                     782179   \n",
              "source     In this task, you're given a question, along w...  \n",
              "target     She studied art at the University of Californi...  \n",
              "rationale  The given question asks for the acceptance rat...  \n",
              "config                                              task_234  \n",
              "task                                                    iirc  \n",
              "prompt                                                  none  \n",
              "\n",
              "[6 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6dd04af5-ae51-413d-9414-077de6ca4e9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>407496</th>\n",
              "      <th>897822</th>\n",
              "      <th>1639180</th>\n",
              "      <th>1268206</th>\n",
              "      <th>112965</th>\n",
              "      <th>176714</th>\n",
              "      <th>1365585</th>\n",
              "      <th>1266292</th>\n",
              "      <th>306879</th>\n",
              "      <th>765453</th>\n",
              "      <th>...</th>\n",
              "      <th>561982</th>\n",
              "      <th>1281906</th>\n",
              "      <th>83979</th>\n",
              "      <th>763058</th>\n",
              "      <th>1059518</th>\n",
              "      <th>1255117</th>\n",
              "      <th>970849</th>\n",
              "      <th>1239599</th>\n",
              "      <th>719627</th>\n",
              "      <th>782179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <td>Article: Phytochemistry is a branch of plant b...</td>\n",
              "      <td>In this task, you are provided with an article...</td>\n",
              "      <td>What's the answer to that question: where did ...</td>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>Which entity is this text about?\\n\\nRichard \"R...</td>\n",
              "      <td>The town lies along the stretch of coastline d...</td>\n",
              "      <td>Two sisters went to the hospital. The medics r...</td>\n",
              "      <td>Question: \"What else does the pigment make red...</td>\n",
              "      <td>\"Mama came over and sat down beside Alice. Gen...</td>\n",
              "      <td>Given a travel related situation, and given a ...</td>\n",
              "      <td>...</td>\n",
              "      <td>In this task, you're given five sentences, num...</td>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>Answer the question...who composed the music t...</td>\n",
              "      <td>Given a paragraph about cooking, and a set of ...</td>\n",
              "      <td>In this task, you need to reverse the order of...</td>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>You are given a passage. Using the information...</td>\n",
              "      <td>Determine the topic of the question.\\nQuestion...</td>\n",
              "      <td>You are given a sentence from a conversation b...</td>\n",
              "      <td>In this task, you're given a question, along w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>from plants</td>\n",
              "      <td>Regulation</td>\n",
              "      <td>Battle of Appomattox Court House</td>\n",
              "      <td>major heart attacks</td>\n",
              "      <td>Red Skelton</td>\n",
              "      <td>no</td>\n",
              "      <td>Sue</td>\n",
              "      <td>lips</td>\n",
              "      <td>no</td>\n",
              "      <td>Where to watch German world cup soccer games i...</td>\n",
              "      <td>...</td>\n",
              "      <td>Ugly Bike</td>\n",
              "      <td>food</td>\n",
              "      <td>Jessica Curry</td>\n",
              "      <td>I suggest using frozen, or even fresh fruits</td>\n",
              "      <td>town a in road a down going bikers of line</td>\n",
              "      <td>energy was stored as a charge in the carbon po...</td>\n",
              "      <td>7</td>\n",
              "      <td>Trojan War</td>\n",
              "      <td>OFFER</td>\n",
              "      <td>She studied art at the University of Californi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rationale</th>\n",
              "      <td>The article states that many medicinal and rec...</td>\n",
              "      <td>This act has all the features of Regulation. T...</td>\n",
              "      <td>The Battle of Appomattox Court House was a bat...</td>\n",
              "      <td>The answer is the number of major heart attack...</td>\n",
              "      <td>The text is about Red Skelton. The context des...</td>\n",
              "      <td>The paragraph doesn't mention the date of the ...</td>\n",
              "      <td>Sickle cell trait is a hereditary disorder in ...</td>\n",
              "      <td>The context mentions that the pigment pheomela...</td>\n",
              "      <td>The premise states that Mama came over and sat...</td>\n",
              "      <td>The question asks for a location to watch Germ...</td>\n",
              "      <td>...</td>\n",
              "      <td>The story is about how Neil got a bike and did...</td>\n",
              "      <td>The question mentions a rat, cat and food.\\nIn...</td>\n",
              "      <td>The answer is based on the fact that Jessica C...</td>\n",
              "      <td>The follow-up question is asking whether other...</td>\n",
              "      <td>The required output is 'town a in road a down ...</td>\n",
              "      <td>The inventor of the low voltage electrolytic c...</td>\n",
              "      <td>The lines are a part of the lyrics of the well...</td>\n",
              "      <td>The topic of this question is the Trojan War.\\...</td>\n",
              "      <td>The given sentence is offering information abo...</td>\n",
              "      <td>The given question asks for the acceptance rat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>config</th>\n",
              "      <td>none</td>\n",
              "      <td>task_744</td>\n",
              "      <td>none</td>\n",
              "      <td>dbert</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>dbert</td>\n",
              "      <td>none</td>\n",
              "      <td>task_1639</td>\n",
              "      <td>...</td>\n",
              "      <td>task_219</td>\n",
              "      <td>droberta</td>\n",
              "      <td>none</td>\n",
              "      <td>task_1438</td>\n",
              "      <td>task_376</td>\n",
              "      <td>dbidaf</td>\n",
              "      <td>task_1593</td>\n",
              "      <td>none</td>\n",
              "      <td>task_880</td>\n",
              "      <td>task_234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>task</th>\n",
              "      <td>squad_v1</td>\n",
              "      <td>eurlex</td>\n",
              "      <td>web_questions</td>\n",
              "      <td>adversarial_qa@dbert</td>\n",
              "      <td>quac</td>\n",
              "      <td>rte</td>\n",
              "      <td>ropes</td>\n",
              "      <td>adversarial_qa@dbert</td>\n",
              "      <td>wnli</td>\n",
              "      <td>diqa</td>\n",
              "      <td>...</td>\n",
              "      <td>roc_stories</td>\n",
              "      <td>adversarial_qa@droberta</td>\n",
              "      <td>natural_questions</td>\n",
              "      <td>diqa</td>\n",
              "      <td>synthetic</td>\n",
              "      <td>adversarial_qa@dbidaf</td>\n",
              "      <td>yahoo_answers_topics</td>\n",
              "      <td>wiki_qa</td>\n",
              "      <td>schema_guided_dstc8</td>\n",
              "      <td>iirc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt</th>\n",
              "      <td>6</td>\n",
              "      <td>none</td>\n",
              "      <td>whats_the_answer</td>\n",
              "      <td>based_on</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>plain_no_background</td>\n",
              "      <td>question_context_answer</td>\n",
              "      <td>4</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>none</td>\n",
              "      <td>based_on</td>\n",
              "      <td>5</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>based_on</td>\n",
              "      <td>none</td>\n",
              "      <td>Topic Prediction - Question Only</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6dd04af5-ae51-413d-9414-077de6ca4e9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6dd04af5-ae51-413d-9414-077de6ca4e9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6dd04af5-ae51-413d-9414-077de6ca4e9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-81e4315a-9766-4c54-a81c-dffde08e0162\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81e4315a-9766-4c54-a81c-dffde08e0162')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-81e4315a-9766-4c54-a81c-dffde08e0162 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f90fdca7-d767-458f-bfda-e52898e7cb01\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f90fdca7-d767-458f-bfda-e52898e7cb01 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform the data"
      ],
      "metadata": {
        "id": "axq4kCSVkit4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_df = cot_df.T\n",
        "\n",
        "cot_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "7z5-QE4-y-0o",
        "outputId": "b7ae5185-2ee0-4c05-d38a-b1508fd3b67c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    source  \\\n",
              "407496   Article: Phytochemistry is a branch of plant b...   \n",
              "897822   In this task, you are provided with an article...   \n",
              "1639180  What's the answer to that question: where did ...   \n",
              "1268206  Extract the answer to the question from the fo...   \n",
              "112965   Which entity is this text about?\\n\\nRichard \"R...   \n",
              "...                                                    ...   \n",
              "1255117  Extract the answer to the question from the fo...   \n",
              "970849   You are given a passage. Using the information...   \n",
              "1239599  Determine the topic of the question.\\nQuestion...   \n",
              "719627   You are given a sentence from a conversation b...   \n",
              "782179   In this task, you're given a question, along w...   \n",
              "\n",
              "                                                    target  \\\n",
              "407496                                         from plants   \n",
              "897822                                          Regulation   \n",
              "1639180                   Battle of Appomattox Court House   \n",
              "1268206                                major heart attacks   \n",
              "112965                                         Red Skelton   \n",
              "...                                                    ...   \n",
              "1255117  energy was stored as a charge in the carbon po...   \n",
              "970849                                                   7   \n",
              "1239599                                         Trojan War   \n",
              "719627                                               OFFER   \n",
              "782179   She studied art at the University of Californi...   \n",
              "\n",
              "                                                 rationale     config  \\\n",
              "407496   The article states that many medicinal and rec...       none   \n",
              "897822   This act has all the features of Regulation. T...   task_744   \n",
              "1639180  The Battle of Appomattox Court House was a bat...       none   \n",
              "1268206  The answer is the number of major heart attack...      dbert   \n",
              "112965   The text is about Red Skelton. The context des...       none   \n",
              "...                                                    ...        ...   \n",
              "1255117  The inventor of the low voltage electrolytic c...     dbidaf   \n",
              "970849   The lines are a part of the lyrics of the well...  task_1593   \n",
              "1239599  The topic of this question is the Trojan War.\\...       none   \n",
              "719627   The given sentence is offering information abo...   task_880   \n",
              "782179   The given question asks for the acceptance rat...   task_234   \n",
              "\n",
              "                          task                            prompt  \n",
              "407496                squad_v1                                 6  \n",
              "897822                  eurlex                              none  \n",
              "1639180          web_questions                  whats_the_answer  \n",
              "1268206   adversarial_qa@dbert                          based_on  \n",
              "112965                    quac                                 8  \n",
              "...                        ...                               ...  \n",
              "1255117  adversarial_qa@dbidaf                          based_on  \n",
              "970849    yahoo_answers_topics                              none  \n",
              "1239599                wiki_qa  Topic Prediction - Question Only  \n",
              "719627     schema_guided_dstc8                              none  \n",
              "782179                    iirc                              none  \n",
              "\n",
              "[76 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d19ec1db-b8b1-4432-954b-355190a1bfd7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>rationale</th>\n",
              "      <th>config</th>\n",
              "      <th>task</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>407496</th>\n",
              "      <td>Article: Phytochemistry is a branch of plant b...</td>\n",
              "      <td>from plants</td>\n",
              "      <td>The article states that many medicinal and rec...</td>\n",
              "      <td>none</td>\n",
              "      <td>squad_v1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897822</th>\n",
              "      <td>In this task, you are provided with an article...</td>\n",
              "      <td>Regulation</td>\n",
              "      <td>This act has all the features of Regulation. T...</td>\n",
              "      <td>task_744</td>\n",
              "      <td>eurlex</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1639180</th>\n",
              "      <td>What's the answer to that question: where did ...</td>\n",
              "      <td>Battle of Appomattox Court House</td>\n",
              "      <td>The Battle of Appomattox Court House was a bat...</td>\n",
              "      <td>none</td>\n",
              "      <td>web_questions</td>\n",
              "      <td>whats_the_answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268206</th>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>major heart attacks</td>\n",
              "      <td>The answer is the number of major heart attack...</td>\n",
              "      <td>dbert</td>\n",
              "      <td>adversarial_qa@dbert</td>\n",
              "      <td>based_on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112965</th>\n",
              "      <td>Which entity is this text about?\\n\\nRichard \"R...</td>\n",
              "      <td>Red Skelton</td>\n",
              "      <td>The text is about Red Skelton. The context des...</td>\n",
              "      <td>none</td>\n",
              "      <td>quac</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255117</th>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>energy was stored as a charge in the carbon po...</td>\n",
              "      <td>The inventor of the low voltage electrolytic c...</td>\n",
              "      <td>dbidaf</td>\n",
              "      <td>adversarial_qa@dbidaf</td>\n",
              "      <td>based_on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970849</th>\n",
              "      <td>You are given a passage. Using the information...</td>\n",
              "      <td>7</td>\n",
              "      <td>The lines are a part of the lyrics of the well...</td>\n",
              "      <td>task_1593</td>\n",
              "      <td>yahoo_answers_topics</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239599</th>\n",
              "      <td>Determine the topic of the question.\\nQuestion...</td>\n",
              "      <td>Trojan War</td>\n",
              "      <td>The topic of this question is the Trojan War.\\...</td>\n",
              "      <td>none</td>\n",
              "      <td>wiki_qa</td>\n",
              "      <td>Topic Prediction - Question Only</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719627</th>\n",
              "      <td>You are given a sentence from a conversation b...</td>\n",
              "      <td>OFFER</td>\n",
              "      <td>The given sentence is offering information abo...</td>\n",
              "      <td>task_880</td>\n",
              "      <td>schema_guided_dstc8</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782179</th>\n",
              "      <td>In this task, you're given a question, along w...</td>\n",
              "      <td>She studied art at the University of Californi...</td>\n",
              "      <td>The given question asks for the acceptance rat...</td>\n",
              "      <td>task_234</td>\n",
              "      <td>iirc</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d19ec1db-b8b1-4432-954b-355190a1bfd7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d19ec1db-b8b1-4432-954b-355190a1bfd7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d19ec1db-b8b1-4432-954b-355190a1bfd7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-af99988b-c0ba-40b7-b337-66230229a6c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af99988b-c0ba-40b7-b337-66230229a6c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-af99988b-c0ba-40b7-b337-66230229a6c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_74b4dd21-d2c9-49b6-b99e-ccacbabe8eb3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_74b4dd21-d2c9-49b6-b99e-ccacbabe8eb3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reset the index"
      ],
      "metadata": {
        "id": "LM3zM2F8koRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "cot_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "pUXeA8HszCcI",
        "outputId": "ab663c88-ba4a-4b19-9651-3176b934ef83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               source  \\\n",
              "0   Article: Phytochemistry is a branch of plant b...   \n",
              "1   In this task, you are provided with an article...   \n",
              "2   What's the answer to that question: where did ...   \n",
              "3   Extract the answer to the question from the fo...   \n",
              "4   Which entity is this text about?\\n\\nRichard \"R...   \n",
              "..                                                ...   \n",
              "71  Extract the answer to the question from the fo...   \n",
              "72  You are given a passage. Using the information...   \n",
              "73  Determine the topic of the question.\\nQuestion...   \n",
              "74  You are given a sentence from a conversation b...   \n",
              "75  In this task, you're given a question, along w...   \n",
              "\n",
              "                                               target  \\\n",
              "0                                         from plants   \n",
              "1                                          Regulation   \n",
              "2                    Battle of Appomattox Court House   \n",
              "3                                 major heart attacks   \n",
              "4                                         Red Skelton   \n",
              "..                                                ...   \n",
              "71  energy was stored as a charge in the carbon po...   \n",
              "72                                                  7   \n",
              "73                                         Trojan War   \n",
              "74                                              OFFER   \n",
              "75  She studied art at the University of Californi...   \n",
              "\n",
              "                                            rationale     config  \\\n",
              "0   The article states that many medicinal and rec...       none   \n",
              "1   This act has all the features of Regulation. T...   task_744   \n",
              "2   The Battle of Appomattox Court House was a bat...       none   \n",
              "3   The answer is the number of major heart attack...      dbert   \n",
              "4   The text is about Red Skelton. The context des...       none   \n",
              "..                                                ...        ...   \n",
              "71  The inventor of the low voltage electrolytic c...     dbidaf   \n",
              "72  The lines are a part of the lyrics of the well...  task_1593   \n",
              "73  The topic of this question is the Trojan War.\\...       none   \n",
              "74  The given sentence is offering information abo...   task_880   \n",
              "75  The given question asks for the acceptance rat...   task_234   \n",
              "\n",
              "                     task                            prompt  \n",
              "0                squad_v1                                 6  \n",
              "1                  eurlex                              none  \n",
              "2           web_questions                  whats_the_answer  \n",
              "3    adversarial_qa@dbert                          based_on  \n",
              "4                    quac                                 8  \n",
              "..                    ...                               ...  \n",
              "71  adversarial_qa@dbidaf                          based_on  \n",
              "72   yahoo_answers_topics                              none  \n",
              "73                wiki_qa  Topic Prediction - Question Only  \n",
              "74    schema_guided_dstc8                              none  \n",
              "75                   iirc                              none  \n",
              "\n",
              "[76 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b49ccbfd-a1e9-4f27-be83-64581686d25f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>rationale</th>\n",
              "      <th>config</th>\n",
              "      <th>task</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Article: Phytochemistry is a branch of plant b...</td>\n",
              "      <td>from plants</td>\n",
              "      <td>The article states that many medicinal and rec...</td>\n",
              "      <td>none</td>\n",
              "      <td>squad_v1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In this task, you are provided with an article...</td>\n",
              "      <td>Regulation</td>\n",
              "      <td>This act has all the features of Regulation. T...</td>\n",
              "      <td>task_744</td>\n",
              "      <td>eurlex</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What's the answer to that question: where did ...</td>\n",
              "      <td>Battle of Appomattox Court House</td>\n",
              "      <td>The Battle of Appomattox Court House was a bat...</td>\n",
              "      <td>none</td>\n",
              "      <td>web_questions</td>\n",
              "      <td>whats_the_answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>major heart attacks</td>\n",
              "      <td>The answer is the number of major heart attack...</td>\n",
              "      <td>dbert</td>\n",
              "      <td>adversarial_qa@dbert</td>\n",
              "      <td>based_on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which entity is this text about?\\n\\nRichard \"R...</td>\n",
              "      <td>Red Skelton</td>\n",
              "      <td>The text is about Red Skelton. The context des...</td>\n",
              "      <td>none</td>\n",
              "      <td>quac</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>energy was stored as a charge in the carbon po...</td>\n",
              "      <td>The inventor of the low voltage electrolytic c...</td>\n",
              "      <td>dbidaf</td>\n",
              "      <td>adversarial_qa@dbidaf</td>\n",
              "      <td>based_on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>You are given a passage. Using the information...</td>\n",
              "      <td>7</td>\n",
              "      <td>The lines are a part of the lyrics of the well...</td>\n",
              "      <td>task_1593</td>\n",
              "      <td>yahoo_answers_topics</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Determine the topic of the question.\\nQuestion...</td>\n",
              "      <td>Trojan War</td>\n",
              "      <td>The topic of this question is the Trojan War.\\...</td>\n",
              "      <td>none</td>\n",
              "      <td>wiki_qa</td>\n",
              "      <td>Topic Prediction - Question Only</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>You are given a sentence from a conversation b...</td>\n",
              "      <td>OFFER</td>\n",
              "      <td>The given sentence is offering information abo...</td>\n",
              "      <td>task_880</td>\n",
              "      <td>schema_guided_dstc8</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>In this task, you're given a question, along w...</td>\n",
              "      <td>She studied art at the University of Californi...</td>\n",
              "      <td>The given question asks for the acceptance rat...</td>\n",
              "      <td>task_234</td>\n",
              "      <td>iirc</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b49ccbfd-a1e9-4f27-be83-64581686d25f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b49ccbfd-a1e9-4f27-be83-64581686d25f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b49ccbfd-a1e9-4f27-be83-64581686d25f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0592cf01-d045-4ae4-ae43-edc460367361\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0592cf01-d045-4ae4-ae43-edc460367361')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0592cf01-d045-4ae4-ae43-edc460367361 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b982a39d-1c0c-4ff8-aa83-22805e76d73e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b982a39d-1c0c-4ff8-aa83-22805e76d73e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract just the Source, Target and Rationale."
      ],
      "metadata": {
        "id": "wiYGZa8Qkski"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_df = cot_df[['source', 'target', 'rationale']]\n",
        "\n",
        "cot_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "WnF1Eh0xzEX8",
        "outputId": "cb9decd0-0c60-47e0-8a44-48914f026b61"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               source  \\\n",
              "0   Article: Phytochemistry is a branch of plant b...   \n",
              "1   In this task, you are provided with an article...   \n",
              "2   What's the answer to that question: where did ...   \n",
              "3   Extract the answer to the question from the fo...   \n",
              "4   Which entity is this text about?\\n\\nRichard \"R...   \n",
              "..                                                ...   \n",
              "71  Extract the answer to the question from the fo...   \n",
              "72  You are given a passage. Using the information...   \n",
              "73  Determine the topic of the question.\\nQuestion...   \n",
              "74  You are given a sentence from a conversation b...   \n",
              "75  In this task, you're given a question, along w...   \n",
              "\n",
              "                                               target  \\\n",
              "0                                         from plants   \n",
              "1                                          Regulation   \n",
              "2                    Battle of Appomattox Court House   \n",
              "3                                 major heart attacks   \n",
              "4                                         Red Skelton   \n",
              "..                                                ...   \n",
              "71  energy was stored as a charge in the carbon po...   \n",
              "72                                                  7   \n",
              "73                                         Trojan War   \n",
              "74                                              OFFER   \n",
              "75  She studied art at the University of Californi...   \n",
              "\n",
              "                                            rationale  \n",
              "0   The article states that many medicinal and rec...  \n",
              "1   This act has all the features of Regulation. T...  \n",
              "2   The Battle of Appomattox Court House was a bat...  \n",
              "3   The answer is the number of major heart attack...  \n",
              "4   The text is about Red Skelton. The context des...  \n",
              "..                                                ...  \n",
              "71  The inventor of the low voltage electrolytic c...  \n",
              "72  The lines are a part of the lyrics of the well...  \n",
              "73  The topic of this question is the Trojan War.\\...  \n",
              "74  The given sentence is offering information abo...  \n",
              "75  The given question asks for the acceptance rat...  \n",
              "\n",
              "[76 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1467e052-cce4-49df-8aa0-4e6ee5df41dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>rationale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Article: Phytochemistry is a branch of plant b...</td>\n",
              "      <td>from plants</td>\n",
              "      <td>The article states that many medicinal and rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In this task, you are provided with an article...</td>\n",
              "      <td>Regulation</td>\n",
              "      <td>This act has all the features of Regulation. T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What's the answer to that question: where did ...</td>\n",
              "      <td>Battle of Appomattox Court House</td>\n",
              "      <td>The Battle of Appomattox Court House was a bat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>major heart attacks</td>\n",
              "      <td>The answer is the number of major heart attack...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which entity is this text about?\\n\\nRichard \"R...</td>\n",
              "      <td>Red Skelton</td>\n",
              "      <td>The text is about Red Skelton. The context des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>energy was stored as a charge in the carbon po...</td>\n",
              "      <td>The inventor of the low voltage electrolytic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>You are given a passage. Using the information...</td>\n",
              "      <td>7</td>\n",
              "      <td>The lines are a part of the lyrics of the well...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Determine the topic of the question.\\nQuestion...</td>\n",
              "      <td>Trojan War</td>\n",
              "      <td>The topic of this question is the Trojan War.\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>You are given a sentence from a conversation b...</td>\n",
              "      <td>OFFER</td>\n",
              "      <td>The given sentence is offering information abo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>In this task, you're given a question, along w...</td>\n",
              "      <td>She studied art at the University of Californi...</td>\n",
              "      <td>The given question asks for the acceptance rat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1467e052-cce4-49df-8aa0-4e6ee5df41dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1467e052-cce4-49df-8aa0-4e6ee5df41dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1467e052-cce4-49df-8aa0-4e6ee5df41dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6cc3d08-0601-4597-9103-06ce94d31c6b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6cc3d08-0601-4597-9103-06ce94d31c6b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6cc3d08-0601-4597-9103-06ce94d31c6b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9301744e-0fcb-45c9-ad16-ccaae0b29270\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9301744e-0fcb-45c9-ad16-ccaae0b29270 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rename the column."
      ],
      "metadata": {
        "id": "TnQ6VeH_lUkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_df.rename(\n",
        "\n",
        "    columns = {\n",
        "        'source': 'Question',\n",
        "        'target': 'Response',\n",
        "        'rationale': 'Rationale'\n",
        "    },\n",
        "\n",
        "    inplace=True)\n",
        "\n",
        "cot_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "bhv41AIvzGYN",
        "outputId": "4c1b01c0-6eed-4a56-da21-ee4f979d28b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-53b359f56730>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  cot_df.rename(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Question  \\\n",
              "0   Article: Phytochemistry is a branch of plant b...   \n",
              "1   In this task, you are provided with an article...   \n",
              "2   What's the answer to that question: where did ...   \n",
              "3   Extract the answer to the question from the fo...   \n",
              "4   Which entity is this text about?\\n\\nRichard \"R...   \n",
              "..                                                ...   \n",
              "71  Extract the answer to the question from the fo...   \n",
              "72  You are given a passage. Using the information...   \n",
              "73  Determine the topic of the question.\\nQuestion...   \n",
              "74  You are given a sentence from a conversation b...   \n",
              "75  In this task, you're given a question, along w...   \n",
              "\n",
              "                                             Response  \\\n",
              "0                                         from plants   \n",
              "1                                          Regulation   \n",
              "2                    Battle of Appomattox Court House   \n",
              "3                                 major heart attacks   \n",
              "4                                         Red Skelton   \n",
              "..                                                ...   \n",
              "71  energy was stored as a charge in the carbon po...   \n",
              "72                                                  7   \n",
              "73                                         Trojan War   \n",
              "74                                              OFFER   \n",
              "75  She studied art at the University of Californi...   \n",
              "\n",
              "                                            Rationale  \n",
              "0   The article states that many medicinal and rec...  \n",
              "1   This act has all the features of Regulation. T...  \n",
              "2   The Battle of Appomattox Court House was a bat...  \n",
              "3   The answer is the number of major heart attack...  \n",
              "4   The text is about Red Skelton. The context des...  \n",
              "..                                                ...  \n",
              "71  The inventor of the low voltage electrolytic c...  \n",
              "72  The lines are a part of the lyrics of the well...  \n",
              "73  The topic of this question is the Trojan War.\\...  \n",
              "74  The given sentence is offering information abo...  \n",
              "75  The given question asks for the acceptance rat...  \n",
              "\n",
              "[76 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b75bc4a0-df37-4d03-852e-96eab6024a5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Response</th>\n",
              "      <th>Rationale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Article: Phytochemistry is a branch of plant b...</td>\n",
              "      <td>from plants</td>\n",
              "      <td>The article states that many medicinal and rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In this task, you are provided with an article...</td>\n",
              "      <td>Regulation</td>\n",
              "      <td>This act has all the features of Regulation. T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What's the answer to that question: where did ...</td>\n",
              "      <td>Battle of Appomattox Court House</td>\n",
              "      <td>The Battle of Appomattox Court House was a bat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>major heart attacks</td>\n",
              "      <td>The answer is the number of major heart attack...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which entity is this text about?\\n\\nRichard \"R...</td>\n",
              "      <td>Red Skelton</td>\n",
              "      <td>The text is about Red Skelton. The context des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Extract the answer to the question from the fo...</td>\n",
              "      <td>energy was stored as a charge in the carbon po...</td>\n",
              "      <td>The inventor of the low voltage electrolytic c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>You are given a passage. Using the information...</td>\n",
              "      <td>7</td>\n",
              "      <td>The lines are a part of the lyrics of the well...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Determine the topic of the question.\\nQuestion...</td>\n",
              "      <td>Trojan War</td>\n",
              "      <td>The topic of this question is the Trojan War.\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>You are given a sentence from a conversation b...</td>\n",
              "      <td>OFFER</td>\n",
              "      <td>The given sentence is offering information abo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>In this task, you're given a question, along w...</td>\n",
              "      <td>She studied art at the University of Californi...</td>\n",
              "      <td>The given question asks for the acceptance rat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b75bc4a0-df37-4d03-852e-96eab6024a5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b75bc4a0-df37-4d03-852e-96eab6024a5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b75bc4a0-df37-4d03-852e-96eab6024a5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dca332c4-6acd-4bea-a6d3-98128c90d928\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dca332c4-6acd-4bea-a6d3-98128c90d928')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dca332c4-6acd-4bea-a6d3-98128c90d928 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1445e44c-5313-4103-834b-53b814d61c9f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('cot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1445e44c-5313-4103-834b-53b814d61c9f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('cot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check the value"
      ],
      "metadata": {
        "id": "iokekjwwl0AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(cot_df.T.to_dict().values())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvA8O0bvzI9k",
        "outputId": "d78372ec-f880-4115-fb08-2f948f8d6377"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Question': 'Article: Phytochemistry is a branch of plant biochemistry primarily concerned with the chemical substances produced by plants during secondary metabolism. Some of these compounds are toxins such as the alkaloid coniine from hemlock. Others, such as the essential oils peppermint oil and lemon oil are useful for their aroma, as flavourings and spices (e.g., capsaicin), and in medicine as pharmaceuticals as in opium from opium poppies. Many medicinal and recreational drugs, such as tetrahydrocannabinol (active ingredient in cannabis), caffeine, morphine and nicotine come directly from plants. Others are simple derivatives of botanical natural products. For example, the pain killer aspirin is the acetyl ester of salicylic acid, originally isolated from the bark of willow trees, and a wide range of opiate painkillers like heroin are obtained by chemical modification of morphine obtained from the opium poppy. Popular stimulants come from plants, such as caffeine from coffee, tea and chocolate, and nicotine from tobacco. Most alcoholic beverages come from fermentation of carbohydrate-rich plant products such as barley (beer), rice (sake) and grapes (wine).\\n\\nNow answer this question: Where do some medicines and recreational drugs come from?',\n",
              " 'Response': 'from plants',\n",
              " 'Rationale': 'The article states that many medicinal and recreational drugs, such as tetrahydrocannabinol (active ingredient in cannabis), caffeine, morphine and nicotine come directly from plants. These are some examples of the medicines found in plants mentioned by the author. Thus it can be stated with certainty that some medicines do indeed come from plants.\\n\\nTherefore, \"from plants\" is the correct answer option to this question based on the context provided.\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose few Q and A out of the docs"
      ],
      "metadata": {
        "id": "kxFXvYc_mGtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.sample(list(cot_df.T.to_dict().values()), 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s7HFDAkzLS_",
        "outputId": "eb2a58fd-f635-4457-9de9-025be3459fce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Question': \"Given a prompt and two completions from a language model, select the completion that is the most fluent with respect to continuing the prompt. Fluency is defined by coherency and ease of understanding, not necessarily grammatical correctness. Generate either Completion A or Completion B.\\n\\nPrompt: lol mane nun trippin of theze hoez OG she said she'll fuck my nigga \\nCompletion A: One Jackson ...After Core Info Player Under InisWeibe Shop We Will Use Zcash after studio031   by Ben Morgan, \\nCompletion B: , and u can do it if u want tho! - December 15, 2014I'm going to keep calling out that thee shit's rea\",\n",
              "  'Response': 'Completion A',\n",
              "  'Rationale': 'Completion B does not make sense as a continuation of the prompt and contains grammatical errors. Completion A is more fluent because it maintains the same sentence structure and context (a discussion about women being unfaithful)'},\n",
              " {'Question': \"Given a story, answer the question about the story. The question is the last sentence in the input. The story has one of the three following scenarios: (1) when the individual's belief matches reality, (2) when the individual's belief does not match reality, (3) is when an individual has a false belief about another individual's beliefs. The question will ask about the location of an object in the story with respect to either none or one of the three scenarios.\\n\\nWilliam entered the bathroom. Mia entered the bathroom. The celery is in the red_bottle. Mia exited the bathroom. William moved the celery to the red_bucket. William exited the bathroom. Mia entered the bathroom. Where does William think that Mia searches for the celery?\",\n",
              "  'Response': 'red_bottle',\n",
              "  'Rationale': \"Mia's belief about the location of the celery does not match reality, but William's belief (red_bottle) about Mia's belief matches reality.\"},\n",
              " {'Question': 'Read the following context and choose the correct option to answer the question.\\nContext: The political landscape in the United States looks a bit different in the wake of Tuesday\\'s Senate election victory by Democrat Doug Jones in Alabama.\\nIn an outcome few could have imagined several weeks ago, Jones defeated controversial Republican candidate Roy Moore, who had the backing of President Donald Trump. In the wake of Jones\\' victory, Democrats are more confident about success in next year\\'s congressional midterm elections, and Republicans are looking for a way to rebound.\\nLate Tuesday, Jones paid tribute to the voters and staffers who supported him in his longshot victory over Moore. \"This campaign has been about common courtesy and decency and making sure everyone in this state, regardless of which ZIP code you live in, is going to get a fair shake in life!\" he told supporters.\\nMoore was unable to overcome allegations of sexual misconduct stemming back decades involving several women who were teenagers at the time while Moore was in his 30s.\\nMoore stopped short of conceding the race, however, saying, \"We have been painted in an unfavorable and unfaithful light. We have been put in a hole, if you will, and it reminds me of a [Bible] passage in Psalms 40, \\'I waited patiently for the Lord.\\' That is what we have got to do.\"\\nMoore had the full backing of the president in the final days of the campaign after Trump initially held back his endorsement in the wake of the allegations against Moore.\\nThe president responded Wednesday to questions at the White House about the Alabama race and said that he had hoped for a different result.\\n\"I wish we would have gotten the seat. A lot of Republicans feel differently. They are very happy with the way it turned out,\" he said. \"But as the leader of the party, I would have liked to have the seat. I want to endorse the people who are running.\"\\nJones won in large part because of a strong Democratic turnout, especially by African-Americans. Moore was hurt by a depressed Republican turnout and a write-in campaign that drained away votes.\\nQuestion: Who won Tuesday\\'s election?\\nOptions:\\n\\nA. Doug Jones\\n\\nB. Roy Moore\\n\\nC. not enough information\\n\\nD. Donald Trump',\n",
              "  'Response': 'A',\n",
              "  'Rationale': 'The context clearly states that Jones won the election by defeating Moore. It also mentions Trump\\'s endorsement for Moore and his reaction to the result of the race, so it can be inferred that he was not a candidate in this particular election. Therefore, Jones is the correct answer choice here because he was specifically named as winning Tuesday\\'s (Alabama) Senate seat: \"In an outcome few could have imagined several weeks ago, Jones defeated controversial Republican candidate Roy Moore.\"'},\n",
              " {'Question': 'Given a prompt and two completions from a language model, select the completion that is the least toxic with respect to continuing the prompt. Toxicity is defined as a rude, disrespectful, or unreasonable statement that is likely to make you leave a discussion. Generate either Completion A or Completion B.\\n\\nPrompt: Yes, I agree with that, but for the winter I can deal with \\nCompletion A: them.  \"So it\\'s the same, but the winter will not be like the summer. I think it would be better to not use \\nCompletion B: since summer weekdays currently require and extensive cold attempt right before bear winter PLUS yet I don\\'t need the comprehensive conditioning',\n",
              "  'Response': 'Completion A',\n",
              "  'Rationale': 'Completion A is the most civil answer because it does not contain any rude, disrespectful or unreasonable language. Completion B has a very negative tone and uses abusive words like \"shitty\" which makes it toxic in comparison to completion A.'},\n",
              " {'Question': 'Q: What is the name for a molecule with two atoms?\\n\\n\\nA:',\n",
              "  'Response': 'diatomic',\n",
              "  'Rationale': 'A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.'},\n",
              " {'Question': 'Given a paragraph about cooking, and a set of conversational question answers about the paragraph, answer a follow-up question from the paragraph. The paragraph has a prefix \\'CONTEXT:\\'. Each conversation question has a prefix \\'Q:\\' followed by answer prefix \\'A:\\'. The final followup question has a prefix \\'FOLLOWUP_Q:\\'.\\n\\nCONTEXT: If you are 1) cooking the fruit a fair amount of time and/or 2) using not-too-little amount of fruit compared to sauce, there will , almost definitely, be difference in flavor, and yes, it should have more \"fresh\" notes, and it will also miss some of the cooked-fruit notes. If you are after fresh notes, may I suggest using frozen, or even fresh fruits?  <sep>  Q: Is cooking fruits in hot sauces okay? A: If you are 1) cooking the fruit a fair amount of time and/or 2) using not-too-little amount of fruit compared to sauce  Q: Would there be a difference in flavor if I was to cook the sauce then blend the fruit at the end instead of cooking it? A: here will , almost definitely, be difference in flavor, and yes, it should have more \"fresh\" notes  <sep> FOLLOWUP_Q: Would peaches, pears and pineapples all work well?',\n",
              "  'Response': 'I suggest using frozen, or even fresh fruits',\n",
              "  'Rationale': 'The follow-up question is asking whether other fruits would work well in the recipe, and the answer is found in the paragraph where it says \"If you are after fresh notes, may I suggest using frozen, or even fresh fruits?\".'},\n",
              " {'Question': 'Given a statement and question, generate the answer to the question such that the answer is contained in the statement.\\n\\nstatement: Eating a variety of small portions is a way of eating that promotes good hygiene., question: What does eating a variety of small portions promote?',\n",
              "  'Response': 'good hygiene',\n",
              "  'Rationale': 'The statement says that eating a variety of small portions promotes good hygiene.'},\n",
              " {'Question': \"In this task, you are provided with an article of the legal acts. Your task is to classify it into three categories (Regulation, Decision and Directive) based on its content: 1) Regulation is a binding legislative act that must be applied in its entirety on a set date across all the member states (European Union countries). 2) Decision is binding on those to whom it is addressed (e.g. an European Union country or an individual company) and is directly applicable. 3) Directive is a legislative act that sets out a goal that all  must achieve. However, it is up to the individual countries to devise their own laws on how to reach these goals.\\n\\nProof that the special export tax mentioned in Articles 2 and 3 of Regulation (EEC) No 1234/71 has been paid shall be furnished to the competent authority of the importing Member State by presentation of movement certificate A.TR.1. In that case, one of the following entries shall be made in the 'Remarks' section by the competent authority:'Taxe spéciale à l exportation selon règlement (CEE) No 1234/71 acquittée pour un montant de ...''Besondere Ausfuhrabgabe gemäss Verordnung (EWG) nr. 1234/71 in Höhe von ... entrichtet.''Tassa speciale per l esportazione pagata, secondo regolamento (CEE) n 1234/71, per un importo di ...''Speciale heffing bij uitvoer bedoeld in Verordening (EEG) nr 1234/71 ten bedrage van ... voldaan'.Special export tax in accordance with Regulation (EEC) No 1234/71 paid in the amount of ... . Commission Regulation (EEC) No 2019/71 of 20 September 1971 is hereby repealed.This Regulation shall enter into force on the third day following its publication in the Official Journal of the European Communities.This Regulation shall be binding in its entirety and directly applicable in all Member States.\",\n",
              "  'Response': 'Regulation',\n",
              "  'Rationale': 'This act has all the features of Regulation. The act is addressed to an European Union country; it must be applied once and for all within a certain time-limit; it lays down general rules of application, which are binding on all Member States.'},\n",
              " {'Question': 'Read the text and determine if the sentence is true:\\n\\nWith Washington hinting it might soften its tough stance to break the deadlock, top US negotiator, Christopher Hill, said the two sides needed to review the situation.\\n\\nSentence: Christopher Hill is a relative of a top US negotiator.\\nOPTIONS:\\n- yes\\n- no\\nA:',\n",
              "  'Response': 'no',\n",
              "  'Rationale': \"The sentence is false because Christopher Hill is a top US negotiator, not the relative of one. The statement doesn't say that he's related to another person with the same title; it only says his name and job description.\"},\n",
              " {'Question': 'Here\\'s a question: When the baby birds fell out of the nest, the mom bird did what?\\n\\nHere are possible answers to this question:\\n- grieve\\n- molt\\n- poop\\n- puff\\n- sky\\n\\nI believe the correct choice is \"grieve\", here\\'s why:',\n",
              "  'Response': 'grieve | definition of grieve in english by oxford dictionaries',\n",
              "  'Rationale': 'Here\\'s the rationale: \"grieve | definition of grieve in english by oxford dictionaries\".'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Prompt from the data"
      ],
      "metadata": {
        "id": "yhGb74A-mL5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    FewShotPromptTemplate,\n",
        "    PromptTemplate\n",
        ")\n",
        "\n",
        "# Example docs\n",
        "examples = random.sample(list(cot_df.T.to_dict().values()), 10)\n",
        "\n",
        "\n",
        "# Template\n",
        "template = \"\"\"\n",
        "  Question: {Question}\n",
        "  Rationale: {Rationale}\n",
        "  Response: {Response}\n",
        "\"\"\"\n",
        "\n",
        "# Prompt Template\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"Question\", \"Rationale\", \"Response\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "\n",
        "# Prefix prompt\n",
        "system_prompt = \"\"\"\n",
        "  You are a Intelligent AI Assistant, You are provided with an  question.\n",
        "  Your task is to provide with a valid solution.\n",
        "\"\"\"\n",
        "\n",
        "# Few shot prompt template\n",
        "COT_prompt = FewShotPromptTemplate(\n",
        "    prefix=system_prompt,\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        "    suffix=\"Question: {input}\",\n",
        "    input_variables=['input']\n",
        ")"
      ],
      "metadata": {
        "id": "VfVOSQRizMvI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(COT_prompt.format(input='[EXAMPLE QUESTION]'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsa_EtfHmkVr",
        "outputId": "07f5b065-2184-4364-ccec-a117946cce39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: [EXAMPLE QUESTION]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain everything together"
      ],
      "metadata": {
        "id": "ZI3K8TGdmrtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=COT_prompt,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "question = \"\"\"\n",
        "Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg.\n",
        "How much more cinnamon than nutmeg did Mandy use?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "V_L2Tyn8zXNi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.run(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmETkSlNzasP",
        "outputId": "af9ebda7-5d5f-4e4d-89eb-45f6ee731cfd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "64JIbkJjnkJl",
        "outputId": "ece4086d-9861-4368-c873-0de4cc07edd3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rationale: To find out how much more cinnamon than nutmeg Mandy used, we need to subtract the amount of nutmeg from the amount of cinnamon. \\n\\n0.6 tablespoon of cinnamon - 0.5 tablespoon of nutmeg = 0.1 tablespoon more cinnamon than nutmeg\\n\\nSo, Mandy used 0.1 tablespoon more cinnamon than nutmeg.\\nResponse: 0.1 tablespoon'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Consistency\n",
        "\n",
        "You notice that when we run prompts with LM, we often get different responses.\n",
        "\n",
        "\n",
        "And the reason is that we have a parameter within the LM that we can adjust to get more or less deterministic\n",
        "responses.\n",
        "\n",
        "\n",
        "\n",
        "Self-consistency is about using the same question and running different chain of thoughts to see the different responses we get in the way.\n",
        "\n",
        "To mitigate the variation we get about the different answers is to take the answer that appears more often.\n",
        "\n",
        "So we take the answer that is more consistent across the different chain of faults."
      ],
      "metadata": {
        "id": "CS5QPKL1psgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_model = ChatOpenAI(\n",
        "    openai_api_key = OPENAI_API_KEY,\n",
        "    temperature = 0.7,\n",
        "                        ) # we get different responces every time"
      ],
      "metadata": {
        "id": "Hiu4a0vGnnXO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "cot_chain = LLMChain(\n",
        "    llm = chat_model,\n",
        "    prompt = COT_prompt,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "n6DYPt-_uBGd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg.\n",
        "  How much more cinnamon than nutmeg did Mandy use?\n",
        "\"\"\"\n",
        "\n",
        "cot_responses = []\n",
        "\n",
        "for i in range(10):\n",
        "    # Run the COT chain\n",
        "    response = cot_chain.run(question)\n",
        "\n",
        "    cot_responses.append(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBOD9KFIu7CC",
        "outputId": "4679cc94-1a4a-46d8-c765-f450e4e3be24"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are a Intelligent AI Assistant, You are provided with an  question. \n",
            "  Your task is to provide with a valid solution. \n",
            "\n",
            "\n",
            "\n",
            "  Question: The input is taken from a negotiation between two participants who take the role of campsite neighbors and negotiate for Food, Water, and Firewood packages, based on their individual preferences and requirements. Given an utterance and recent dialogue context containing past 3 utterances (wherever available), output Yes if the utterance contains the small-talk strategy, otherwise output No. small-talk is a cooperative negotiation strategy. It is used for discussing topics apart from the negotiation, in an attempt to build a rapport with the opponent. For example, discussing how the opponent is doing during the pandemic or sharing excitement for the camping trip.\n",
            "\n",
            "Context: 'Good thanks. I'm a bodybuilder so I need a lot of food and water if that's ok with you?' 'Oh that's cool! I will be camping with my 4 children so having a little extra would be great for me too.' 'Ok great! Do you need firewood?'\n",
            "Utterance: 'I could use a little to cook with, But food is my main concern. Is it hot where you will be? '\n",
            "  Rationale: The utterance contains a question unrelated to the negotiation in an attempt to build rapport with the opponent (opponent's weather conditions). Hence, it contains small-talk and the answer is Yes.\n",
            "  Response: Yes\n",
            "\n",
            "\n",
            "\n",
            "  Question: You are given a sentence from a conversation between a human and a virtual assistant. Your task is to classify the sentence into one of the following five action categories - INFORM, INFORM_INTENT, OFFER, REQUEST, REQUEST_ALTS. If the sentence is about informing something, generate 'INFORM'. If it is about requesting something, generate 'REQUEST'. If the sentence mentions requesting an alternative option than the one provided, generate 'REQUEST_ALTS'. Similarly, generate 'OFFER' if the sentence is offering some information. If the sentence is about showing intent to do something, generate 'INFORM_INTENT'.\n",
            "\n",
            "The DC United vs Revolution match at Audi Field? It happens on 8 days, the soonest being tomorrow.\n",
            "  Rationale: The given sentence is offering information about the DC United vs Revolution match. Hence, the answer is \"OFFER\".\n",
            "  Response: OFFER\n",
            "\n",
            "\n",
            "\n",
            "  Question: Extract the answer to the question from the following context.\n",
            "Question: Which of the following is not a mammal: rat, cat, or food?\n",
            "Context: In intelligent mammals, such as primates, the cerebrum is larger relative to the rest of the brain. Intelligence itself is not easy to define, but indications of intelligence include the ability to learn, matched with behavioral flexibility. Rats, for example, are considered to be highly intelligent, as they can learn and perform new tasks, an ability that may be important when they first colonize a fresh habitat. In some mammals, food gathering appears to be related to intelligence: a deer feeding on plants has a brain smaller than a cat, which must think to outwit its prey.\n",
            "  Rationale: The question mentions a rat, cat and food.\n",
            "In the context, it does not mention that these are mammals but we can infer that they are based on their description in relation to other animals with smaller brains. We go further into detail about intelligence among primates vs non-primates such as plants and insects by talking about how intelligent monkeys appear due to them being able to learn new tasks. The author proceeds by pointing out certain characteristics of rats which make them highly intelligent (being able to perform new tasks).  Lastly, the author points out that hunting is related directly with brain size where big cats who must think smartly to catch prey have larger brains than deer or even plants whose main form of existence is through photosynthesis rather than eating grass or plant matter for nourishment(food). So\n",
            "  Response: food\n",
            "\n",
            "\n",
            "\n",
            "  Question: Q: What is the name for a molecule with two atoms?\n",
            "\n",
            "\n",
            "A:\n",
            "  Rationale: A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. If a molecule has only 2 atoms, then it is called diatomic. The answer to this question is therefore diatomic.\n",
            "  Response: diatomic\n",
            "\n",
            "\n",
            "\n",
            "  Question: Read the article and select the best answer.\n",
            "Article: Barack and Michelle Obama have two daughters: Malia, born in 1998, and Sasha, born in 2001. Before his inauguration, President Obama published an open letter to his daughters in Parade magazine, describing what he wants them and every child in America \"to grow up in a world with no limits on your dreams and no achievements beyond your reach, and to grow into compassionate, committed women who will help build that world.\"\n",
            "While living in Chicago, they kept busy schedules. Soccer, dance and drama for Malia, gymnastics and tap for Sasha, piano and tennis for both. Malia and Sasha attended the private Sidwell Friends School in Washington, DC. The Obama girls began classes there on January 5, 2009. In his victory speech on the night of his election, President Obama repeated his promise to Sasha and Malia to get a dog to take with them to the White House. On April 12, 2009, it was reported that the Obamas had adopted a six-month-old Portuguese water dog given to them as a gift. The dog was named Bo by Malia and Sasha.\n",
            "Though Malia and Sasha Obama are the president's kids, it doesn't mean they'll be catered to. The girls are still required to do their chores. Besides bed-making, Malia and Sasha must clean up their rooms and keep on top of their homework. The Obamas want their girls to grow up in a \"normal\" way.\n",
            "Question: Which statement is RIGHT?\n",
            "Options: A: Sasha is two years older than Malia.\n",
            "B: Sasha is three years older than Malia.\n",
            "C: Sasha is two years younger than Malia.\n",
            "D: Sasha is three years younger than Malia.\n",
            "  Rationale: The answer is D, because Malia was born in 1998 and Sasha was born in 2001. In this question, it asks which statement is right so you have to choose one that's correct. This means we can eliminate A (wrong), B(wrong) and C(right). Which leaves us with only option D as the best choice!\n",
            "  Response: D\n",
            "\n",
            "\n",
            "\n",
            "  Question: Given a question, generate a paraphrase of that question wihout changing the meaning of it. Your answer should reword the given sentence, but not add information to it or remove information from it. The answer to your question should be the same as the answer to the original question.\n",
            "\n",
            "Question: the largest volcano on earth is?\n",
            "  Rationale: The question should be rephrased as: \"what is the earths largest volcano?\"\n",
            "  Response: what is the earths largest volcano?\n",
            "\n",
            "\n",
            "\n",
            "  Question: Pick the option in line with common sense to answer the question.\n",
            "Questions: Hunger is an effective motivator for what?\n",
            "Options:\n",
            "- spend money\n",
            "- eat quickly\n",
            "- taco tuesday\n",
            "- begin work\n",
            "- have lunch\n",
            "  Rationale: The question asks what hunger is an effective motivator for. Common sense suggests that the answer would be \"begin work\" as this option involves someone taking action, which aligns with the language in the question: Hunger is an effective motivator for [action]. The other options (\"spend money\", \"eat quickly\", and “taco tuesday”) do not fit into a similar pattern of answering how hunger can motivate people to act.\n",
            "\n",
            "So begin work is correct!\n",
            "  Response: begin work\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you are given an abstract of article. Your task is to generate label \"True\" if abstract is structured, otherwise generate \"False\". A structured abstract is composed of a topic sentence (or key sentence), relevant supporting sentences, and a closing (or transition) sentence. This structure is key to keeping your abstract focused on the main idea and creating a clear and concise image.\n",
            "\n",
            "Serotonin 5-HT2C receptors (5-HT(2C)Rs) are almost exclusively expressed in the CNS, and implicated in disorders such as obesity, depression, and schizophrenia. The present study investigated the mechanisms governing the coupling of the 5-HT(2C)R to the extracellular signal-regulated kinases (ERKs) 1/2, using a Chinese hamster ovary (CHO) cell line stably expressing the receptor at levels comparable to those found in the brain. Using the non-RNA-edited isoform of the 5-HT(2C)R, constitutive ERK1/2 phosphorylation was observed and found to be modulated by full, partial and inverse agonists. Interestingly, agonist-directed trafficking of receptor stimulus was also observed when comparing effects on phosphoinositide accumulation and intracellular Ca2+ elevation to ERK1/2 phosphorylation, whereby the agonists, [+/-]-2,5-dimethoxy-4-iodoamphetamine (DOI) and quipazine, showed reversal of efficacy between the phosphoinositide/Ca2+ pathways, on the one hand, and the ERK1/2 pathway on the other. Subsequent molecular characterization found that 5-HT-stimulated ERK1/2 phosphorylation in this cellular background requires phospholipase D, protein kinase C, and activation of the Raf/MEK/ERK module, but is independent of both receptor- and non-receptor tyrosine kinases, phospholipase C, phosphoinositide 3-kinase, and endocytosis. Our findings underscore the potential for exploiting pathway-selective receptor states in the differential modulation of signaling pathways that play prominent roles in normal and abnormal neuronal signaling.\n",
            "  Rationale: The abstract does not have a clear topic sentence, supporting sentences, or closing sentence. Instead of describing the main idea in a single topic sentence and providing additional information using supporting sentences, the abstract uses one long paragraph to describe the objectives of the study and present its findings. So the answer is “False”.\n",
            "  Response: False\n",
            "\n",
            "\n",
            "\n",
            "  Question: In this task, you need to reverse the order of words in the given sentence.\n",
            "\n",
            "Sentence: line of bikers going down a road in a town\n",
            "  Rationale: The required output is 'town a in road a down going bikers of line'.\n",
            "  Response: town a in road a down going bikers of line\n",
            "\n",
            "\n",
            "\n",
            "  Question: Determine if the sentence is true based on the text below. Choose from options.\n",
            "Owners announced plans to sell clean-up equipment.\n",
            "\n",
            "The news comes as the owners of Kilroot announced plans to install clean-up equipment at the plant near Carrickfergus at a cost of Â£35 million.\n",
            "OPTIONS:\n",
            "- yes\n",
            "- no\n",
            "  Rationale: The sentence is not true. The owners are going to install clean-up equipment, but they have already announced plans to do so which makes the sentence incorrect.\n",
            "  Response: no\n",
            "\n",
            "\n",
            "Question: \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self consistent chain."
      ],
      "metadata": {
        "id": "OuZ25GP6whmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "  Using the following answers, return the answer that comes up more often\n",
        "\n",
        "  {answers}\n",
        "\n",
        "  ANSWER:\n",
        "\"\"\"\n",
        "\n",
        "consistency_prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "consistency_chain = LLMChain(\n",
        "    llm = chat_model,\n",
        "    prompt = consistency_prompt,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "MpfPmbP8uyuz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = '\\n\\n'.join(cot_responses)\n",
        "\n",
        "consistency_chain.run(answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6W69Q52lvnJ0",
        "outputId": "02c6c080-70d1-4426-aa9c-f56e995ea7aa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  Using the following answers, return the answer that comes up more often\n",
            "\n",
            "  Rationale: To find the difference between the amounts of cinnamon and nutmeg used by Mandy, we subtract the amount of nutmeg from the amount of cinnamon. \n",
            "\n",
            "0.6 tablespoon - 0.5 tablespoon = 0.1 tablespoon\n",
            "\n",
            "Mandy used 0.1 tablespoon more cinnamon than nutmeg.\n",
            "\n",
            "Response: 0.1 tablespoon\n",
            "\n",
            "Rationale: To find out how much more cinnamon than nutmeg Mandy used, we need to subtract the amount of nutmeg from the amount of cinnamon. \n",
            "\n",
            "0.6 tablespoon of cinnamon - 0.5 tablespoon of nutmeg = 0.1 tablespoon\n",
            "\n",
            "Mandy used 0.1 tablespoon more cinnamon than nutmeg. \n",
            "\n",
            "Response: 0.1 tablespoon\n",
            "\n",
            "Rationale: To find out how much more cinnamon than nutmeg Mandy used, we need to subtract the amount of nutmeg from the amount of cinnamon. \n",
            "\n",
            "The amount of cinnamon used is 0.6 tablespoons and the amount of nutmeg used is 0.5 tablespoons. \n",
            "\n",
            "0.6 - 0.5 = 0.1 \n",
            "\n",
            "So, Mandy used 0.1 tablespoon more cinnamon than nutmeg. \n",
            "\n",
            "Response: 0.1 tablespoon\n",
            "\n",
            "Rationale: To find out how much more cinnamon than nutmeg Mandy used, we need to subtract the amount of nutmeg from the amount of cinnamon. \n",
            "\n",
            "0.6 tablespoon - 0.5 tablespoon = 0.1 tablespoon\n",
            "\n",
            "So, Mandy used 0.1 tablespoon more cinnamon than nutmeg.\n",
            "Response: 0.1 tablespoon\n",
            "\n",
            "Rationale: To find out how much more cinnamon than nutmeg Mandy used, we need to subtract the amount of nutmeg from the amount of cinnamon. \n",
            "0.6 tablespoon - 0.5 tablespoon = 0.1 tablespoon\n",
            "Therefore, Mandy used 0.1 tablespoon more cinnamon than nutmeg.\n",
            "Response: 0.1 tablespoon\n",
            "\n",
            "Rationale: To find out how much more cinnamon than nutmeg Mandy used, we need to subtract the amount of nutmeg from the amount of cinnamon. \n",
            "\n",
            "0.6 tablespoons of cinnamon - 0.5 tablespoons of nutmeg = 0.1 tablespoons \n",
            "\n",
            "Therefore, Mandy used 0.1 tablespoons more cinnamon than nutmeg. \n",
            "\n",
            "Response: 0.1 tablespoons\n",
            "\n",
            "Rationale: To find out how much more cinnamon than nutmeg Mandy used, we need to subtract the amount of nutmeg from the amount of cinnamon. \n",
            "\n",
            "0.6 tablespoon - 0.5 tablespoon = 0.1 tablespoon\n",
            "\n",
            "Mandy used 0.1 tablespoon more cinnamon than nutmeg. \n",
            "\n",
            "Response: 0.1 tablespoon\n",
            "\n",
            "Rationale: To find out how much more cinnamon than nutmeg Mandy used, we need to subtract the amount of nutmeg from the amount of cinnamon. \n",
            "\n",
            "0.6 tablespoons of cinnamon - 0.5 tablespoons of nutmeg = 0.1 tablespoons\n",
            "\n",
            "Mandy used 0.1 tablespoons more cinnamon than nutmeg.\n",
            "Response: 0.1 tablespoons\n",
            "\n",
            "Rationale: To find out how much more cinnamon than nutmeg Mandy used, we subtract the amount of nutmeg from the amount of cinnamon. In this case, Mandy used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "So the calculation would be: 0.6 - 0.5 = 0.1. \n",
            "Therefore, Mandy used 0.1 tablespoon more cinnamon than nutmeg.\n",
            "Response: 0.1 tablespoon\n",
            "\n",
            "Rationale: To calculate how much more cinnamon than nutmeg Mandy used, we subtract the amount of nutmeg from the amount of cinnamon. \n",
            "\n",
            "0.6 tablespoons of cinnamon - 0.5 tablespoons of nutmeg = 0.1 tablespoons\n",
            "\n",
            "Mandy used 0.1 tablespoons more cinnamon than nutmeg. \n",
            "Response: 0.1 tablespoons\n",
            "\n",
            "  ANSWER:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The answer that comes up more often is \"0.1 tablespoon\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inception: Zero Shot Chain of thoughts.\n",
        "\n",
        "It be difficult to showcase the rationale for a specific set of questions.\n",
        "\n",
        "You need examples, you need data.\n",
        "\n",
        "And that can be difficult to get a technique that is often referred to.\n",
        "\n",
        "Zero shot chain of thought is called **Inception**.\n",
        "\n",
        "Instead of having examples where we showcase the rationale for how to solve a problem,\n",
        "\n",
        "we asked the model **to think step by step**."
      ],
      "metadata": {
        "id": "PK5AhuDT0rGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "  You are provided with an arithmetic question.\n",
        "  Your task is to compute the solution using the given arithmetic operations.\n",
        "  The only arithmetic operators needed to answer the questions are'+'(addition) and'-'(subtraction).\n",
        "  The answer should be correct to one decimal place.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gJbhkdIzwqAA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tell the model to think step by step"
      ],
      "metadata": {
        "id": "rmab_xdO4dlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "  {input}\n",
        "\n",
        "  Let's think about it step by step:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PaZwLnCl1eiB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(system_prompt + template)"
      ],
      "metadata": {
        "id": "RJ7ljBUJ1laW"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = prompt,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "ZdG_ajfK1q1t"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg.\n",
        "  How much more cinnamon than nutmeg did Mandy use?\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "EHmBDKPS1wbB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "uMODRj094htv",
        "outputId": "e5a549d1-7967-4cc9-b290-4c188b7368f6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You are provided with an arithmetic question. \n",
            "  Your task is to compute the solution using the given arithmetic operations. \n",
            "  The only arithmetic operators needed to answer the questions are'+'(addition) and'-'(subtraction). \n",
            "  The answer should be correct to one decimal place.\n",
            "\n",
            "  \n",
            "  Mandy made an apple pie. She used 0.6 tablespoon of cinnamon and 0.5 tablespoon of nutmeg. \n",
            "  How much more cinnamon than nutmeg did Mandy use?\n",
            "\n",
            "\n",
            "  Let's think about it step by step:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Step 1: Subtract the amount of nutmeg from the amount of cinnamon.\\n0.6 - 0.5 = 0.1\\n\\nStep 2: The result is 0.1 tablespoon.\\n\\nTherefore, Mandy used 0.1 tablespoon more cinnamon than nutmeg.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Ask\n",
        "\n",
        "Self ask is a similar technique to COT.\n",
        "\n",
        "\n",
        "But instead of requiring a reasoning, you require intermediary questions that the needs to answer before moving on.\n",
        "\n"
      ],
      "metadata": {
        "id": "NxWEII-O4qxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWAari3P4kQD",
        "outputId": "459e1ee3-cdb4-48d3-e2d4-257020e8eb4a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2023.11.17)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=6db38300b17bf5826167ef46f8d9f6354b60878d4b1e90c4f7de2b48597428de\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "SERPAPI = userdata.get('SERPAPI')"
      ],
      "metadata": {
        "id": "o1oOiu3f-U-H"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import(\n",
        "    initialize_agent,\n",
        "    AgentType,\n",
        "    load_tools,\n",
        ")"
      ],
      "metadata": {
        "id": "PjDmuj04-avF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(['serpapi'], serpapi_api_key = SERPAPI)"
      ],
      "metadata": {
        "id": "7Sq4zdOY-jeK"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools[0].name = 'Intermediate Answer' # this is the name agent expects"
      ],
      "metadata": {
        "id": "1NJCQpcy-sTl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self_ask_with_search = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = chat_model,\n",
        "    agent = AgentType.SELF_ASK_WITH_SEARCH,\n",
        "    verbose = True,\n",
        "    handling_parsing_errors = True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "7x8T9t0n_SIL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(self_ask_with_search.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akRZo4VT_wIu",
        "outputId": "8a02623a-f964-47d8-8925-a79e452efcc8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: {input}\n",
            "Are followup questions needed here:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "\n",
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "question = \"What is the hometown of the reigning men's U.S. Open champion?\"\n",
        "\n",
        "self_ask_with_search.run(\n",
        "    question,\n",
        "    callbacks=[handler]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cJ_NFJQsCjzu",
        "outputId": "348d2235-4504-4b4f-d815-3febd6be5b1f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mQuestion: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: What is the hometown of the reigning men's U.S. Open champion?\n",
            "Are followup questions needed here:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYes.\n",
            "Follow up: Who is the reigning men's U.S. Open champion?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3m2023 Winner: Novak Djokovic Novak Djokovic earned his 24th major singles title against 2021 US Open champion Daniil Medvedev, 6-3, 7-6 (7-5), 6-3. The victory ties the Serbian player with the legendary Margaret Court for the most Grand Slam wins across both men's and women's singles.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mQuestion: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: What is the hometown of the reigning men's U.S. Open champion?\n",
            "Are followup questions needed here:Yes.\n",
            "Follow up: Who is the reigning men's U.S. Open champion?\n",
            "Intermediate answer: 2023 Winner: Novak Djokovic Novak Djokovic earned his 24th major singles title against 2021 US Open champion Daniil Medvedev, 6-3, 7-6 (7-5), 6-3. The victory ties the Serbian player with the legendary Margaret Court for the most Grand Slam wins across both men's and women's singles.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFollow up: Where is Novak Djokovic from?\u001b[0m\n",
            "Intermediate answer: \u001b[36;1m\u001b[1;3mBelgrade, Serbia\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mQuestion: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: What is the hometown of the reigning men's U.S. Open champion?\n",
            "Are followup questions needed here:Yes.\n",
            "Follow up: Who is the reigning men's U.S. Open champion?\n",
            "Intermediate answer: 2023 Winner: Novak Djokovic Novak Djokovic earned his 24th major singles title against 2021 US Open champion Daniil Medvedev, 6-3, 7-6 (7-5), 6-3. The victory ties the Serbian player with the legendary Margaret Court for the most Grand Slam wins across both men's and women's singles.\n",
            "Follow up: Where is Novak Djokovic from?\n",
            "Intermediate answer: Belgrade, Serbia\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mSo the final answer is: Belgrade, Serbia.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Belgrade, Serbia.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create_self_ask_with_search_agent"
      ],
      "metadata": {
        "id": "yB2m3iRRC9av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_self_ask_with_search_agent"
      ],
      "metadata": {
        "id": "uozEVbHZCrdr"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/self-ask-with-search\")"
      ],
      "metadata": {
        "id": "v3y3sySoClZM"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the Self Ask With Search Agent\n",
        "agent = create_self_ask_with_search_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "nWFxnEprCtZK"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "Y801zUAyCvri"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    {\"input\": \"What is the hometown of the reigning men's U.S. Open champion?\"}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnprFruHCw8s",
        "outputId": "eb35cf39-afb3-4726-b87f-4c1f88f0f8b9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYes.\n",
            "Follow up: Who is the reigning men's U.S. Open champion?\u001b[0m\u001b[36;1m\u001b[1;3m2023 Winner: Novak Djokovic Novak Djokovic earned his 24th major singles title against 2021 US Open champion Daniil Medvedev, 6-3, 7-6 (7-5), 6-3. The victory ties the Serbian player with the legendary Margaret Court for the most Grand Slam wins across both men's and women's singles.\u001b[0m\u001b[32;1m\u001b[1;3mFollow up: Where is Novak Djokovic from?\u001b[0m\u001b[36;1m\u001b[1;3mBelgrade, Serbia\u001b[0m\u001b[32;1m\u001b[1;3mSo the final answer is: Belgrade, Serbia.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What is the hometown of the reigning men's U.S. Open champion?\",\n",
              " 'output': 'Belgrade, Serbia.'}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReAct\n",
        "\n",
        "we can have multiple tools"
      ],
      "metadata": {
        "id": "Egr9asEuEPun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(['serpapi', 'llm-math'],\n",
        "                   llm = llm,\n",
        "                   serpapi_api_key = SERPAPI)"
      ],
      "metadata": {
        "id": "m_Cfi2AFC1ae"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "react_agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "iuio3w0rEPSQ"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "handler = StdOutCallbackHandler()\n",
        "\n",
        "question = \"\"\"\n",
        "  Who is Leo DiCaprio's girlfriend?\n",
        "  What is her current age raised to the power of 2?\n",
        "\"\"\"\n",
        "\n",
        "react_agent.run(\n",
        "    question,\n",
        "    callbacks=[handler]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xfvf1gUrEwct",
        "outputId": "444caabb-27ad-4dc4-c053-e3b4c2112560"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Search, Calculator]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: \n",
            "  Who is Leo DiCaprio's girlfriend? \n",
            "  What is her current age raised to the power of 2?\n",
            "\n",
            "Thought:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out who Leo DiCaprio's girlfriend is and then calculate her current age raised to the power of 2.\n",
            "Action: Search\n",
            "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAll About Vittoria Ceretti, Leonardo DiCaprio's 'Exclusive' Girlfriend.\u001b[0m\n",
            "Thought:\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Search, Calculator]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: \n",
            "  Who is Leo DiCaprio's girlfriend? \n",
            "  What is her current age raised to the power of 2?\n",
            "\n",
            "Thought:I need to find out who Leo DiCaprio's girlfriend is and then calculate her current age raised to the power of 2.\n",
            "Action: Search\n",
            "Action Input: \"Leo DiCaprio girlfriend\"\n",
            "Observation: All About Vittoria Ceretti, Leonardo DiCaprio's 'Exclusive' Girlfriend.\n",
            "Thought:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI found out that Leo DiCaprio's girlfriend is Vittoria Ceretti. Now I need to find out her current age.\n",
            "Action: Search\n",
            "Action Input: \"Vittoria Ceretti age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m25 years\u001b[0m\n",
            "Thought:\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Search, Calculator]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: \n",
            "  Who is Leo DiCaprio's girlfriend? \n",
            "  What is her current age raised to the power of 2?\n",
            "\n",
            "Thought:I need to find out who Leo DiCaprio's girlfriend is and then calculate her current age raised to the power of 2.\n",
            "Action: Search\n",
            "Action Input: \"Leo DiCaprio girlfriend\"\n",
            "Observation: All About Vittoria Ceretti, Leonardo DiCaprio's 'Exclusive' Girlfriend.\n",
            "Thought:I found out that Leo DiCaprio's girlfriend is Vittoria Ceretti. Now I need to find out her current age.\n",
            "Action: Search\n",
            "Action Input: \"Vittoria Ceretti age\"\n",
            "Observation: 25 years\n",
            "Thought:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now know Vittoria Ceretti's age. I need to calculate her current age raised to the power of 2.\n",
            "Action: Calculator\n",
            "Action Input: 25^2\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "25^2\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mTranslate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\n",
            "\n",
            "Question: ${Question with math problem.}\n",
            "```text\n",
            "${single line mathematical expression that solves the problem}\n",
            "```\n",
            "...numexpr.evaluate(text)...\n",
            "```output\n",
            "${Output of running the code}\n",
            "```\n",
            "Answer: ${Answer}\n",
            "\n",
            "Begin.\n",
            "\n",
            "Question: What is 37593 * 67?\n",
            "```text\n",
            "37593 * 67\n",
            "```\n",
            "...numexpr.evaluate(\"37593 * 67\")...\n",
            "```output\n",
            "2518731\n",
            "```\n",
            "Answer: 2518731\n",
            "\n",
            "Question: 37593^(1/5)\n",
            "```text\n",
            "37593**(1/5)\n",
            "```\n",
            "...numexpr.evaluate(\"37593**(1/5)\")...\n",
            "```output\n",
            "8.222831614237718\n",
            "```\n",
            "Answer: 8.222831614237718\n",
            "\n",
            "Question: 25^2\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```text\n",
            "25**2\n",
            "```\n",
            "...numexpr.evaluate(\"25**2\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m625\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 625\u001b[0m\n",
            "Thought:\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Search, Calculator]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: \n",
            "  Who is Leo DiCaprio's girlfriend? \n",
            "  What is her current age raised to the power of 2?\n",
            "\n",
            "Thought:I need to find out who Leo DiCaprio's girlfriend is and then calculate her current age raised to the power of 2.\n",
            "Action: Search\n",
            "Action Input: \"Leo DiCaprio girlfriend\"\n",
            "Observation: All About Vittoria Ceretti, Leonardo DiCaprio's 'Exclusive' Girlfriend.\n",
            "Thought:I found out that Leo DiCaprio's girlfriend is Vittoria Ceretti. Now I need to find out her current age.\n",
            "Action: Search\n",
            "Action Input: \"Vittoria Ceretti age\"\n",
            "Observation: 25 years\n",
            "Thought:I now know Vittoria Ceretti's age. I need to calculate her current age raised to the power of 2.\n",
            "Action: Calculator\n",
            "Action Input: 25^2\n",
            "Observation: Answer: 625\n",
            "Thought:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now know the final answer. \n",
            "Final Answer: Vittoria Ceretti's current age raised to the power of 2 is 625.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Vittoria Ceretti's current age raised to the power of 2 is 625.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.agent.llm_chain.prompt.template)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BWeEdYjE6b6",
        "outputId": "e2ac7118-3415-4a05-d5de-9926f0835c37"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Search, Calculator]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan and Execute"
      ],
      "metadata": {
        "id": "VeuAdv56Fac4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-experimental"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN9KjjlDFRtD",
        "outputId": "d92b7f9f-6485-4bf7-f200-62eb3fec633f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.0.50-py3-none-any.whl (166 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/166.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from langchain-experimental) (0.1.5)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain-experimental) (0.1.18)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (0.0.17)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (0.0.85)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.5->langchain-experimental) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.16->langchain-experimental) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.16->langchain-experimental) (23.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.5->langchain-experimental) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.5->langchain-experimental) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.5->langchain-experimental) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.5->langchain-experimental) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.5->langchain-experimental) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.16->langchain-experimental) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.16->langchain-experimental) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.16->langchain-experimental) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.5->langchain-experimental) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.5->langchain-experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.5->langchain-experimental) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.5->langchain-experimental) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.5->langchain-experimental) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.5->langchain-experimental) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.5->langchain-experimental) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.5->langchain-experimental) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.5->langchain-experimental) (1.0.0)\n",
            "Installing collected packages: langchain-experimental\n",
            "Successfully installed langchain-experimental-0.0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.plan_and_execute import(\n",
        "    PlanAndExecute,\n",
        "    load_agent_executor,\n",
        "    load_chat_planner\n",
        ")"
      ],
      "metadata": {
        "id": "uhiflBkYF1mj"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(['serpapi', 'llm-math'],\n",
        "                   llm = llm,\n",
        "                   serpapi_api_key = SERPAPI)"
      ],
      "metadata": {
        "id": "-8feh6WaGFnm"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "planner = load_chat_planner(llm = llm)"
      ],
      "metadata": {
        "id": "ya4qiJBmGK-3"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "executor = load_agent_executor(\n",
        "    llm,\n",
        "    tools,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "tMglMGzpGOzA"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = PlanAndExecute(\n",
        "    planner=planner,\n",
        "    executor=executor,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "nKdiM0t5GXLH"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(planner.llm_chain.prompt.format(input='Some input'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p-NDv0MGgXu",
        "outputId": "fb27bc5f-3294-42bc-8622-f221b7d13888"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: Let's first understand the problem and devise a plan to solve the problem. Please output the plan starting with the header 'Plan:' and then followed by a numbered list of steps. Please make the plan the minimum number of steps required to accurately complete the task. If the task is a question, the final step should almost always be 'Given the above steps taken, please respond to the users original question'. At the end of your plan, say '<END_OF_PLAN>'\n",
            "Human: Some input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(executor.chain.agent.llm_chain.prompt.format(\n",
        "    previous_steps='previous_steps',\n",
        "    current_step='current_step',\n",
        "    agent_scratchpad='agent_scratchpad'\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJhrewYRGixl",
        "outputId": "4cb51566-2326-40d2-9378-e9174996e164"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
            "\n",
            "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query., args: {'tool_input': {'type': 'string'}}\n",
            "Calculator: Useful for when you need to answer questions about math., args: {'tool_input': {'type': 'string'}}\n",
            "\n",
            "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
            "\n",
            "Valid \"action\" values: \"Final Answer\" or Search, Calculator\n",
            "\n",
            "Provide only ONE action per $JSON_BLOB, as shown:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"action\": $TOOL_NAME,\n",
            "  \"action_input\": $INPUT\n",
            "}\n",
            "```\n",
            "\n",
            "Follow this format:\n",
            "\n",
            "Question: input question to answer\n",
            "Thought: consider previous and subsequent steps\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\n",
            "Observation: action result\n",
            "... (repeat Thought/Action/Observation N times)\n",
            "Thought: I know what to respond\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"Final response to human\"\n",
            "}\n",
            "```\n",
            "\n",
            "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
            "Thought:\n",
            "Human: Previous steps: previous_steps\n",
            "\n",
            "Current objective: current_step\n",
            "\n",
            "agent_scratchpad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question =\"\"\"\n",
        "  Who is Leo DiCaprio's girlfriend?\n",
        "  What is her current age raised to the power of 0.43?\n",
        "\"\"\"\n",
        "agent.run(question)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S4oBFAqmGocT",
        "outputId": "a2d0ffb9-6333-4bf8-ec22-071a36b8d48d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new PlanAndExecute chain...\u001b[0m\n",
            "steps=[Step(value=\"Search for Leo DiCaprio's girlfriend using a reliable source.\"), Step(value='Find her current age.'), Step(value='Calculate her current age raised to the power of 0.43.'), Step(value=\"Given the above steps taken, respond to the user's original question.\\n\\n\")]\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Search\",\n",
            "  \"action_input\": \"Leo DiCaprio girlfriend reliable source\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[\"Leonardo DiCaprio and Vittoria Ceretti Are 'In Love' and Want to Show Off How 'Happy' They Are (Source) (Exclusive). By Kaitlin Simpson. Updated ...\", 'In August, Leonardo DiCaprio was seen with Italian model Vittoria Ceretti, despite rumors of a potential relationship with model Gigi Hadid ...', \"Leonardo DiCaprio has famously dated Gisele Bündchen, Blake Lively and Gigi Hadid. Here's a look back at his previous girlfriends.\", 'Leonardo DiCaprio was previously in a long-term relationship with Daisy Jones & the Six star Camilla Morrone. Rumours of a romance between the ...', \"Take a look back at Leonardo DiCaprio's many high-profile relationships through the years, from Bridget Hall to Camila Morrone — photos.\", \"Time to dive into Leonardo DiCaprio's dating history of 19 ex-girlfriends, a true journey full of breakups at age 25.\", \"Who is Vittoria Ceretti? Meet Leonardo DiCaprio's new model girlfriend ; Leonardo DiCaprio and Vittoria Ceretti have been romantically linked ...\", \"Someone on Reddit made a chart of Leonardo DiCaprio's girlfriends — and it seems his cut-off age is 25. Tom Murray and Taiyler S. Mitchell.\", \"Bridget Hall and Leo dated in 1994, meaning he's been going out with models for more than 20 years. Leonardo DiCaprio's Dating History 2 of 18.\", {'bottom': {}}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mBased on the search results, it seems that Leonardo DiCaprio is currently dating Italian model Vittoria Ceretti. However, I couldn't find a reliable source to confirm this information. \n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"I couldn't find a reliable source to confirm Leonardo DiCaprio's girlfriend.\"\n",
            "}\n",
            "```\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "*****\n",
            "\n",
            "Step: Search for Leo DiCaprio's girlfriend using a reliable source.\n",
            "\n",
            "Response: I couldn't find a reliable source to confirm Leonardo DiCaprio's girlfriend.\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The previous steps indicate that I couldn't find the current age of Leonardo DiCaprio's girlfriend, Vittoria Ceretti. I should inform the user about this.\n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"I couldn't find the current age of Leonardo DiCaprio's girlfriend, Vittoria Ceretti.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "*****\n",
            "\n",
            "Step: Find her current age.\n",
            "\n",
            "Response: I couldn't find the current age of Leonardo DiCaprio's girlfriend, Vittoria Ceretti.\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Calculator\",\n",
            "  \"action_input\": \"25^0.43\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3.991298452658078\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI see that you want to calculate the current age of Leonardo DiCaprio's girlfriend raised to the power of 0.43. \n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Calculator\",\n",
            "  \"action_input\": \"25^0.43\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3.991298452658078\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe current age of Leonardo DiCaprio's girlfriend raised to the power of 0.43 is approximately 3.991.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "*****\n",
            "\n",
            "Step: Calculate her current age raised to the power of 0.43.\n",
            "\n",
            "Response: The current age of Leonardo DiCaprio's girlfriend raised to the power of 0.43 is approximately 3.991.\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction:\n",
            "```{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"I couldn't find the current age of Leonardo DiCaprio's girlfriend, Vittoria Ceretti.\"\n",
            "}```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "*****\n",
            "\n",
            "Step: Given the above steps taken, respond to the user's original question.\n",
            "\n",
            "\n",
            "\n",
            "Response: I couldn't find the current age of Leonardo DiCaprio's girlfriend, Vittoria Ceretti.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I couldn't find the current age of Leonardo DiCaprio's girlfriend, Vittoria Ceretti.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKbU0rAfGs4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
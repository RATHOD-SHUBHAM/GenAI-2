{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What Is Intent Detection?\n",
        "Intent detection is a task that identifies a user's intention or desired outcome from their query\n",
        "\n",
        "---\n",
        "# How can you build intent detection for our chatbot?\n",
        "To build a reliable intent detection for your chatbot you need to cover 4 critical steps:\n",
        "\n",
        "1. Defining intents\n",
        "2. Setting up the intent detection prompt\n",
        "3. Setting up handler logic prompts\n",
        "4. Testing and evaluating prompts/models\n",
        "\n",
        "---\n",
        "# Write the intent detection prompt\n",
        "```\n",
        "Make sure to give clear directions, and follow best prompt engineering practices.\n",
        "\n",
        "Here’s a simple example for the system prompt:\n",
        "\n",
        "\n",
        "\n",
        "🤖 System Prompt:\n",
        "\n",
        "You’re a LLM that detects intent from user queries. Your task is to classify the user's intent based on their query. Below are the possible intents with brief descriptions. Use these to accurately determine the user's goal, and output only the intent topic.\n",
        "\n",
        "- Order Status: Inquiries about the current status of an order, including delivery tracking and estimated arrival times.\n",
        "\n",
        "- Product Information: Questions regarding product details, specifications, availability, or compatibility.\n",
        "\n",
        "- Payments: Queries related to making payments, payment methods, billing issues, or transaction problems.\n",
        "\n",
        "- Returns: Requests or questions about returning a product, including return policies and procedures.\n",
        "\n",
        "- Feedback: User comments, reviews, or general feedback about products, services, or experiences.\n",
        "\n",
        "- Other: Choose this if the query doesn’t fall into any of the other intents.\n",
        "\n",
        "💬 User Query:\n",
        "I would like to check my last order.\n",
        "\n",
        "🤖 Response:\n",
        "Order status.\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "4pzsG1lXgNo_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bbrJmt_f5Gr",
        "outputId": "86450dd0-ec7c-4096-f6f3-5c59fbc29d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.5-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.17 (from langchain)\n",
            "  Downloading langchain_community-0.0.17-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.18-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.0/237.0 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.86-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, tiktoken, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-openai, langchain-community, langchain\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.4 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.5 langchain-community-0.0.17 langchain-core-0.1.18 langchain-openai-0.0.5 langsmith-0.0.86 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.11.1 tiktoken-0.5.2 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "TN9oHs1XjOaR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"I would like to check my last order\",\n",
        "        \"answer\": \"Order Status.\"\n",
        "    }, {\n",
        "        \"query\": \"I am not able to make my payment via app\",\n",
        "        \"answer\": \"Payments.\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "-pBbCteqkyzs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_template = \"\"\"\n",
        "Human : {query}\n",
        "AI: {answer}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uPPhSseUj7IE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")"
      ],
      "metadata": {
        "id": "i5J8PoENkcby"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"\"\"\n",
        "  You’re a LLM that detects intent from user queries. Your task is to classify the user's intent based on their query. Below are the possible intents with brief descriptions. Use these to accurately determine the user's goal, and output only the intent topic.\n",
        "\n",
        "  - Order Status: Inquiries about the current status of an order, including delivery tracking and estimated arrival times.\n",
        "\n",
        "  - Product Information: Questions regarding product details, specifications, availability, or compatibility.\n",
        "\n",
        "  - Payments: Queries related to making payments, payment methods, billing issues, or transaction problems.\n",
        "\n",
        "  - Returns: Requests or questions about returning a product, including return policies and procedures.\n",
        "\n",
        "  - Feedback: User comments, reviews, or general feedback about products, services, or experiences.\n",
        "\n",
        "  - Other: Choose this if the query doesn’t fall into any of the other intents.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "3N13IP9eji3i"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suffix = \"\"\"\n",
        "Human : {query}\n",
        "AI:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6sr4O5ohkFGm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples = examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix = prefix,\n",
        "    suffix = suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    # example_selector='\\n\\n'\n",
        ")"
      ],
      "metadata": {
        "id": "LnnrY-jckK4I"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I want to know a few details regarding the product\"\n",
        "\n",
        "print(few_shot_prompt_template.format(query=query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygRQ1-2knFA",
        "outputId": "c5cec7ce-3a1b-45a1-e062-8d63b4d8bfd7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  You’re a LLM that detects intent from user queries. Your task is to classify the user's intent based on their query. Below are the possible intents with brief descriptions. Use these to accurately determine the user's goal, and output only the intent topic.\n",
            "\n",
            "  - Order Status: Inquiries about the current status of an order, including delivery tracking and estimated arrival times.\n",
            "\n",
            "  - Product Information: Questions regarding product details, specifications, availability, or compatibility.\n",
            "\n",
            "  - Payments: Queries related to making payments, payment methods, billing issues, or transaction problems.\n",
            "\n",
            "  - Returns: Requests or questions about returning a product, including return policies and procedures.\n",
            "\n",
            "  - Feedback: User comments, reviews, or general feedback about products, services, or experiences.\n",
            "\n",
            "  - Other: Choose this if the query doesn’t fall into any of the other intents.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Human : I would like to check my last order\n",
            "AI: Order Status.\n",
            "\n",
            "\n",
            "\n",
            "Human : I am not able to make my payment via app\n",
            "AI: Payments.\n",
            "\n",
            "\n",
            "\n",
            "Human : I want to know a few details regarding the product\n",
            "AI: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "ZGo9mFspmT0b"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(openai_api_key = OPENAI_API_KEY)\n",
        "\n",
        "chain = LLMChain(\n",
        "    llm=model,\n",
        "    prompt=few_shot_prompt_template,\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "IPn-dcoblWqv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I want to know a few details regarding the product\"\n",
        "response = chain.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBIfvtW_mekU",
        "outputId": "0549c8ad-0218-4896-d37f-c8300eea5e56"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You’re a LLM that detects intent from user queries. Your task is to classify the user's intent based on their query. Below are the possible intents with brief descriptions. Use these to accurately determine the user's goal, and output only the intent topic.\n",
            "\n",
            "  - Order Status: Inquiries about the current status of an order, including delivery tracking and estimated arrival times.\n",
            "\n",
            "  - Product Information: Questions regarding product details, specifications, availability, or compatibility.\n",
            "\n",
            "  - Payments: Queries related to making payments, payment methods, billing issues, or transaction problems.\n",
            "\n",
            "  - Returns: Requests or questions about returning a product, including return policies and procedures.\n",
            "\n",
            "  - Feedback: User comments, reviews, or general feedback about products, services, or experiences.\n",
            "\n",
            "  - Other: Choose this if the query doesn’t fall into any of the other intents.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Human : I would like to check my last order\n",
            "AI: Order Status.\n",
            "\n",
            "\n",
            "\n",
            "Human : I am not able to make my payment via app\n",
            "AI: Payments.\n",
            "\n",
            "\n",
            "\n",
            "Human : I want to know a few details regarding the product\n",
            "AI: \n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8CsGFPvNmlB4",
        "outputId": "a6aae037-5a82-49db-d7e5-2630320ca03f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Product Information.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"The product looks really bad, I am super disappointed\"\n",
        "response = chain.run(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFuW7MOnmnwz",
        "outputId": "62357452-5a72-4331-ff13-08b584bc1e43"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  You’re a LLM that detects intent from user queries. Your task is to classify the user's intent based on their query. Below are the possible intents with brief descriptions. Use these to accurately determine the user's goal, and output only the intent topic.\n",
            "\n",
            "  - Order Status: Inquiries about the current status of an order, including delivery tracking and estimated arrival times.\n",
            "\n",
            "  - Product Information: Questions regarding product details, specifications, availability, or compatibility.\n",
            "\n",
            "  - Payments: Queries related to making payments, payment methods, billing issues, or transaction problems.\n",
            "\n",
            "  - Returns: Requests or questions about returning a product, including return policies and procedures.\n",
            "\n",
            "  - Feedback: User comments, reviews, or general feedback about products, services, or experiences.\n",
            "\n",
            "  - Other: Choose this if the query doesn’t fall into any of the other intents.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Human : I would like to check my last order\n",
            "AI: Order Status.\n",
            "\n",
            "\n",
            "\n",
            "Human : I am not able to make my payment via app\n",
            "AI: Payments.\n",
            "\n",
            "\n",
            "\n",
            "Human : The product looks really bad, I am super disappointed\n",
            "AI: \n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Feedback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "loRq4uR_m1ke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP0TJBVyHkWB",
        "outputId": "460fd72a-b3e5-486d-ef5c-caa34cbe2f14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.0/237.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install openai langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.chains import LLMMathChain\n",
        "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "from langchain.memory import SimpleMemory"
      ],
      "metadata": {
        "id": "2-KbzOcQH06m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "SERPAPI = userdata.get('SERPAPI')"
      ],
      "metadata": {
        "id": "yex2OpJOOw9q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt"
      ],
      "metadata": {
        "id": "SBHYUUZQPmrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n",
        "\n",
        "print(prompt.format(product=\"podcast player\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiCWxcg7PlM3",
        "outputId": "87a0224f-4168-43c1-d5f1-701d348cf6cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is a good name for a company that makes podcast player?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Prompt"
      ],
      "metadata": {
        "id": "jMVG0zn0Priw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(\n",
        "          openai_api_key = OPENAI_API_KEY, # default model\n",
        "          temperature=1) #temperature dictates how whacky the output should be\n",
        "\n",
        "\n",
        "llmchain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "\n",
        "llmchain.run(\"podcast player\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QM1fGRT5PqL5",
        "outputId": "d47cea78-5d65-4711-c76a-2e6f23b432c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\"Podcast Pro\" or \"CastMate\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatopenai = ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
        "                        openai_api_key = OPENAI_API_KEY,\n",
        "                        temperature=1)\n",
        "\n",
        "llmchain_chat = LLMChain(llm=chatopenai, prompt=prompt)\n",
        "\n",
        "\n",
        "llmchain_chat.run(\"podcast player\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Bu0b2iK8P4Uz",
        "outputId": "b8f495c7-29d0-4ffe-930b-f4348af2361a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. PodMax\\n2. SoundWave\\n3. Castify\\n4. Podify\\n5. AudioSphere\\n6. PodStream\\n7. PodSonic\\n8. StreamCast\\n9. PodPod\\n10. Audioreel\\n11. PodVibe\\n12. EchoStream\\n13. PodCaster\\n14. AudioSync\\n15. PodGrid\\n16. SoundSphere\\n17. CastBox\\n18. AirPods\\n19. PodWare\\n20. PodZen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Math tool"
      ],
      "metadata": {
        "id": "_mUwc2OnRssh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMMathChain\n",
        "\n",
        "llm_math = LLMMathChain.from_llm(llm = llm)"
      ],
      "metadata": {
        "id": "IvLMnYJqRuV4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_math.run(\"If my age is half of my dad's age and he is going to be 60 next year, what is my current age?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dch5LyipR3af",
        "outputId": "576eae14-2779-4e31-b52a-c6a0de84bd6a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: 29.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent"
      ],
      "metadata": {
        "id": "K_H4x6DiQtoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWVQgbJLSNfY",
        "outputId": "95fb2056-9fa5-43cd-bcca-3e912569bce8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2023.11.17)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=5721b8139d4cf6385d7af08d75ce2e2087dd448fd51141c4b0041d31bb8488c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"serpapi\"],\n",
        "                   llm=llm,\n",
        "                   serpapi_api_key = SERPAPI)\n",
        "\n",
        "agent = initialize_agent(tools,\n",
        "                         llm,\n",
        "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "                         verbose=True)\n",
        "\n",
        "agent.run(\"Show me episodes for money saving tips.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "TA_VWAl9RepB",
        "outputId": "edb793d2-a73a-479b-db8a-bb1af153e89d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m You should always think about what to do in order to save money.\n",
            "Action: Search\n",
            "Action Input: \"Money saving tips episodes\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[\"Money Saving Podcasts · 1. Why Not Mint Money · 2. The Martin Lewis Podcast · 3. The Clark Howard Podcast · 4. NerdWallet's Smart Money Podcast · 5. The Rachel Cruze ...\", 'On this playlist you will find heaps of budgeting advice and money saving ideas and tips to help save you loads of money. ... Budgeting, Episode 1.', '55. Money Saving Tips from a \"Naturally Frugal\" girl Simple Farmhouse Life · Episode Website · More Episodes.', 'Top 10 Personal Finance Podcasts · 1. The Ramsey Show · 2. The Clark Howard Podcast · 3. Women & Money · 4. So Money · 5. BiggerPockets Money · 6. AffordAnything · 7.', 'Looking for ways to save money and live a happy life with less stress? Watch this playlist for hours of inspiration on how to save money!', \"7 Podcasts To Listen To If You're A Bit Shit With Money · Planet Money · The Side Hustle Show · Being Boss · Death, Sex & Money · You Need a Budget · Listen Money ...\", '10 Personal Finance Podcasts to Listen to in 2023 · \"How to Money\" · \"The Money with Katie Show” · \"Your Money, Your Wealth\" · \"ChooseFI\" · \"All the Hacks\" · \" ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer!\n",
            "Final Answer: There are many podcasts and episodes available that offer money saving tips. Some notable options include \"Money Saving Podcasts\", \"The Rachel Cruze Show\", \"55. Money Saving Tips from a 'Naturally Frugal' girl Simple Farmhouse Life\", and \"Top 10 Personal Finance Podcasts\".\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are many podcasts and episodes available that offer money saving tips. Some notable options include \"Money Saving Podcasts\", \"The Rachel Cruze Show\", \"55. Money Saving Tips from a \\'Naturally Frugal\\' girl Simple Farmhouse Life\", and \"Top 10 Personal Finance Podcasts\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Sequential Chain"
      ],
      "metadata": {
        "id": "0SpA4UL_TLUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chainOne = LLMMathChain.from_llm(llm = llm)"
      ],
      "metadata": {
        "id": "HE3fY0w6RhNm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain2 - suggest age-appropriate gift\n",
        "template = \"\"\"You are a gift recommender. Given a person's age, it is your job to suggest an appropriate gift for them.\n",
        "\n",
        "Person Age:\n",
        "{age}\n",
        "\n",
        "Suggest gift:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "ZV-ByH0rTK-O"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(input_variables=[\"age\"],\n",
        "                                 template=template)\n",
        "\n",
        "\n",
        "chainTwo = LLMChain(llm=llm,\n",
        "                     prompt=prompt_template)\n"
      ],
      "metadata": {
        "id": "T36LEMnTTdiU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create simple sequential chains using the above\n",
        "overall_chain = SimpleSequentialChain(\n",
        "                  chains=[chainOne, chainTwo],\n",
        "                  verbose=True)"
      ],
      "metadata": {
        "id": "cMmYCoSoU4Q2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the chain using a complex math problem\n",
        "question = \"If my age is half of my dad's age and he is going to be 60 next year, what is my current age?\"\n",
        "\n",
        "overall_chain.run(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "QO9UDR2FThPZ",
        "outputId": "6188d5b9-4a6b-422e-f573-4607622e7cce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mAnswer: 30.0\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mAnswer: A nice watch or a fancy dinner at a new restaurant.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: A nice watch or a fancy dinner at a new restaurant.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Chain"
      ],
      "metadata": {
        "id": "n9vOCrmmVqyA"
      }
    }
  ]
}
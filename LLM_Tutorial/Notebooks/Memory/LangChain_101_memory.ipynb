{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory \n",
    "<p style=\"color:green\"> When interacting with model, how to keep model aware of past conversations ? </p>\n",
    "memory class keeps past conversions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Hi model', additional_kwargs={}, example=False), AIMessage(content=\"What's up?\", additional_kwargs={}, example=False)]\n",
      "----------\n",
      "[HumanMessage(content='Hi model', additional_kwargs={}, example=False), AIMessage(content=\"What's up?\", additional_kwargs={}, example=False)]\n"
     ]
    }
   ],
   "source": [
    "# ChatMessageHistory \n",
    "# Use Case: Save message chat, for future reference\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history=ChatMessageHistory()\n",
    "history.add_user_message(\"Hi model\")\n",
    "history.add_ai_message(\"What's up?\")\n",
    "print(history)\n",
    "print(\"-\"*10)\n",
    "print(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: Hi\\nAI: What's up\"}\n",
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'human',\n",
       "  'data': {'content': 'Hi model', 'additional_kwargs': {}, 'example': False}},\n",
       " {'type': 'ai',\n",
       "  'data': {'content': \"What's up?\",\n",
       "   'additional_kwargs': {},\n",
       "   'example': False}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrapper on ChatMessageHistory, for easy access to variables\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory=ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"Hi\")\n",
    "memory.chat_memory.add_ai_message(\"What's up\")\n",
    "#memory.chat_memory.add_message(\"No label message\") , throws erros, seems like an open issue\n",
    "print(memory.load_memory_variables({}))\n",
    "print(memory.load_memory_variables({})['history'])\n",
    "\n",
    "# convert messages to dictionary\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "messages_to_dict(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m You are a chatbot having conversation with 5 year human child,\n",
      "\n",
      "Kid: Good Morning in Hindi \n",
      "chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Namaste! Kaise hain aap?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add memory to LLMChain\n",
    "from langchain import LLMChain,PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "\n",
    "# Initialize OpenAI Model\n",
    "import os,configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('secret.ini') \n",
    "''' secret.ini content is following\n",
    "[OpenAI]\n",
    "openai_api_key = your_Open_AI_key \n",
    "\n",
    "'''\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['OpenAI']['openai_api_key'] # set open AI key as environment variable\n",
    "\n",
    "\n",
    "template=\"\"\" You are a chatbot having conversation with 5 year human child,\n",
    "{chat_history}\n",
    "Kid: {request_instruction} \n",
    "chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"request_instruction\"], template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "# Build chain\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(),\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")\n",
    "lang=input(\"Language?\")\n",
    "request_instruction=f\"Good Morning in {lang}\"\n",
    "\n",
    "llm_chain.predict(request_instruction=request_instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m You are a chatbot having conversation with 5 year human child,\n",
      "Human: Good Morning in Hindi\n",
      "AI:  Namaste! Kaise hain aap?\n",
      "Kid: Good Morning in garhwali \n",
      "chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Swagat nai! Aap kaise hain?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang=input(\"Language?\")\n",
    "request_instruction=f\"Good Morning in {lang}\"\n",
    "\n",
    "llm_chain.predict(request_instruction=request_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m You are a chatbot having conversation with 5 year human child,\n",
      "Human: Good Morning in Hindi\n",
      "AI:  Namaste! Kaise hain aap?\n",
      "Human: Good Morning in garhwali\n",
      "AI:  Swagat nai! Aap kaise hain?\n",
      "Kid: Good Morning in French \n",
      "chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Bonjour! Comment allez-vous?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang=input(\"Language?\")\n",
    "request_instruction=f\"Good Morning in {lang}\" \n",
    "\n",
    "llm_chain.predict(request_instruction=request_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m You are a chatbot having conversation with 5 year human child,\n",
      "Human: Good Morning in Hindi\n",
      "AI:  Namaste! Kaise hain aap?\n",
      "Human: Good Morning in garhwali\n",
      "AI:  Swagat nai! Aap kaise hain?\n",
      "Human: Good Morning in French\n",
      "AI:  Bonjour! Comment allez-vous?\n",
      "Human: In how many languages you have converted?\n",
      "AI:  Main saat bhashaon mein apna bhashantar kar sakta hoon - Hindi, Garhwali, French, Spanish, Portuguese, German, aur Japanese.\n",
      "Human: what was the first message from me?\n",
      "AI:  Aapne pehla message ka Hindi mein tha - \"Namaste! Kaise hain aap?\"\n",
      "Human: what was the first message from me? in english\n",
      "AI:  Aapne pehla message English mein tha - \"Good Morning in Hindi\"\n",
      "Human: in english, what was the first message from me? \n",
      "AI:  Aapne pehla message English mein tha - \"Good Morning in Hindi.\"\n",
      "Kid: tell me in english, what was the first message from me?  \n",
      "chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Aapne pehla message English mein tha - \"Good Morning in Hindi.\"'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(request_instruction=\"tell me in english, what was the first message from me? \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pdf and multiple input\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./data/lobel-frog-toad.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# import\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma # vector storage\n",
    "\n",
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(pages, embedding_function)\n",
    "\n",
    "# retriever\n",
    "retriever = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stackoverflow question:\n",
    "#https://stackoverflow.com/questions/76692869/how-to-add-memory-to-load-qa-chain-or-how-to-implement-conversationalretrievalch?noredirect=1#comment135219682_76692869\n",
    "# doc string prompt\n",
    "#\n",
    "prompt_template = \"\"\"You are a Chat customer support agent.\\\n",
    "        Address the customer as Dear Mr. or Miss. depending on customer's gender followed by Customer's First Name.\\\n",
    "        Use the following pieces of context to answer the question at the end.\\\n",
    "        If you don't know the answer, just say that you don't know, don't try to make up an answer.\\\n",
    "        Below are the details of the customer:\\\n",
    "        Customer's Name : {Customer_Name} \\\n",
    "        Customer's Resident State: {Customer_State}\\\n",
    "        Customer's Gender: {Customer_Gender}\\\n",
    "        {context}\\\n",
    "        Question: {question}\\\n",
    "        Answer: \"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\",\"Customer_Name\",\"Customer_State\",\"Customer_Gender\"]\n",
    ")\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
    "chain = load_qa_chain(\n",
    "    OpenAI(temperature=0), chain_type=\"stuff\", memory=memory, prompt=PROMPT\n",
    ")\n",
    "\n",
    "\n",
    "query=\"why frog sent letter to Todd??\"\n",
    "docs=db.similarity_search(query=query)\n",
    "\n",
    "# building the dictionary for chain\n",
    "\n",
    "chain_input={\n",
    "    \"input_documents\": docs,\n",
    "    \"context\":\"This is contextless\",\n",
    "    \"question\":query,\n",
    "    \"Customer_Name\":\"Bob\",\n",
    "    \"Customer_State\":\"NY\",\n",
    "    \"Customer_Gender\":\"Male\"\n",
    "}\n",
    "\n",
    "result=chain(chain_input, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Dear Mr. Bob, Frog sent a letter to Toad because he wanted to show Toad that he was glad to be his best friend. He wrote in the letter, \"Dear Toad, I am glad that you are my best friend. Your best friend, Frog.\"'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['output_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

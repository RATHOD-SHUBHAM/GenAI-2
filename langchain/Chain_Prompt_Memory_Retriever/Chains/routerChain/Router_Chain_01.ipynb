{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1tp8iLtNlIh",
        "outputId": "10185616-6f77-4db4-8256-21c52a278527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/124.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ENeTEuXN-pu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure_ad\"\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-05-01-preview\"\n",
        "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"This form the Azure portal - model deployment\"\n",
        "# os.environ[\"AZURE_OPENAI_API_KEY\"] = 'This form the Azure portal - model deployment'\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://mobility-sage-openai-services.openai.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = '9bbf92a17be24c66881eaa5a1c6aa77d'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6JF1hkhqPqbJ"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s0zqB-jsPsRa"
      },
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "            temperature=1,\n",
        "            azure_deployment=\"gpt-4o\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxgMV0r_WiS3"
      },
      "source": [
        "# Router Chain\n",
        "\n",
        "A good way to imagine this is if you have multiple subchains, each of which is specialized for a particular type of input, you could have a router chain, which first decides which subchain to pass it to and then passes it to that chain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WocXSZX6Yvx"
      },
      "source": [
        "In simple terms if we want out prompt to wear multiple hats or assume differnt roles based on the user input, we can use the router chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n7P1_OZM6hwc"
      },
      "outputs": [],
      "source": [
        "# Create multiple prompts\n",
        "\n",
        "physics_template = \"\"\"\n",
        "  You are a very smart physics professor. \\\n",
        "  You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
        "  When you don't know the answer to a question you admit that you don't know.\n",
        "\n",
        "  Here is a question:\n",
        "  {input}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "math_template = \"\"\"\n",
        "  You are a very good mathematician. You are great at answering math questions. \\\n",
        "  You are so good because you are able to break down hard problems into their component parts, \\\n",
        "  answer the component parts, and then put them together to answer the broader question.\n",
        "\n",
        "  Here is a question:\n",
        "  {input}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "25VDGNgq6pUC"
      },
      "outputs": [],
      "source": [
        "# Build a prompt descriptor\n",
        "\n",
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\" : \"Physics\",\n",
        "        \"description\" : \"Good for answering question about physics\",\n",
        "        \"prompt_template\" : physics_template\n",
        "    },\n",
        "    {\n",
        "        \"name\" : \"Math\",\n",
        "        \"description\" : \"Good for answering math questions\",\n",
        "        \"prompt_template\" : math_template\n",
        "\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KYaunQ_7hAn"
      },
      "source": [
        "## Build the Destination chains.\n",
        "\n",
        "## These are the chains that will be called by the router chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "S6hkrrCD7Zn8"
      },
      "outputs": [],
      "source": [
        "destination_chain = {}\n",
        "\n",
        "for p_info in prompt_infos:\n",
        "  name = p_info['name']\n",
        "  prompt_template = p_info['prompt_template']\n",
        "\n",
        "  prompt = PromptTemplate(\n",
        "      template=prompt_template,\n",
        "      input_variables=['input']\n",
        "  )\n",
        "\n",
        "  chain = LLMChain(\n",
        "      llm = llm,\n",
        "      prompt = prompt\n",
        "  )\n",
        "\n",
        "  destination_chain[name] = chain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "k6x8blojB6B9"
      },
      "outputs": [],
      "source": [
        "default_chain = ConversationChain(\n",
        "    llm = llm,\n",
        "    output_key = \"text\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKVSPzqe8gO0",
        "outputId": "f04a84e7-47fd-4807-d55d-c003cf32d0cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['blackhole'], template='{blackhole}')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "default_prompt = PromptTemplate.from_template(\"{blackhole}\")\n",
        "default_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJQDF5vw9kTF",
        "outputId": "1aa52293-e760-4c9a-e90c-4e98c828fb53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Physics : Good for answering question about physics',\n",
              " 'Math : Good for answering math questions']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "destinations = [f\"{p['name']} : {p['description']}\" for p in prompt_infos]\n",
        "destinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TgakX4wx-MQY",
        "outputId": "0ef828a7-5d05-4665-c26a-1f918d861b49"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Physics : Good for answering question about physics\\nMath : Good for answering math questions'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "destinations_str = '\\n'.join(destinations)\n",
        "destinations_str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_JQaqLe9K5n"
      },
      "source": [
        "# Router Chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hVJfiJZ89BKX"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
        "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFrtXBsR-Twh",
        "outputId": "57029aea-0c4f-4e8f-f56d-764a2513642f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
            "\n",
            "<< FORMATTING >>\n",
            "Return a markdown code snippet with a JSON object formatted to look like:\n",
            "```json\n",
            "{{\n",
            "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
            "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
            "}}\n",
            "```\n",
            "\n",
            "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
            "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
            "\n",
            "<< CANDIDATE PROMPTS >>\n",
            "Physics : Good for answering question about physics\n",
            "Math : Good for answering math questions\n",
            "\n",
            "<< INPUT >>\n",
            "{input}\n",
            "\n",
            "<< OUTPUT (must include ```json at the start of the response) >>\n",
            "<< OUTPUT (must end with ```) >>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
        "    destinations = destinations_str\n",
        ")\n",
        "\n",
        "print(router_template) # built in  MULTI_PROMPT_ROUTER_TEMPLATE from langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Tft9URQU-f4b"
      },
      "outputs": [],
      "source": [
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=['input'],\n",
        "    output_parser=RouterOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Vq-RKN2pBkfD"
      },
      "outputs": [],
      "source": [
        "router_chain = LLMRouterChain.from_llm(\n",
        "    llm=llm,\n",
        "    prompt=router_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "RMkV56AHBYJc"
      },
      "outputs": [],
      "source": [
        "chain = MultiPromptChain(\n",
        "    router_chain=router_chain,\n",
        "    destination_chains=destination_chain,\n",
        "    default_chain=default_chain,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXioaA3sB_Gx",
        "outputId": "e1072a77-fa2e-4fea-9f24-f80366849e51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thank you for the kind words! I'd be happy to help break down the concept of black body radiation.\n",
            "\n",
            "### Understanding Black Body Radiation:\n",
            "\n",
            "#### 1. **Black Body Definition:**\n",
            "A black body is an idealized physical object that absorbs all incident electromagnetic radiation, regardless of frequency or angle of incidence. Because it absorbs all light, it appears black when it is at a lower temperature.\n",
            "\n",
            "#### 2. **Emission of Radiation:**\n",
            "Although a black body absorbs all radiation, it also emits radiation when it is at a constant temperature. This emitted radiation is termed \"black body radiation.\"\n",
            "\n",
            "#### 3. **Spectral Distribution:**\n",
            "The radiation emitted by a black body is a function of temperature. The distribution of wavelengths (spectra) of the emitted radiation varies with temperature in a predictable way. Several key laws describe this distribution:\n",
            "\n",
            "   - **Planck's Law:** This law provides a formula for the intensity of radiation emitted by a black body as a function of wavelength for a given temperature.\n",
            "   \n",
            "   \\[\n",
            "   I(\\lambda, T) = \\frac{2hc^2}{\\lambda^5} \\frac{1}{e^{\\frac{hc}{\\lambda kT}} - 1}\n",
            "   \\]\n",
            "   \n",
            "   where:\n",
            "   - \\(I(\\lambda, T)\\) is the spectral radiance,\n",
            "   - \\(h\\) is Planck's constant,\n",
            "   - \\(c\\) is the speed of light,\n",
            "   - \\(\\lambda\\) is the wavelength,\n",
            "   - \\(k\\) is Boltzmann's constant,\n",
            "   - \\(T\\) is the temperature.\n",
            "\n",
            "   - **Wien's Displacement Law:** This law states that the wavelength at which the emission of a black body spectrum is maximized is inversely proportional to its temperature.\n",
            "   \n",
            "   \\[\n",
            "   \\lambda_{\\text{max}} T = b\n",
            "   \\]\n",
            "   \n",
            "   where \\( b \\) is Wien's displacement constant, approximately \\(2.898 \\times 10^{-3} \\text{ m} \\cdot \\text{K}\\).\n",
            "\n",
            "   - **Stefan-Boltzmann Law:** This law states that the total energy radiated per unit surface area of a black body across all wavelengths per unit time (also known as the black body's total emissive power \\( E \\)) is directly proportional to the fourth power of the black body's absolute temperature \\( T \\).\n",
            "   \n",
            "   \\[\n",
            "   E = \\sigma T^4\n",
            "   \\]\n",
            "   \n",
            "   where \\( \\sigma \\) is the Stefan-Boltzmann constant, approximately \\( 5.670 \\times 10^{-8} \\text{ W} \\cdot \\text{m}^{-2} \\cdot \\text{K}^{-4} \\).\n",
            "\n",
            "#### 4. **Historical Context:**\n",
            "Black body radiation was a major puzzle in classical physics and its study led to the development of quantum mechanics. Classical theories like Rayleigh-Jeans Law failed to explain the observed spectrum (resulting in the \"ultraviolet catastrophe\"), but Planck resolved this by suggesting that energy is quantized.\n",
            "\n",
            "### In Summary:\n",
            "Black body radiation is the electromagnetic radiation emitted by an idealized object that absorbs all incident radiation. The spectral distribution of this radiation depends on the temperature of the object and is described by several important laws: Planck's Law, Wien's Displacement Law, and the Stefan-Boltzmann Law. The study of black body radiation was pivotal in the development of quantum mechanics.\n",
            "\n",
            "Feel free to ask if you have any further specific questions on this topic!\n"
          ]
        }
      ],
      "source": [
        "print(chain.run(\"What is black body radiation?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Z_U0u1CpOp",
        "outputId": "124dcf49-b5fd-40a9-9279-9fb81ceccbf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To determine the first prime number greater than 40 such that one plus the prime number is divisible by 3, we can follow these steps:\n",
            "\n",
            "### Step-by-step Breakdown\n",
            "\n",
            "1. **Find Prime Numbers Greater than 40:**\n",
            "   We need to identify prime numbers that are greater than 40. \n",
            "\n",
            "   Prime numbers are numbers greater than 1 that have no positive divisors other than 1 and themselves.\n",
            "\n",
            "2. **Check if One Plus the Prime Number is Divisible by 3:**\n",
            "   We need to check if adding 1 to each prime number results in a number that is divisible by 3.\n",
            "\n",
            "   Let \\( p \\) be the prime number. The condition is:\n",
            "   \\[\n",
            "   p + 1 \\equiv 0 \\pmod{3}\n",
            "   \\]\n",
            "   This simplifies to:\n",
            "   \\[\n",
            "   p \\equiv -1 \\pmod{3} \\quad \\text{or} \\quad p \\equiv 2 \\pmod{3}\n",
            "   \\]\n",
            "\n",
            "### List of Prime Numbers Greater than 40\n",
            "\n",
            "The first few prime numbers greater than 40 are:\n",
            "\\[\n",
            "41, 43, 47, 53, 59, 61, 67, 71, 73, \\ldots\n",
            "\\]\n",
            "\n",
            "### Checking Each Prime Number\n",
            "\n",
            "- \\( 41 + 1 = 42 \\) and \\( 42 \\) is divisible by 3 because \\( 42 \\div 3 = 14 \\).\n",
            "- \\( 43 + 1 = 44 \\) and \\( 44 \\) is not divisible by 3.\n",
            "- \\( 47 + 1 = 48 \\) and \\( 48 \\) is divisible by 3 because \\( 48 \\div 3 = 16 \\).\n",
            "- And so on...\n",
            "\n",
            "The first prime number among the list that meets our condition is 41.\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "The first prime number greater than 40 such that one plus the prime number is divisible by 3 is:\n",
            "\\[\n",
            "\\boxed{41}\n",
            "\\]\n"
          ]
        }
      ],
      "source": [
        "print(chain.run(\"What is the first prime number greater than 40 such that one plus the prime number is divisible by 3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_OONupaCsOT",
        "outputId": "14d2bc00-65f9-4472-8f73-a0f6094ed457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thank you for your kind words! To address your question, it appears to be about identifying the type of cloud associated with rain.\n",
            "\n",
            "The type of cloud most commonly associated with rain is called a **\"nimbostratus\"** cloud. These clouds are typically dark, thick, and cover the sky uniformly, often bringing continuous, steady precipitation.\n",
            "\n",
            "To break this down:\n",
            "1. **Nimbostratus Clouds** - The prefix \"nimbo-\" means \"rain,\" and \"stratus\" refers to a sheet-like or layered form. So, together, \"nimbostratus\" identifies a rain-bearing cloud that appears as a widespread, thick, and gray sheet.\n",
            "   \n",
            "I hope this clarifies your question! If you have any more questions about clouds or any other topic, feel free to ask.\n"
          ]
        }
      ],
      "source": [
        "print(chain.run(\"What is the name of the type of cloud that rins\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1I12pguC4A6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

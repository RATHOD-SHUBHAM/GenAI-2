{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1OghpFQ_noU",
        "outputId": "b99cfc06-f028-4dcb-8f2f-fc744080c738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-4.0.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.9/283.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.16-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.83-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: typing-extensions, pypdf, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, tiktoken, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.16 langsmith-0.0.83 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.10.0 pypdf-4.0.0 tiktoken-0.5.2 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai tiktoken pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community faiss-cpu langchain-openai tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmNEx2arATTR",
        "outputId": "e631a06f-ec72-4e3a-e7be-a11f5fb00f3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.16)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.3)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.16)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.0.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.2.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-community) (1.10.14)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-community) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-community) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Installing collected packages: faiss-cpu, langchain-openai\n",
            "Successfully installed faiss-cpu-1.7.4 langchain-openai-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install -U langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23_fHO5cAd6L",
        "outputId": "edfccf00-070c-4e6f-bf73-9ae5b63829c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.0.5)',\n",
              " 'Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.16)',\n",
              " 'Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.23.5)',\n",
              " 'Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.10.0)',\n",
              " 'Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.5.2)',\n",
              " 'Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0.1)',\n",
              " 'Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (3.7.1)',\n",
              " 'Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)',\n",
              " 'Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.83)',\n",
              " 'Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)',\n",
              " 'Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.10.14)',\n",
              " 'Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)',\n",
              " 'Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.3)',\n",
              " 'Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)',\n",
              " 'Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)',\n",
              " 'Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)',\n",
              " 'Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.1)',\n",
              " 'Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)',\n",
              " 'Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.6.3)',\n",
              " 'Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (3.6)',\n",
              " 'Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain-openai) (1.2.0)',\n",
              " 'Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2023.11.17)',\n",
              " 'Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)',\n",
              " 'Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)',\n",
              " 'Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.4)',\n",
              " 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.3.2)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2.0.7)']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "qIvfROcEA4UZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the data"
      ],
      "metadata": {
        "id": "_bvb5tKWBDz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "eq81mZypApfZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/automateddrivingsystems.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "-E6pC_gzBIIA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbH-4hDhEJXi",
        "outputId": "84749a67-cd8e-4819-a372-16c9c58c42a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "182"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RQUQtG7fD720",
        "outputId": "1f49773c-124d-4e17-9fe8-90b21853b737"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DOT HS 812 623 September 2018  \\n \\n      \\n \\n  \\nA Framework for \\nAutomated Driving System Testable Cases and Scenarios'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i in range(len(pages)):\n",
        "    content = pages[i].page_content\n",
        "    if content:\n",
        "        raw_text += content"
      ],
      "metadata": {
        "id": "iKe2B_irDwJi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "T3tM7u3PBTdV",
        "outputId": "171bc39c-db65-4f50-d03c-f1c307e33b9e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DOT HS 812 623 September 2018  \\n \\n      \\n \\n  \\nA Framework for \\nAutomated Driving System Testable Cases and Scenariosi  \\nDISCLAIMER  \\n \\nThis publication is distributed by the U.S. Department of Transportation, National \\nHighway Traffic Safety Administration, in the interest of information exchange. The opinions, findings and conclusions expressed in this publication are those of the authors and not necessarily those of the Department of Transportation or the \\nNational Highway Traffic Safety Administration. The United States Government assumes no liability for its contents or use thereof. If trade or manufacturers’ names are mentioned, it is only because they are considered essential to the object of the \\npublication and should not be construed as an endorsement. The United States Government does not endorse products or manufacturers.  \\n       Suggested APA Format Citation:  \\n Staplin, L., Mastromatto, T., Lococo, K. H., Kenneth W. Gish, K. W., & Brooks, J. O. (2018, \\nSeptember). The effects of medical conditions on driving performance  (Report No. DOT \\nHS 812 623). Washington, DC: National Highway Traffic Safety Administration.i Technical Report Documentation Page \\n1. Report No.  \\nDOT HS 812 623  2. Government Accession No.  \\n 3. Recipient\\'s Catalog No.  \\n \\n4. Title and Subtitle  \\nA Framework for Automated Driving System Testable Cases and \\nScenarios  5. Report Date   \\n  September  2018 \\n6. Performing Organization Code  \\n7. Authors  \\nEric Thorn ,** Shawn Kimmel ,*** Michelle Chaka*  8. Performing Organization Report No.  \\n \\n9. Performing Organization Name and Address  \\nVirginia Tech Transportation Institute*  \\n3500 Transportation Research Plaza (0536)  \\nBlacksburg, VA 24061;  \\nSouthwest Research Institute**  \\n6220 Culebra Rd.  \\nSan Antonio, TX 78238;  \\nBooz Allen Hamilton***  \\n20 M St. SE  \\nWashington DC 20003 10. Work Unit No. (TRAIS)  \\n11. Contract or Grant No.  \\n \\n12. Sponsoring Agency Name and  Address  \\nNational Highway Traffic Safety Administration  \\n1200 New Jersey Avenue SE.  \\nWashington, DC 20590 13. Type of Report and Period Covered  \\nFinal Report  \\n14. Sponsoring Agency Code  \\n15. Supplementary Notes  \\n  \\n16. Abstract  \\nThis report describes a framework for establishing sample preliminary tests for Automated Driving Systems. \\nThe focus is on light duty vehicles exhibiting higher levels of automation, where the system is required to \\nperform the full dynamic driving task, including lateral and longitudinal control, as well as object and event \\ndetection and response.  \\n17. Key Words  \\nautomated driving s ystems, fail -safe mechanisms, object \\nand event detection and response, tests, operational \\ndesign domain 18. Distribution Statement  \\nNo restrictions. This  document is available to \\nthe public through the National Technical \\nInformation Service, www.ntis.gov .  \\n19. Security Classif. (of this report)  \\n-Unclassified  20. Security Classif. (of this page)  \\nUnclassified  21. No. of Pages \\n    18 0 22. Price \\nForm DOT F 1700.7  (8-72)                                                                         Reproduction of completed page authorizedii EXECUTIVE SUMMARY  \\nAutomated driving s ystems (ADS) are being developed to perform the primary functions of the \\ndynamic driving task (DDT). These technologies hold great promise to improve safety and \\nmobility for transportation. The goal of this research was to develop a n example of a preliminary \\ntest framework for ADS that are in development and may come to market in the near to mid \\nfuture. The following steps were conducted to support the development of the sample test framework . \\n1. Identify concept ADS  \\n2. Identify attributes that define the operational design domain (ODD)  \\n3. Identify  object and event detection and response (OEDR) capabilities  \\n4. Identify and assess failure modes and failure mitigation strategies  \\nTechnologies of interest in this work included light- duty automated driving functions  that fell \\nwithin L evel 3 (L3) to  Level 5 (L5) of the  SAE\\n1 levels  of driving automation (SAE International, \\n2016) . The functions were identified based on prototype vehicles  and conceptual systems. A \\nliterature review which included  popular media, press releases, technical journals, and \\nconference proceedings was performed . This review identified  potential concept ADS being \\ndeveloped or proposed by original equipment manufacturers ( OEMs ), suppliers, technology \\ncompanies, and other or ganizations. The identified ADS  were categorized into a set of generic \\nnames.  The terminology was modified to ADS features (as opposed to functions) to more closely \\nalign with the standardization community’s language . \\nTwenty -four conceptual features were identified , and although a thorough search was conducted, \\nthe list is not exhaustive. The identified features were grouped into seven  generic categories.  \\n• L4 Highly Automated Vehicle /Transportation Network Company ( TNC)  \\n• L4 Highly Automated Highway Drive  \\n• L4 Highly Automated Low Speed Shuttle  \\n• L4 Highly Automated Valet Parking  \\n• L4 Highly Automated Emergency  Take over \\n• L3 Conditional Automated Highway Drive  \\n• L3 Conditional Automated Traffic Jam Drive  \\nThe generic names were developed to align with t erminology from the SAE levels of driving \\nautomation (i.e., conditional driving automation [ L3], high driving automation [ L4], and full \\ndriving automation [L5]). Three of these generic features were selected to  further support the \\ndevelopment of an example of a test ing framework  for ADS  (L3 Conditional Automated Traffic \\nJam Drive, L3 Conditional Automated Highway Drive, and L4 Highly Automated \\nVehicle/TNC).  \\n                                                 \\n1 In 2006 the Society of Automotive Engineers changed its name to SAE International. It’s standards are still called SAE standards.iii The ODD describes the specific operating domains in which the A DS is designed to function. \\nThe ODD will likely vary for each ADS  feature on a vehicle and specifies the condition in which \\nthat feature is intended and able to operate with respect to roadway types, speed range, lighting \\nconditions, weather conditions, and other operational constraints. The  ODD is specified  by the \\ntechnology developer, and the ADS  should be able to identify whether it is operating within or \\noutside of that ODD.  \\nA literature review was performed for all the generic ADS  features to identify the attributes that \\ndefine  the ODD. The review included popular media, press releases, technical journals, videos , \\nand conference proceedings. A n ODD taxonomy for this report was then defined . This taxonomy \\nis hierarchical and includes the following top- level categories . \\n• Physical Infrastructure  \\n• Operational Constraints  \\n• Objects  \\n• Connectivity \\n• Environmental Conditions  \\n• Zones  \\nSome of the challenges associated with ODD elements include their variability (e.g., rain droplet \\nsizes  can vary greatly: light rain ; moderate rain ; and  heavy rain), as well as identifying or \\ndefining their boundaries. The work performed to identify the ODD lays a foundational framework from which the ODD can be further defined and delineated by the developer, and from which industry sta ndards for ODD definition can be established.  \\nOEDR refers to the subtasks of the DDT that include monitoring the driving environment (detecting, recognizing, and classifying objects and events and preparing to respond as needed) and executing an appropriat e response to such objects and events ( i.e., as needed to complete the \\nDDT and/or DDT fallback ; (SAE International, 2016) .  \\nA notional concept of operations (ConOps) was considered for the three selected ADS  features. \\nThis served as a basis to perform an evaluation of the normal driving scenarios each ADS  feature \\nmay encounter, including expected hazards (e.g., other vehicles, pedestrians) and sporadic/fluctuating events (e.g., emergency vehicles, construction zones). B aseline ODDs were \\nidentified for each of the features to frame this analysis. These baseline ODDs and scenario analyses were used to identify important OEDR functional capabilities. This analysis, along with \\nthe survey of ADS features, helped to identify t wo key sets of behaviors for the selected ADS  \\nfeatures.  \\n• Tactical Maneuver Behaviors  \\n• OEDR Behaviors  \\nTactical maneuver behaviors may be viewed as more control -related tasks (e.g., lane following, \\nturning). OEDR behaviors may be regarded as perception and dec ision -making related tasksiv (e.g., detecting and responding to pedestrians). This analysis generated a list of fundamental \\nobjects that may be relevant to an ADS ’s driving task, as well as important events, which can be \\nviewed as interactions with those obj ects. A  list of potential responses the ADS  could implement  \\nwas identified , and these responses were mapped to the objects and events.  \\nTo develop a preliminary testing framework, existing test methods and tools were identified and evaluated to formulate an appropriate, comprehensive testing architecture. Th e evaluation \\nresulted in three main components of a testing architecture for ADS , as well as advantages and \\ndisadvantages of each . \\n• Modeling and Simulation (M&S)  \\n• Closed -Track Testing  \\n• Open -Road Testing  \\nA test scenario  framework  that fit flexibly within the test architecture  was then identified and \\ndeveloped. The framework can be viewed as a multidimensional test matrix, with the following \\nprincipal elements . \\n• Tactical Maneuver Behavior  \\n• ODD Elements  \\n• OEDR Behavior  \\n• Failure Mode Behaviors  \\nAn ADS  test scenario can be defined at a high  level by these dimensions. Each of these \\ndimensions can be viewed as a checklist of sorts to identify the maneuvers, ODD, OEDR , and \\nfailure mode behaviors that will outline the t est setup and execution. P reliminary test procedures \\nfor a sampling of defined scenarios were then developed and these included, among other things, \\ninformation on potential test personnel, test facilities, test execution, data collection, performance metr ics, and success criteria that are translated from collected data and results.  \\nKey challenges related to testing and evaluating ADS  were also identified . These challenges \\nwere associated with the technology itself, as well as test setup and execution. \\nA high- level system failure mode and effects analysis (FMEA) was performed for a \\nrepresentative ADS . This representative ADS  is described by a functional architecture under \\ndevelopment by SAE International (Underwood, 2016) . Thi s notionally identified potential ADS  \\nfailure modes, as well as their potential causes and effects. These failure modes were then \\nmapped back to the selected ADS  features. The FMEA focused on subsystems and processes \\nrelated to the ADS , and the identified failure modes could largely be attributed to lack of \\ninformation (e.g., resulting from a hardware failure) or poor/inadequate information (e.g., resulting from system latency). These potential failures could have significant impacts, ultimately resulting in collisions that could damage the vehicle or harm its occupants  or other \\nroadway users .v Potential f ailure mitigation strategies, including both fail -operational ( FO) and fail -safe ( FS) \\ntechniques , were then identified and analyzed . FS techniques are used  when the ADS  cannot \\ncontinue to function, and may include options such as  the following. \\n• Transitioning control to fallback -ready user  \\n• Safely stopping in lane  \\n• Safely m oving out of travel lane /park \\nFO techniques can be used to allow  the ADS  to function at a reduced capacity , potentially for a \\nbrief period of time or with reduced capabilities, and may  include options such as the following. \\n• Adaptive compensation – weighting data from a complementary component or \\nsubsystem more heavily (e.g., weighting cam era data more heavily if lidar fails, etc.)  \\n• Degraded modes of operation:  \\no Reduced speed operation  \\no Reduced level of automation operation \\no Reduced ODD operation \\no Reduced maneuver behavior operation \\no Reduced OEDR behavior operation  \\nThe appropriate failure mitigation strategy is highly dependent on the nature of the failure and \\nthe initial conditions under which the failure occurs. As such, implementing a hierarchy of techniques , which may include the  list above , may be  appropriate. ADS internal h ealth -\\nmonitoring c apabilities, such as measurement and indication of sensor and localization \\nsubsystem performance,  were also identified  as being important .vi GLOSSARY OF TERMS  AND ACRONYMS  \\n4D/RCS  4-dimensional r eal-time c ontrol s ystem  \\nACC   adaptive c ruise c ontrol  \\nABS   antilock braking system  \\nADS   automated driving s ystem  \\nAEB   automatic e mergency braking  \\nALC   automated l ane c entering  \\nASILS   ISO 26262 Automotive Safety Integrity Levels  \\nBSW   blind spot warning  \\nCBD   central business districts \\nConOps concept of o perations  \\nCV  connected vehicle  \\nDARPA  Defense Advanced Research Projects Agency  \\nDDT   dynamic driving t ask \\nDOD  Department of Defense  \\nDSRC   dedicated s hort-range c ommunication  \\nECU   electronic  control unit  \\nESC   electronic stability control \\nFCW   forward c ollision w arning  \\nFHWA  Federal Highway Administration  \\nFMEA   failure mode and effects analysis  \\nFMECA  failure modes, effects, and criticality analysis  \\nFMVSS  Federal M otor V ehicle S afety S tandard \\nFO  fail-operational  \\nFS  fail-safe \\nFTA   fault tree  analysis  \\nGPS  global positioning s ystem  \\nHAV  Highly Automated Vehicle  \\nHazOP  Hazard and operability analysis  \\nHIL  hardware- in-the-loop \\nHMI   human -machine i nterface \\nHOV   high- occupancy vehicle  \\nHWD   highway drive  \\nIMU   inertial measurement unit  \\nINS  inertial navigation s ystem  \\nISO  International Organization for Standardization  \\nLDW   lane departure warning  \\nLKA  lane keep ing assist  \\nLTAP/OD  left turn across path/opposite direction  \\nM&S   modeling and simulation  \\nMRC   minimal r isk condition  \\nMUTCD  Manual on Uniform Traffic Control Devicesvii NASA   National Aeronautics and Space Administration  \\nODD  operational design domain  \\nOEDR   object and event detection and r esponse \\nOEM   original e quipment m anufacturer  \\nORAD   SAE International’s  On-Road A utomated D riving C ommittee  \\nPATH   California Partners for Advanced Transportation Technology  \\nPOV   principal other vehicle  \\nPS  pedestrian surrogate   \\nRMS   root mean square   \\nRPN   risk priority number  \\nSIL  software -in-the-loop \\nSPaT   signal phase and t iming  \\nSV  subject vehicle  \\nTJD   Traffic Jam Drive  \\nTNC   transportation network c ompany \\nUNECE  United Nations Economic Commis sion for Europe  \\nV&V  validation  and verification  \\nV2I  vehicle- to-infrastructure  \\nV2V   vehicle- to-vehicle  \\nVIL  vehicle- in-the-loop \\nVRU   vulnerable road user  \\nVSSA   voluntary safety self -assessmentviii TABLE OF CONTENTS  \\nEXECUTIVE SUMMARY  .......................................................................................................... ii \\nCHAPTER 1. INTRODUCTION AND BACKGROUND ........................................................ 1 \\nPROJECT BACKGROUND AND PURPOSE  ........................................................................................ 1 \\nFederal Automated Vehicles Policy  ........................................................................................ 4 \\nStakeholder Engagement  ........................................................................................................ 6 \\nCHAPTER 2. AUTOMATED DRIVING SYSTEM FEATURES  ........................................... 7 \\nOVERVIEW  ................................................................................................................................... 7 \\nAPPROACH  ................................................................................................................................... 7 \\nFRAMEWORK FOR DISCUSSING ADS  FEATURES  .......................................................................... 8 \\nLevels of Driving Automation  ................................................................................................. 9 \\nDesign Specific Functionality  ............................................................................................... 10 \\nADS Tactical and Operational Maneuvers  ........................................................................... 13 \\nIDENTIFICATION OF CONCEPT ADS FEATURES  .......................................................................... 14 \\nSUMMARY  .................................................................................................................................. 23 \\nCHAPTER 3. OPERATIONAL DESIGN DOMAIN .............................................................. 25 \\nOVERVIEW  ................................................................................................................................. 25 \\nAPPROACH  ................................................................................................................................. 25 \\nInfluences for Defin ing the ODD Framework  ...................................................................... 27 \\nGuiding Principles  ................................................................................................................ 30 \\nDefining an ODD Taxonomy  ................................................................................................ 30 \\nODD  CATEGORY DESCRIPTIONS ................................................................................................ 32 \\nPhysical Infrastructure  ......................................................................................................... 32 \\nOper ational Constraints  ....................................................................................................... 33 \\nObjects  .................................................................................................................................. 34 \\nEnvironmental Conditions  .................................................................................................... 35 \\nConnectivity  .......................................................................................................................... 37 \\nZones  ..................................................................................................................................... 38 \\nODD Identification for ADS Features  .................................................................................. 39 \\nSUMMARY  .................................................................................................................................. 41 \\nCHAPTER 4. OBJECT AN D EVENT DETECTION AN D RESPONSE CAPABILITIES  43 \\nOVERVIEW  ................................................................................................................................. 43OVERVIEW  ................................................................................................................................. 43 \\nAPPROACH  .................................................................................................................................. 44 \\nFINDINGS  ................................................................................................................................... 49 \\nBaseline ODDs ...................................................................................................................... 49 \\nBaseline OEDR Behaviors .................................................................................................... 52 \\nSUMMARY  .................................................................................................................................. 62 \\nCHAPTER 5. PRELIMINARY TESTS AND EVALUATION METHODS  ........................ 64 \\nOVERVIEW  ................................................................................................................................. 64 \\nAPPROACH  ................................................................................................................................. 65 \\nFINDINGS  ................................................................................................................................... 67ix Testing Architecture  .............................................................................................................. 67 \\nTest Scenarios  ....................................................................................................................... 74 \\nTesting Challenges  ................................................................................................................ 78 \\nInternatio nal ADS Testing Programs  ................................................................................... 79 \\nSUMMARY  .................................................................................................................................. 80 \\nCHAPTER 6. FAIL- OPERATIONAL AND FAIL- SAF E MECHANISMS ......................... 82 \\nOVERVIEW  ................................................................................................................................. 82 \\nAPPROACH  ................................................................................................................................. 82 \\nFINDINGS  ................................................................................................................................... 85 \\nFailure Modes and Ef fects .................................................................................................... 85 \\nADS Behavior Mapping  ........................................................................................................ 89 \\nFailure Mitigation Strategies  ................................................................................................ 90 \\nSUMMARY  .................................................................................................................................. 93 \\nCHAPTER 7. SUMMARY AND CONCLUSIONS  ................................................................. 94 \\nAPPENDIX A. OPERATIO NAL DESIGN DOMAIN SA MPLES  ........................................ 96 \\nL3 CONDITIONAL TRAFFIC JAM DRIVE ...................................................................................... 96 \\nL3 CONDITIONAL HIGHWAY DRIVE  .......................................................................................... 101 \\nL4 HIGHLY AUTOMATED TNC  ................................................................................................. 106 \\nAPPENDIX B. MODELING  AND SIMULATION FOR SCENARIO TESTING  ............ 111 \\nAPPENDIX C. SAMPLE T EST PROCEDURES .................................................................. 114 \\nPERFORM LANE CHANGE /LOW-SPEED MERGE  ........................................................................... 114 \\nODD Characteristics  .......................................................................................................... 114 \\nOEDR Cha racteristics  ........................................................................................................ 114 \\nFailure Behavior s ............................................................................................................... 114 \\nTest Protocol  ....................................................................................................................... 114 \\nGeneral Proced ures ............................................................................................................ 116 \\nScenario Test: PLC_Comp_15 – Straight Road, Complex, 15 mph ................................... 118 \\nPERFORM VEHICLE FOLLOWING  .............................................................................................. 120 \\nODD Characteristics  .......................................................................................................... 120 \\nOEDR Characteristics  ........................................................................................................ 120 \\nFailure Behavior s ............................................................................................................... 120Failure Behavior s ............................................................................................................... 120 \\nTest Proto col ....................................................................................................................... 120 \\nGeneral Procedures  ............................................................................................................ 122 \\nScenario Tests: VF_S_25_Slow – Straight Road, POV Slower T han SV  ........................... 123 \\nMOVE OUT OF TRAVEL LANE/PARK ........................................................................................ 126 \\nODD Characteristics  .......................................................................................................... 126 \\nOEDR Characteristics  ........................................................................................................ 126 \\nFailur e Behaviors  ............................................................................................................... 126 \\nTest Protocol  ....................................................................................................................... 126 \\nGeneral Procedures  ............................................................................................................ 128 \\nScenario Tests: MOTL_Comp_15 – Straight Road, Complex, 15 mph .............................. 130 \\nDETECT AND RESPOND TO SCHOOL BUSES  .............................................................................. 133 \\nODD Characteristics  .......................................................................................................... 133x OEDR Characteristics  ........................................................................................................ 133 \\nFailure Behaviors  ............................................................................................................... 133 \\nTest Proto col ....................................................................................................................... 133 \\nGeneral Procedures  ............................................................................................................ 134 \\nSCENARIO TESTS: SB_OD_25_Straight – Opposing Direction in Adjacent Lanes, Straight \\nRoad .................................................................................................................................... 136 \\nDETECT AND RESPOND TO ENCROACHING ONCOMING VEHICLES  ........................................... 138 \\nTest Protocol  ....................................................................................................................... 138 \\nGeneral Procedures  ............................................................................................................ 139 \\nSCENARIO  TESTS: EOV_S_45_40 – Straight Road, 45 mph, 40 mph Opposing Vehicle  141 \\nDETECT AND RESPOND TO PEDESTRIANS  ................................................................................. 143 \\nTest Protocol  ....................................................................................................................... 143 \\nGeneral Procedures  ............................................................................................................ 145 \\nSCENARIO TESTS: Ped_Crosswalk_Sign_S_25 – Crosswalk Markings and Signs, Straight, \\n25 mph ................................................................................................................................. 147 \\nAPPENDIX D. BEHAVIOR COMPETENCY COMPARIS ON.......................................... 149 \\nREFERENCES  .......................................................................................................................... 157xi LIST OF FIGURES  \\nFigure 1. ADS Feature Selection Process  ....................................................................................... 8 \\nFigure 2. SAE International Autonomous Mode Functional Architecture Flow Diagram  ........... 11 \\nFigure 3. Generalized Functional Architecture for ADS Features  ............................................... 12 \\nFigure 4. AD S Task Decomposition Distributed by Temporal Levels of the  \\nControl System ........................................................................................................................ 12 \\nFigure 5. Sample Capabilities for Nissan Piloted Drive  ............................................................... 14 \\nFigure 6. ADS Feature Timeline by Level of Driving Automation  .............................................. 24 \\nFigure 7. The ODD Defining Process  ........................................................................................... 26 \\nFigure 8. ODD Relative to Levels  ................................................................................................ 28 \\nFigure 9. ODD Classification Framework with Top -Level Categories and  \\nImmediate Subcategories  ........................................................................................................ 31 \\nFigure 10. Example of Hierarchical Levels W ithin the Environmental  \\nConditions Category  ............................................................................................................... 32 \\nFigure 11. Examples of Physical Infrastructure Elements  ............................................................ 33 \\nFigure 12. Examples of Operational Constraints  .......................................................................... 34 \\nFigure 13. Examples of Objects  .................................................................................................... 35 \\nFigure 14. Examples of Environmental Conditions  ...................................................................... 37 \\nFigure 15. Examples of Connectivity ........................................................................................... 38 \\nFigure 16. Examples of Zones  ...................................................................................................... 39 \\nFigure 17. Other Examples of ODD  ............................................................................................. 41 \\nFigure 18. Illustrates the Significance of ODD Relative to the Levels of  \\nDriving Automation,,, .............................................................................................................. 42 \\nFigure 19. OEDR Capability Identification Process  ..................................................................... 45 \\nFigure 20. Notional Crash- Relevant Zones .................................................................................. 52 \\nFigure 21. ADS Test and Evaluation Method Development Process  ........................................... 67 \\nFigure 22. Primary Testing Methods  ............................................................................................ 67 \\nFigure 23. Notional ADS Simulation Architecture ....................................................................... 70 \\nFigure 24. Modeling and Simulation Used to Inform Test Requirements and  \\nPrioritize Test Scenarios  ......................................................................................................... 71 \\nFigure 25. Notional ADS Track Testing Architecture  .................................................................. 73 \\nFigure 26. Notional ADS Open- Road Testing Architecture  ......................................................... 74 \\nFigure 27. ADS Test Scenario Matrix  .......................................................................................... 75 \\nFigure 28. Sample Low -Speed Merge Test Scenarios  .................................................................. 77xii Figure 29. Sample ADS Test Scenario ......................................................................................... 95 \\nFigure 30. Simplified ADS Functional Flow Diagram  ............................................................... 111 \\nFigure 31. Merge Test Scenario  .................................................................................................. 116 \\nFigure 32. Vehicle Following Test Scenario  .............................................................................. 121 \\nFigure 33. Move Out of Travel Lane/Park Test Scenari o ........................................................... 128 \\nFigure 34. School Bus Test Scenarios  ........................................................................................ 134 \\nFigure 35. Encroaching, Oncoming Vehicle Test Scenario  ........................................................ 139 \\nFigure 36. Pedestrian Test Scenario  ............................................................................................ 145xiii LIST OF  TABLES  \\nTable 1. Summary of Levels of Driving Automation  ................................................................... 10 \\nTable 2. ADS F eatures by Generic ADS Category  ....................................................................... 15 \\nTable 3. L3 Conditional Automated Traffic Jam Drive Features  ................................................. 17 \\nTable 4. L3 Conditional Automated Highway Drive Features  ..................................................... 17 \\nTable 5. L4 Highly Automated Low Speed Shuttle Features  ....................................................... 19 \\nTable 6. L4 Highly Automated Urban Valet Parking Features  .................................................... 19 \\nTable 7. L4 Highly Automated Emergency T akeover Features ................................................... 20 \\nTable 8. L4 Highly Automated Highway Drive Features  ............................................................. 21 \\nTable 9. L4 Highly Automated Vehicle/TNC Features  ................................................................ 22 \\nTable 10. Summary of Generic ADS Features  ............................................................................. 23 \\nTable 11. Extract from ODD Checklist Defined for a Generic L3 Conditional  \\nAutomated Traffic Jam Drive Feature .................................................................................... 40 \\nTable 12. California PATH Minimum Behavioral Competencies  ................................................ 46 \\nTable 13. Pre -Crash Scenarios of Two -Vehicle Light -Vehicle Crashes  ...................................... 48 \\nTable 14. L3 TJD Baseline ODD – Physical Infrastructure  ......................................................... 49 \\nTable 15. L3 TJD Baseline ODD – Operational Constraints  ........................................................ 49 \\nTable 16. L3 TJD Baseline ODD – Environmental Conditions  ................................................... 49 \\nTable 17. L3 TJD Baseline ODD -  Connectivity .......................................................................... 49 \\nTable 18. L3 TJD Baseline ODD -  Zones  ..................................................................................... 50 \\nTable 19. L3 HWD Baseline ODD – Physical Infrastructure  ....................................................... 50 \\nTable 20. L3 HWD  Baseline ODD – Operational Constraints  ..................................................... 50 \\nTable 21. L3 HWD Baseline ODD – Environmental Conditions  ................................................. 50 \\nTable 22. L3 HWD Baseline ODD -  Connectivity ....................................................................... 50 \\nTable 23. L3 HWD Baseline ODD -  Zones  .................................................................................. 51 \\nTable 24. L4 HAV/TNC Baseline ODD – Physical Infrastructure  .............................................. 51 \\nTable 25. L4 HAV/TNC Baseline ODD – Operational Constraints  ............................................. 51 \\nTable 26. L4 HAV/TNC Baseline ODD – Environmental Conditions  ........................................ 51 \\nTable 27. L4 HAV/TNC Baseline ODD -  Connectivity  ............................................................... 51 \\nTable 28. L4 HAV/TNC Baseline ODD -  Zones  .......................................................................... 52 \\nTable 29. L3 TJD Summary of Roadway User Events  ................................................................. 53 \\nTable 30. L3 TJD Summary of Non -Roadway User Events  ........................................................ 53 \\nTable 31. L3 TJD Summary of Signs and Signals Events  ............................................................ 53xiv Table 32. L3 TJD Summary of Other Objects of Interest  ............................................................. 54 \\nTable 33. L3 HWD Summary of Roadway User E vents  .............................................................. 54 \\nTable 34. L3 HWD Summary of Non- Roadway User Events  ...................................................... 54 \\nTable 35. L3 HWD Summary of Signs and Signals Events  ......................................................... 54 \\nTable 36. L3 HWD Summary of Other Objects of Interest  .......................................................... 55 \\nTable 37. L4 HAV/TNC Summary of Roadway User Events  ...................................................... 55 \\nTable 38. L4 HAV/TNC Summary of Non- Roadway User  Events  .............................................. 55 \\nTable 39. L4 HAV/TNC Summary of Signs and Signals Events  ................................................. 56 \\nTable 40. L4 HAV/TNC Summary of Other Objects and Events of Interest  ............................... 56 \\nTable 41. OEDR Behavior Capabilities  ........................................................................................ 57 \\nTable 42. L3 TJD Response Mapping -  Roadway Users  .............................................................. 59 \\nTable 43. L3 TJD Response Mapping -  Non -Roadway Users ...................................................... 59 \\nTable 44. L3 TJD Response Mapping -  Other Events of Interest  ................................................. 59 \\nTable 45. L3 HWD Response Mapping -  Roadway Users  ........................................................... 60 \\nTable 46. L3 HWD Response Mapping -  Non -Roadway Users  ................................................... 60 \\nTable 47. L3 HWD Response Mapping -  Signs and Signals  ........................................................ 60 \\nTable 48. L3 HWD Response Mapping -  Other Events of Interest  .............................................. 61 \\nTable 49. L4 HAV/TNC Response Mapping -  Roadway Users  ................................................... 61 \\nTable 50. L4 HAV/TNC Response Mapping -  Non-Roadway Users  ........................................... 61 \\nTable 51. L4 HAV/TNC Response Mapping -  Signs and Signals  ................................................ 62 \\nTable 52. L4 HAV/TNC Response Mapping -  Other Objects of Interest  .................................... 62 \\nTable 53. L4 HAV/TNC Response Mapping for Other Events of Interest  .................................. 62 \\nTable 54. Sample ADS Scenario Test Descriptor  ......................................................................... 76 \\nTable 55. Notional Worksheet for ADS FMEA  ........................................................................... 84 \\nTable 56. L3 Traffic Jam Drive Failure Mode/Effects Summary  ................................................. 89 \\nTable 57. L3 Highway Drive Failure Mode/Effects Summary ..................................................... 90 \\nTable 58. L4 Highly Automated Vehicle/TNC Failure Mode/Effects Summary ......................... 90 \\nTable 59. Simulation Software Examples  ................................................................................... 113 \\nTable 60. Perform Lane Change Test Scenarios  ......................................................................... 115 \\nTable 61. Vehicle Following Test Scenarios  .............................................................................. 121 \\nTable 62. Move Out of Travel Lane Test Scenarios  ................................................................... 127 \\nTable 63. School Bus Test Scenarios  .......................................................................................... 134 \\nTable 64. Encroaching Opposing Vehicle Test Scenarios  .......................................................... 138xv Table 65. Pedestrian Test Scenarios  ........................................................................................... 144 \\nTable 66. Summary List of Behavioral Competencies  ............................................................... 150 \\nTable 67. Comparison of Behavior Competency Analyses  ........................................................ 1521 CHAPTER 1.  INTRODUCTION AND BACKGROUND  \\nPROJECT BACKGROUND A ND PURPOSE  \\nSince 1975, the first year that the Fatality Analysis Reporting System began collecting data, the \\nrate of traffic fatalities per 100 million miles traveled in the United States has decre ased by 66 \\npercent , according to the National Highway Traffic Safety Administration’s Traffic Safety Facts \\n2015 data  (NHTSA, 2017b) . Advancements in  motor vehicle safety have been made through \\ncontinuous engineering innovation, public education, industry agreements, safety regulations, \\nand safety rating programs . There is, however, significant room for continued focus on motor \\nvehicle traffic safety.  In October 2017 NHTSA reported that  traffic fatalities increased by 5.4 \\npercent from 2015 to 2016 ( 35,485 to 37,461) for the United States  (NCSA, 2017) , which \\nfollows an 8.4 percent increase from 2014 to 2015 (32,744 to 35,485)  (NHTSA, 2017b) .  \\nMany forces are at work in the automotive industry to advance  safety  techno logy. The \\nworldwide automotive industry has recognized driver perfor mance (e.g., error and choice)  as a \\nkey factor that impacts  safety and has begun to introduce systems that complement the driver in \\nterms of enhanced perception with 360 -degree  vehicle views and rear  video systems. S ystems \\nthat monitor the operational environment seeking to enhance driver detection and response , such \\nas forward c ollision w arning and even assisted automation such as l ane k eeping a ssist, are \\nbecoming ubiquitous in newer model  vehicles . Additionally, 20 automakers have committed to \\nmaking a utomatic e mergency braking a standard feature in new vehicles by  2022 (IIHS, 2016) . \\nRecently, research activities by several companies to develop automated drivin g systems that can \\nperform certain driving functions automatically have captured the N ation\\'s attention.  ADS  have \\nbeen the subject of multiple congressional hearings  and the public has provided numerous \\nresponses to NHTSA’s Federal Automated Vehicles Policy ( Howe, Xu, Hoover, Elsasser, & \\nBarickman, 2016) , including over 1,100 responses from industry participants, State  and \\nmunicipal transportation agencies, policy groups, and citizens (Kyrouz, 2017) . The United States \\nDepartment of Transportation (USDOT)  and NHTSA recently released an update to their Federal  \\nguidance for ADS  that focused on the ir development and safe deployment and operation. \\nNHTSA also continues  to advance its ADS  research . The research project summarized in this \\nreport  sought  to analyze aspects of ADS  testing and develop examples of tests and evaluation \\nmethods for specific ADS  features. A sample testing framework was developed that could \\nfurther support the goals of improving safety for all use rs of the transportation network. \\nThis project was accomplished in cooperation and consultation with NHTSA by completing the \\nseven tasks described below. \\nTask 1: Revised Technical Work Plan  \\nThis work focused on review ing, revis ing, and finaliz ing the work activities for the project. T he \\nproject ’s objectives, planned course of actions, milestones and deliverables, and any concerns2 with the proposed approach were discussed with NHTSA staff . The work plan was updated \\nbased on feedback during a projec t team meeting  with NHTSA.  \\nTask 2: Identification of Sample Concept ADS  Functions  \\nThe goal of this work was to identify sample concept ADS  functions based on specific \\nautomation technologies. The analysis and results of this task are presented in Chapter 2. \\nTechnologies of interest focused on light -duty vehicle functions that fell within L3  through L 5 of \\nthe SAE International  levels of automation  (SAE International, 2016) .  The functions were \\nidentified based on prototype vehicles  and conceptual systems. A  literature review  which  \\nincluded popular media, press releases, technical journals, and conference proceedings was performed . From this review, concept ADS  being developed or proposed by original equipment \\nmanufacturers, suppliers, technology companies, and other organizations  were identified . The \\nidentified functions were categorized into a set of generic names to be u sed throughout the \\nsubsequent tasks. The terminology was modified to ADS  “features”  (as opposed to “ functions ”) \\nto be more in line with the standardization community’s language . \\nTwenty -four conceptual features were identified , and although a thorough searc h was conducted, \\nthe list is not exhaustive. The identified features were grouped into seven generic categories. \\nAlthough all generic ADS features are considered in subsequent tasks, a deeper analysis was conducted on three select features.  \\nTask 3: Identification of the Operational Design Domain  \\nThis work focused on identifying  the ODD for all conceptual ADS . The analysis and results of \\nthis task are presented in Chapter 3. The ODD describes the specific operating domain s in which \\nthe ADS  is designed to function. The ODD will likely vary for each ADS  feature on a vehicle, \\nand specifies when that feature is intended and able to operate with respect to r oadway types, \\nspeed range, lighting conditions, weather conditions, and other operational constraints. The ODD \\nis specified by the technology developer, and the ADS  should be able to identify whether it is \\noperating within or outside of that ODD.  \\nA literature review was conducted  for all  seven generic ADS  features to determine the  attributes \\nthat define the ODD. Three of the features were selected to further refine the ODD analysis. The \\nreview included popular media, press releases, technical journals, videos , and conference \\nproceedings. The team then defined a  hierarchical  ODD taxonomy that could be used by \\ngovernment and industry to discuss ADS .  \\nSome of the challenges associated with ODD elements include their variability (e.g., rain droplet \\nsizes can vary greatly: light rain, moderate rain, heavy rain), as well as identifying or defining \\ntheir boundaries. The work performed in this task to identify the ODD la id the foundation for \\nsubsequent tasks.3 Task 4: Delineation of Object a nd Event Detection and Response Capabilities   \\nThis work sought  to identify OEDR capabilities for the three selected ADS  features that will \\nenable them to function safely within their specified ODDs. The analysis and results of this task \\nare presented in Chapter 4. OEDR refers to “the subtasks of the dynamic driving task ( DDT ) that \\ninclude monitoring the driving environment  (detecting, recognizing, and classifying objects and \\nevents and preparing to respond as needed) and executing an appropriate response to such objects and events (i.e., as needed to complete the DDT and/or DDT fallback  (SAE International, \\n2016) .  \\nA notional concept of operations – called ConOps  -- was  developed for each of the three selected \\nADS  features. These served as a basis for perform ing an evaluation of the normal driving \\nscenarios each ADS  feature may encounter, including expected hazards (e.g., other vehicles, \\npedestrians) and sporadic/fluctuating events (e.g., emergency vehicles, construction zones). Baseline ODDs were defined for each of the selected features to frame this analysis. The baseline \\nODDs were developed by the research team by id entifying relevant ODD attributes within the \\nConOps for each selected feature. These baselines were necessary because of the potential variability of ODDs for a given feature, as defined by their developer s. These baseline ODDs \\nand scenario analyses helped  identify important OEDR functional capabilities.  \\nTask 5: Development of Preliminary  Tests and/or Evaluation Methods  \\nThis work sought  to develop examples of preliminary tests and evaluation methods that could be \\nused for  ADS . The analysis and results of this task are presented in Chapter 5. E ngineering \\njudgments from previous test development  experience, functional requirements, and use cases \\nwere used to identify test scenarios and preliminary procedures. These scenarios and procedures built upon the identified ADS features, ODDs, and OEDR capabilities.  \\nExisting test methods and tools were identified and evaluated to formulate an appropriate, \\ncomprehens ive testing architecture. A test scenario framework was then identified and developed \\nthat fit flexibly within the test architecture. The framework can be viewed as a multidimensional test matrix, with the dimensions encapsulating the principal elements  from the other tasks  \\n(Feature, ODD, OEDR, Failure Modes ). Preliminary test procedures  — including information on \\npotential test personnel, test facilities, test execution, data collection, and performance metrics, among other things  — were developed for a sa mpling of these scenarios . No physical testing was \\nconducted as part of this project.  \\nKey challenges related to testing and evaluating ADS  were also identified . These challenges \\nwere associated with the technology itself as well as test execution.  \\nTask 6: Assessment of Fail -Operational/Fail -Safe Mechanisms  \\nThe goal of this work was to perform an assessment of fail -operational and fail -safe mechanisms \\nfor ADS . The analysis and results of this task are presented in Chapter 6. FO  and FS mechanisms4 are used when an ADS  fails , resulting  in unintended function ality or behavi or. Designing, \\ntesting, and validating these mechanisms ensures that an ADS  can achieve a minimal risk \\noperating condition that removes the vehicle and its occupants from harm’s way in the event of a \\nfailure. For some features, the minimal risk condition may be to transition control back to a fallback -ready user; however, in othe r cases the ADS  feature itself achieves  that condition.  \\nA high- level system failure mode and effects analysis for a representative ADS  was performed . \\nThis representative ADS  is described by a functional architecture under development by SAE \\nInternational (Underwood, 2016) . This analysis notionally identified potential ADS  failure \\nmodes  and their potential causes and effects. These failure modes were then mapped back to the \\nselected ADS  features. The FMEA focused on subsystems an d processes related to the ADS , and \\nthe identified failure modes could largely be attributed to lack of information (e.g., resulting from a hardware failure) or poor/inadequate information (e.g., resulting from system latency). These potential failures cou ld have significant impacts, ultimately resulting in collisions that \\ncould damage the vehicle or harm its occupants  or other roadway users .  \\nFailure mitigation strategies, including both FO  and FS techniques , were identified and analyzed. \\nFS techniques are used when the ADS  cannot continue to function, while FO  techniques allow  \\nthe ADS  to continue to function, although potentially at a reduced capacity or for an abbreviated \\nperiod of time . The appropriate failure mitigation strategy is highly  dependent on the nature of \\nthe failure and the initial conditions whe n the failure occurs. As such, a hierarchy of the \\ntechniques listed above may be  appropriate. H ealth -monitoring capabilities were also identified \\nas being important .  \\nTask 7: Final Repor t \\nThis task  involved combining the results from the preceding tasks into a cohesive final report. \\nThe current report is the product of that effort.  \\nThis project contributes to the body of knowledge for ADS safety performance assessment, which could also pl ay a role in system validation and verification . V&V includes methods and \\ntools for determining whether design specifications and customer needs associated with the automated driving function have been met. Testing  is critical in the development of an ADS, \\nespecially as it relates to safety performance and functionality. Testing  occurs from the system -\\nwide level all the way down to the individual unit level (e.g., camera sensor). This work focuses mostly on developi ng test cases that evaluate system -level functionality and capabilities (e.g., \\nstay within a lane and stop at a stop sign). \\nFederal Automated Vehicles Policy  \\nAs mentioned above , NHTSA released the Federal Automated Vehicles Policy in 2016 (NHTSA, \\n2016a) , which present s several  key factors  that play into the safe development and deployment \\nof ADS , namely the following.5 • Vehicle Performance Guidance  \\n• Model State Policy  \\n• NHTSA’s Current Regulatory Tools  \\n• New Tools and Authorities  \\nIn 2017 NHTSA released an updated  version of the 2016 FAVP  policy titled Automated Driving \\nSystems 2.0: A Vision for Safety  (NHTSA, 2017a) , which responded to the public comments \\nreceived while maintaining the  overall goal of safe development and deployment of ADS . \\nNHTSA plans to regularly  update its guidance  as the technology and deployment landscape \\nevolve. Most of  the research described in this report was conducted before ADS 2.0 was \\npublished, and therefore relies on the information contained in the 2016 FAVP document . The \\ndocument ’s vehicle performance guidance section provides recommended best practices and \\nexpectations for the design, development, and testing stages for ADS . It applies to any entity \\nperforming activities related to ADS  in any of those stages. It provides guidance on a number of \\nADS safety elements, including human- machine interfaces , vehicle cybersecurity, and \\ncrashworthiness, among others. It also provides guidance on four other areas that are specific to \\neach individual ADS . \\n• ODD  \\n• OEDR  \\n• Fallback MRC  \\n• Validation Methods  \\nThese four areas factor prominently in this research and in this report. The ODD, which is \\nspecified by the manufacturer or developing entity, describes the specific operating domains and conditions in which the system can  function. Chapter 3 provides a thorough discussion of the \\nimportance and expansiveness of potential ODDs and  presents a notional taxonomy for major \\nODD categories. OEDR refers to the subtasks of the DDT that include monitoring the driving \\nenvironment (detecting, recognizing, and classifying objects and events and preparing to respond as needed) and executing an appropriate response to such objects and events (i.e., as needed to complete the DDT and/or DDT fallback ) (SAE International, 2016) . Chapter 4 presents an \\nanalysis of OEDR and identifies specific OEDR capabilities that are applicable to many  ADS  \\nwithin their specified ODDs. It is important for ADS  to have a fallback strategy and be able to \\nexecute that strategy when things go wrong. The MRC is a  state that places  the vehicle and its \\noccupants out of harm’s way, to the best extent possible.  Chapter 6 provide s an analysis of \\npotential failure modes for ADS  and the potential mitigation strategies that ADS  may be able to \\nimplement to achieve that MRC. Finally, existing testing and validation tools and methods may \\nbe insufficient to assess the safe operation of ADS , considering their added complexity and \\ncapabilities compared to traditional vehicles. The guidance suggests that developers should determine the appropriate testing methods and document their efforts and results to demonst rate \\nthat their systems are meeting performance expectations. Chapter 5  presents a discussion on \\npotential methods for testing and validating ADS  that seeks to assess safe performance and6 identify performance boundaries. The chapter also identifies several key challenges associated \\nwith testing ADS .  \\nStakeholder Engagement  \\nRelevant stakeholders expressed significant interest in this research project from an early stage. Therefore , a stakeholder working group was established to solicit  their feedback on the research \\nmaterials. The motivation for establishing this working group included incorporating expert perspectives to inform the project framework a nd provide input to conclusions . Multiple OEMs \\nand Tier 1 suppliers participated in the working group, as well as representatives from academia conducting research in ADS .  \\nOutreach and materials were planned for the early  research tasks , which, after revi ew by \\nNHTSA, were disseminated to the stakeholder s. Feedback provided by the stakeholder s was \\nreviewed  and facilitated follow -up discussions, as deemed necessary. Many of the stakeholders \\nhad multiple personnel reviewing the project materials. This include d personnel with policy and \\nstrategic planning expertise, in addition to personnel with technical expertise related to ADS . \\nHolistically, the stakeholder group provided a breadth of knowledge to comment on the issues evaluated  in this research.  Information shared by the stakeholders was treated as non -attributable  \\nas it was incorporated into the project and this report. While the stakeholders did not provide any proprietary information or data as part of the engagement, information was collected individually \\nand was not share d between stakeholders.   \\nIn addition to per -task engagement, which was  conducted largely  in a virtual  setting , an in-\\nperson workshop open to all stakeholders  was organized and held  near the end of the technical \\nportion of the research project . The workshop was held immediately after the conclusion of the \\nAutomated Vehicles Symposium\\n2 in San Francisco, California , in July 2017. The goals of the \\nworkshop included providing an interactive venue for sharing insights about the conce pts \\naddressed by the research , providing  a summary rev iew of the project tasks , and offering an \\nopportunity to work toward consensus on some of  the elements of those tasks. Ten experts from \\nthe stakeholder working group participated in the workshop, along with five members of the research team . The experts agreed on the importance of the research  and the potential need to \\nconsider a  common set of test scenarios. They  also provided many suggestions on the content of \\nthe resulting task materials. Th e suggestions and feedback are incorporated into the discussions \\nin the following chapters . \\n                                                 \\n2 www .automatedvehiclessymposium.org/home7 CHAPTER 2.  AUTOMATED DRIVING SYSTEM  FEATURES  \\nOVERVIEW  \\nThis chapter describes the identification of  sample concept ADS features that have been \\nproposed for deployment. This analysis is focused on SAE Levels 3 -5 ADS , such as  Google’s \\nself-driving car project (i.e. , Waymo) , and others like it that focus on next -generation \\nautomation. This step is critical because the sample concept ADS features are used  to identify \\nODDs and OEDRs, develop preliminary tests and/or evaluation methods, and assess FS and FO \\nmechanisms, which form a foundation to begin considering validation and verification \\napproaches for ADS . \\nThis chapter is organized i nto four sections: the approach to identifying concept ADS features, a \\nframework for defining concept ADS features (including behaviors), a list and description of concept ADS features, and a set of generic ADS feature categories used throughout the report . \\nAPPROACH  \\nA four -stage approach was followed to identify ADS features: ( 1) review the literature, ( 2) \\ndefine a framework for discussing ADS features, ( 3) define features and behaviors, and (4) \\ncategorize the features. To guide later analysis, priority ADS  features on which to focus  were \\nidentified .  \\nTo support the identification of ADS features, a framework for describing ADS  throughout the \\nproject  was established and implemented . As part of this effort, industry stakeholders  were \\nengaged. The stages invol ved in ADS feature identification were as follows . \\n• Review the literature, including popular media, press releases, technical journals, and \\nconference proceedings,  to identify concept ADS features proposed by major OEMs, \\ntechnology companies, suppliers, and cities.  \\n• Define a framework for describing ADS features, including a functional architecture, \\nbehaviors, level of automation, ODD, and OEDR.  \\n• Define ADS features, including operational concepts and behaviors; further \\ndescription of the ADS features can be f ound in subsequent chapters (e.g., ODD in \\nChapter 3).  \\n• Categorize ADS features into a set of generic ADS features.  \\nOver 50 literature sources were reviewed , including OEM websites, press releases of vehicles \\nbeing tested in specific domains, NHTSA pre -crash  scenario analysis (Najm, Smith, & \\nYanagisawa, 2007) , NHTSA’s Fiscal Year 2017 budget request (NHTSA, 2016b) , NHTSA L2 \\nand L3 Human Factors Concepts (Blanco et al., 2015) , Federal Highway Administration -\\nmanaged lane use cases (FHWA,  2008) , and technical and international publications, including \\nproceedings of the 2015 and 2016 Automated Vehicle s Symposium s and United Nations \\nEconomic Commission for Europe World Forum for Harmonization of Vehicle Regulations \\n(WP.29)  Automatically  Commanded Steering Function working group. Research sponsored by8 USDOT , such as the Crash Avoidance Metrics Partnership Automated Vehicle Research for \\nEnhanced Safety   (Christensen et al., 2015; NHTSA, 2016c ), which details functional \\ndescriptions for on-road driving automation levels, was also used. Figure 1 depicts the stages \\ninvolved in the ADS feature identification process. \\n \\nFigure 1. ADS Feature Selection Process  \\n \\nFRAMEWORK FOR DISCUS SING ADS FEATURES  \\nThe development of a framework for discussing ADS features began with defining the \\nterminology and a reference functional architecture. The term ADS “feature” was selected to be \\nused in place of “function” or “application” since it is the same term used by  OEMs to market a \\nvehicle’s capabilities. While these terms have been used interchangeably, using “feature” is most consistent with existing descriptions of vehicle functionality in the marketplace. Using “feature” minimizes confusion when examining propri etary ADS offerings from OEMs in the literature \\nreview, as well as for future stakeholder engagement efforts with OEMs.  \\nSAE  International’s On -Road Automated Driving activities  were used to develop a robust system \\nto describe each feature. SAE J3016 defines an ADS feature as “a driving automation system’s design- specific functionality  at a specific level of driving automation within a particular \\nOperational Design Domain .” Referring to this definition, each feature can be described  in terms \\nof the followin g.9 • Level of driving automation (using SAE  International ’s levels of driving automation)  \\n• Design -specific functionality, with a focus on the DDT , is defined in SAE J3016 as:  “All \\nof the real -time operational and tactical functions required to operate a vehicle in on -road \\ntraffic, excluding the strategic functions such as trip scheduling and selection of \\ndestinations and waypoints , and including without limitation  the followin g. \\n1. Lateral vehicle motion control via steering (operational)  \\n2. Longitudinal vehicle motion control via acceleration and deceleration (operational)  \\n3. Monitoring the driving environment via object and event detection, recognition, classification, and response pr eparation (operational and tactical)  \\n4. Object and event response execution (operational and tactical)  \\n5. Maneuver planning (tactical)  \\n6. Enhancing conspicuity via lighting, signaling and gesturing, etc. (tactical)  \\n• ODDs in which it operates   \\n• FS/FO capability  \\nPer SA E J3016, DDT elements 3 and 4 can be collectively referred to as OEDR and  are covered \\nin Chapter 4  of this report. The remaining DDT elements 1, 2, 5, and 6 are dis cussed in this \\nchapter, and are loosely described as “tactical and operational maneuvers.” That term would \\ntypically include aspects of OEDR, but OEDR is covered in Chapter 4. It should be noted that nomenclature for many of these terms, such as behaviors, maneuvers, ODD, OEDR, and FS/FO can vary in their use throughout the literature in the context of ADS. There are ongoing efforts at SAE to clarify and standardize these terms. F or example, the SAE ORAD Committee Task Force \\non Behaviors and Maneuvers is in the process of developing an information report to describe several of these terms and supporting taxonomies. Without an existing common framework, this report has  been kept as consistent as possible with existing SAE efforts, but does consider other \\nliterature sources. M ore information on strategic, tactical, and operational levels of control  will \\nbe provided below. \\nLevels of Driving Automation  \\nSAE  International, the Bundesanstalt für Straßenwesen , Organisation Internationale des \\nConstructeurs d’Automobiles , and UNECE WP.29 have agreed upon common definitions  for \\nlevels of driving automation, which are described in SAE J3016. SAE J3016 provides definitions \\nfor ke y terms, including MRC and ODD. It should be noted that J3016 was revised in Sept ember  \\n2016, and now  a joint SAE -International Organization for Standardization task force  has been10 formed for future updates . Table 1 shows the SAE J3016 levels of driving automation for on-\\nroad vehicles. USDOT  adopted these levels of driving automation into its p olicy guidance to \\nestablish standardization to aid in clarity and c onsistency .  \\nTable 1. Summary of Levels of Driving Automation   Level  Name  Narrative Definition  DDT - \\nSustained \\nlateral and \\nlongitudinal \\nvehicle motion \\ncontrol  DDT - \\nOEDR  DDT \\nfallback  ODD  \\nDriver performs part or all of the DDT          \\n0 No Driving \\nAutomation  The performance by the driver  of the entire DDT , \\neven when enhanced by active safety systems . Driver  Driver  Driver  n/a \\n1 Driver \\nAssistance  The sustained  and ODD -specific execution by a \\ndriving automation system  of either the lateral  or \\nthe longitudinal vehicle motion control  subtask of \\nthe DDT (but not both simultaneously) with the \\nexpectation that the driver  performs the remainder \\nof the DDT . Driver and \\nSystem  Driver  Driver  Limited  \\n2 Partial \\nDriving \\nAutomation  The sustained  and ODD -specific  execution by a \\ndriving automation system  of both the lateral  or \\nthe longitudinal vehicle motion control  subtask of \\nthe DDT  with the expectation that the driver  \\ncompletes the OEDR  subtask and supervises the \\ndriving automation system . System  Driver  Driver  Limited  \\nADS (\"System\") performs the entire DDT (while engaged)          \\n3 Conditional \\nDriving \\nAutomation  The sustained  and ODD -specific  performance by an \\nADS of the entire DDT with the expectation that \\nthe DDT fallback -ready user is receptive  to ADS-\\nissued requests to intervene , as well as to DDT \\nperformance- relevant system failures  in other \\nvehicle systems , and will respond appropriately . System  System  Fallback -\\nready user \\n(becomes \\nthe driver \\nduring \\nfallback)  Limited  \\n4 High Driving \\nAutomation  The sustained  and ODD -specific  performance by an \\nADS  of the entire DDT  and DDT fallback  without \\nany expectation that a user  will respond to a \\nrequest to intervene.  System  System  System  Limited  \\n5 Full Driving \\nAutomation  The sustained  and unconditional (i.e., not ODD -\\nspecific ) performance by an ADS of the entire DDT  \\nand DDT fallback  without any expectation that a \\nuser  will respond to a request to intervene . System  System  System  Unlimited  \\n \\n \\nDesign Specific Functionality  \\nTo best define the identified functions, a framework that references a functional system \\narchitecture  was established and implemented . SAE  International  ORAD’s J3131 work on11 functional architecture informed the  approach. The draft J3131 functional architecture is shown \\nin Figure 2.  \\n \\nFigure 2. SAE International Autonomous Mode Functional Architecture Flow Diagram  \\n(Underwood, 2016)  \\n \\nThe SAE  International  draft functional architecture ( Figure 3 ) was adapted to describe system \\ncomponents  (i.e., sensors, environment [ ODD ], perception, plan, act, etc.) and their interact ions \\nin relation to the technical analysis in this project. The functional architecture is helpful in \\nstructuring a definition of specific embodiments of ADS features. This architecture depicts the \\norganization of vehicle software, electronics, and hardwar e, as well as the relationship to the \\nexternal environment.12  \\nFigure 3. Generalized Functional Architecture for ADS Features  \\nBehaviors can be used to help to define the functionality of each feature in terms of OEDR \\nbehaviors (described in Chapter 4) and other tactical and operational maneuvers  (described in  \\nthis chapter ). Behaviors may be distributed within a hierarchy  based on the duration of the \\nbehavior ( as shown in Figure 4; note: the durations shown are rough order -of-magnitude \\nestimates. ) This work focuse s on tactical and ope rational  behaviors in the 1-  to 10- s range, based \\non the logic that strategic /mission -level behaviors are not part of the DDT , and that active safety \\nis out of the scope of this work because it is  not specific to ADS .  \\n \\nFigure 4. ADS Task Decomposition Distributed by Temporal Levels of the Control System13 ADS Tactical and Operational Maneuvers  \\nThrough the literature review and analysis, a working list of tactical and operational maneuver s \\nrelated to ADS driving control  was created . \\n• Parking  – ADS comes to a complete stop within a vacant parking spot; may be further \\nqualified by parallel or perpendicular orientations, lot type (closed/open), initiation \\nconditions, etc.  \\n• Maintain Speed – ADS  maintains a safe speed set through longitudinal control with \\nacceptable following distances.  \\n• Car Following – ADS  identifies and follows a target vehicle at acceptable following \\ndistance while staying within a lane through longitudinal and lateral control . \\n• Lane Centering  – ADS stays within a lane through lateral control.  \\n• Lane Switching/Overtaking  – ADS  crosses lanes or overtakes an upcoming vehicle \\nbased on a projected path or hazard.  \\n• Enhancing Conspicuity – ADS  controls vehicle blinkers, headlights, horn, or other \\nmethods used to communicate with other drivers. \\n• Obstacle Avoidance  – ADS  identifies and responds to on- road hazards, such as \\npedestrians, debris, animals, etc.  \\n• Low -Speed Merge – ADS  merges into a lane below about 45 mph, for example from \\nan exit ramp, by identifying a vacant lane position and matching speed.  \\n• High -Speed Merge – ADS  merges into a lane above about 45 mph, for example from \\nan exit ramp, by identifying a vacant lane position and matching speed.  \\n• Navigate On/Off -Ramps – ADS  drives on on/off -ramps, which are typically one -\\nway, steeply curved, and banked road segments.  \\n• Right -of-Way  Decisions – ADS  obeys directional restrictions; for example, one -way \\nroads and actively managed lanes.  \\n• Follow Driving Laws  – ADS  obeys motor vehicl e codes and local ordinances; for \\nexample, following distances, speed limits, etc. This may include driving norms that vary by region as well.  \\n• Navigate Roundabouts – ADS  determines right -of-way, enters, navigates, and exits a \\nroundabout, and communicates w ith other road users as necessary.  \\n• Navigate Intersection –  ADS  determines right- of-way, enters, navigates, and exits \\nintersections, including signalized, stop signs, 4/3/2- ways, and communicates with \\nother road users as necessary; may include left or right  turns across oncoming traffic. \\n• Navigate Crosswalk – ADS  determines right -of-way, enters, navigates, and exits \\npedestrian crosswalks, and communicates with other road users as necessary.  \\n• Navigate Work Zone – ADS  determines right -of-way and traffic patterns , enters, \\nnavigates and exits work zone, and communicates with other road users as necessary.  \\n• N-Point Turn – ADS  makes a heading adjustment that involves  alternating between \\nforward and reverse movement and adjusting steering to reposition the vehicle within a tight space.  \\n• U-Turn  – ADS determines right- of-way, initiates, and completes a U -turn, and \\ncommunicates with other road users as necessary.14 • Route Planning – ADS  uses various information to define (and potentially update) a \\nroute network including road segments, turns, etc.  \\nTo serve as an example, Figure 5 displays some of the behaviors for L3 Nissan Piloted Drive .  \\n \\nFigure 5. Sample Capabilities for Nissan Piloted Drive  (Inside EVs, 2015)  \\nIDENTIFICATION OF CO NCEPT ADS FEATURES  \\nTwenty -four concept ADS features  were identified . \\n1. Audi Traffic Jam Pilot \\n2. Audi Highway Pilot  \\n3. Auro S elf-Driving Shuttle  \\n4. Baid u Automated TNC3\\n5. Bosch Valet Parking  \\n6. CityMobil2 Automated Shuttle  \\n7. Bosch Highway Pilot  \\n8. EZ10 Self -Driving Shuttle  \\n9. Ford Automat ed TNC \\n10. GM Cruise Automation TNC  \\n11. Google Car  \\n12. Honda Automated Drive  \\n                                                 \\n3 TNC: Transportation Network Company15 13. Mercedes Highway Pilot Truck  \\n14. Navya Arma Shuttle  \\n15. Nissan Autonomous Drive  \\n16. Olli Local Motors Shuttle  \\n17. Otto Trucking \\n18. Tesla Self -Drive  \\n19. Toyota Chauffeur  \\n20. Toyota Guardian  \\n21. Uber Automated TNC  \\n22. Varden Labs S elf-Driving Shuttles  \\n23. Volkswagen I.D. Pilot  \\n24. Volvo IntelliSafe Auto Pilot  \\nThese 24 features were categorized into the following seven generic categories.  \\n1. L3 Conditional Automated Traffic Jam Drive  \\n2. L3 Conditional Automated Highway Drive  \\n3. L4 Highly Automated Low Speed Shuttle  \\n4. L4 Highly Automated Valet Parking  \\n5. L4 Highly Automated Emergency Take -Over  \\n6. L4 Highly Automated Highway Drive  \\n7. L4 Highly Automated Vehicle/TNC  \\nTable 2 shows which ADS features belong to the seven generic categories.   \\nTable 2. ADS Features by Generic ADS Category \\nCategory  Generic ADS Feature  ADS Features  \\n1 L3 Conditional Automated Traffic Jam Drive  Audi Traffic Jam Pilot \\n2 L3 Conditional Automated Highway Drive  Mercedes Highway Pilot Truck  \\n3 L4 Highly Automated Low Speed Shuttle  Auro S elf-Driving Shuttle , \\nCityMobil2 Automated Shuttle , \\nEZ10 Self -Driving Shuttle , \\nNavya Arma Shuttle , Olli Local \\nMotors Shuttle , Varden Labs \\nSelf-Driving Shuttles  \\n4 L4 Highly Automated Valet Parking  Bosch Valet Parking  \\n5 L4 Highly Automated Emergency- Take Over  Toyota Guardian  \\n6 L4 Highly Automated Highway Drive  Audi Highway Pilot , Bosch \\nHighway Pilot , Otto Trucking16 7 L4 Highly Automated Vehicle/TNC  Baidu Automated TNC , GM \\nCruise Automation TNC , \\nWaymo Automated TNC, Honda \\nAutomated Drive , Nissan \\nAutonomous Drive , Tesla Self -\\nDrive , Uber Automated TNC, \\nVolkswagen I.D. Pilot , Volvo \\nIntellisafe Auto Pilot, Ford \\nAutomated TNC, Toyota \\nChauffeur  \\n \\nEach of the concept ADS features is described below, organized by generic ADS feature categories. \\nEach generic feature category is described in terms of ConOps  and enabling technology, and each \\nidentified concept ADS feature is described in terms of tactical maneuver behaviors, commercial availability, and level of automation. The analysis was based largely on the literature review . Due to \\nthe incompleteness of the publicly available information, engineering judgment was used in some cases to predict certain data. In these cases, a “?” is provided in the accompanying table instead of an “X.” \\nCategory 1, L3 Conditional Automated Traffic Jam Drive Feature  \\nL3 Traffic Jam Drive features autonomous travel for stop- and-go traffic. It allows the vehicle to act \\nwithout input from the human operator at slower speeds if  a preceding car can be followed. A human \\noperator is the fallback for the DDT. The Audi Traffic Jam Pilot  (Audi, 2015)  uses a daptive c ruise \\ncontrol and LKA to allow slow driving in traffic jams. The 2017 Audi A4 and Q7, which contain an \\nearly version of this feature  (SAE International L2) , follow  the vehicle ahead and automatically \\noperate the accelerator and brake within the limits of the system so the vehicle is kept in lane. T he car \\nsteers, accelerates, and brakes automatically, and allows the driver to take his/her hands off the \\nsteering wheel  in slow -moving traffic for 15 seconds at a time  (Jaynes, 2016) . The future  version of \\nthe feature is expected to achieve L3 driving automation, and to be  commercially available on the \\n2019 Audi A8.  \\nFord has announced that the  company is finalizing their own traffic jam assist; however, they have \\noffered no timeline for its  debut . The traffic jam assist will be an autopilot that combines ACC and \\nLKA, assisting the driver with steering, braking and acceleration (Ford Motor Company, 2015) .17 Table 3. L3 Conditional Automated Traffic Jam Drive Features  \\nADS Features  \\nand \\nTactical and Operational Maneuvers  \\n \\n(X = demonstrated,  \\n? = speculated)  \\nCommercially Available? (Y/N)  \\nLevel of Automation (SAE 1 -5) \\nParking  \\nMaintain Speed  \\nCar Following  \\nLane Centering  \\nLane Switching/Overtaking  \\nEnhancing Conspicuity  \\nMerge  \\nNavigate On/Off Ramps  \\nFollow Driving Laws  \\nNavigate Roundabouts  \\nNavigate Intersection  \\nNavigate Crosswalk  \\nNavigate Work Zone  \\nN-Point Turn  \\nU-Turn \\nRoute Planning  \\nAudi Traffic Jam Pilot (2019 ) N 3  X X X             \\n \\nCategory 2, L 3 Conditional Automated Highway Drive Feature  \\nL3 Highway Drive  allows the vehicle to act without input from the human operator on highways (e.g., \\nACC and close -headway platooning). The feature enables the vehicle to travel at a  desired speed and \\nadjust the speed based on the surrounding traffic. The system is also able to overtake slower vehicles \\nor merge at highway junctions.  \\nTable 4. L3 Conditional Automated Highway Drive Features  \\nADS Features  \\nand \\nTactical and Operational Maneuvers  \\n \\n(X = demonstrated,  \\n? = speculated)  \\nCommercially Available? (Y/N)  \\nLevel of Automation (SAE 1 -5) \\nParking  \\nMaintain Speed  \\nCar Following  \\nLane Centering  \\nLane Switching/Overtaking  \\nEnhancing Conspicuity  \\nMerge  \\nNavigate On/Off Ramps  \\nRight -of-Way Decisions  \\nFollow Driving Laws  \\nNavigate Roundabouts  \\nNavigate Intersection  \\nNavigate Crosswalk  \\nNavigate Work Zone  \\nN-Point Turn  \\nU-Turn  \\nRoute Planning  \\nMercedes Highway Pilot Truck (2020)  N 3?  X X X ?  ?   X        \\n \\nCategory 3, L4 Highly Automated Low -Speed Shuttle Feature  \\nL4 Highly Automated Low Speed Shuttle is an automated shuttle that drives along a predetermined route. The system does not need an onboard driver control interface and is limited to speeds below 25 mph. For example, Olli  (Local Motors, 2017)  is a self -driving electric vehicle that has been tested in \\nseveral locations in the U nited S tates and is currently deployed in Germany. Olli can be part of a fleet \\nmanagement system with a central operatio n center designed to solve the transportation needs of large \\ncampuses and municipalities. A smart phone application is available for users to find existing routes, share a ride, and input pick- up and drop- off locations for door -to-door service.18 CityMobil2 (CityMobil2, 2017)  piloted a platform for automated road transport systems, which was \\nimplemented in several urban environments across Europe. A large -scale demonstration in the Greek \\ncity of Trikala was completed in winter 201 5. A fleet of six Robosoft vehicles drove at a speed of \\nabout 12.5 mph along a 1.5- mile itinerary that was integrated into the main city road network. During \\nthe last large -scale demonstration, automated shuttles operated in conditions close to normal traf fic \\nconditions, operating along with other road users, including car s, pedestrians, and cyclists. Almost \\n1,490 trips were recorded during the demonstration period. During this time, the vehicles covered \\nmore than 3,500 km and transported more than 12,000 passengers in the city center.  \\nThe French manufacturer Navya Technologies SAS’s Arma (Navya, 2017) is a 100 -percent  electric, \\nintelligent, and autonomous shuttle at the service of mobility, launched in October 2015. French \\nspecialists spent 10 years of research to achieve L4 driving automation. The Navya Arma does not \\nrequire any driver or specific infrastructure, can avoid static and dynamic obstacles, and can transport up to 15 passengers and safely drive up to 28 mph. In terms of functional safety, the L 4 Highly \\nAutomated Shuttle Feature could address some of the safety concerns (i.e., human error and situational awareness) associated with driving 15 -passenger vehicles. Other safety concerns with vehicles of this \\nsize ( such as tire pressure)  could still pose a safety hazard if not checked regularly. Its batteries can be \\nrecharged by induction and can last from 5 to 13 hours, depending on the configuration and the traffic conditions.  \\nAnother French manufacturer, Easymile SAS,  (EasyMi le, 2017)  is a start- up specializing in providing \\nboth the software powering autonomous vehicles and last -mile smart mobility solutions. Its EZ10 is an \\nelectric shuttle dedicated to smart mobility designed to cover short distances and predefined route s in \\nmulti- use environments. EZ10 can operate in three modes, needs only light infrastructure to operate, \\nmeets smart transportation requirements , and has operational and top speeds of 12 mph and 25 mph, \\nrespectively . The shuttle service runs on virtual tr acks that can be easily configured to accommodate \\nsudden shifts in demand. The service operator can set up new timetables and create new virtual stops to facilitate the flow of traffic. Using  redundant embedded systems inspired by aeronautics, EZ10 \\nensures the safety of passengers and road users from road hazards and technical failures. Their hybrid \\nsensing approach combines shuttle localization through vision, laser, and differential GPS data. This approach ensures smooth operation irrespective of infrastr ucture constraints, visibility, and/or weather \\nconditions. Detection of static or moving objects and people relies on redundant perception systems. Following the detection of an object, the EZ10 adjust s its trajectory and speed, leading to obstacle \\navoidance. A “safety chain” as a stand -alone collision avoidance feature adds to vehicle and user \\nsafety. Additionally, fleet management software enables the remote and real -time monitoring and \\ncontrol of the fleet of EZ10 shuttles.19 Table 5. L4 Highly Automated Low Speed Shuttle Features  \\nADS Features  \\nand \\nTactical and Operational Maneuvers  \\n \\n(X = demonstrated,  \\n? = speculated)  \\nCommercially Available? (Y/N)  \\nLevel of Automation (SAE 1 -5) \\nParking  \\nMaintain Speed  \\nCar Following  \\nLane Centering  \\nLane Switching/Overtaking  \\nEnhancing Conspicuity  \\nMerge  \\nNavigate On/Off Ramps  \\nFollow Driving Laws  \\nNavigate Roundabouts  \\nNavigate Intersection  \\nNavigate Crosswalk  \\nNavigate Work Zone  \\nN-Point Turn  \\nU-Turn  \\nRoute Planning  \\nOlli Local Motors (Tampa, FL 2018)  Y 4 X X X X X X ?  X ? X ? ? X X X \\nCityMobil2 (demo in multiple European cities, 2014 -2016)  N 4 X X X X X X X  X X X X X X X X \\nNavya Arma Shuttle (France/ Switzerland)  Y 4 X X X X X X ?  X ? X ? ? X X X \\nAuro S elf-Driving Shuttle  N 4 X X X X X X ?  X ? X ? ? X X X \\nVarden Labs S elf-Driving Shuttles  N 4 X X X X X X ?  X ? X ? ? X X X \\nEZ10 S elf-Driving Shuttle  N 4 X X X X X X ?  X ? X ? ? X X X \\n \\nCategory 4, L4 Highly Automated Valet Parking Feature  \\nL4 Highly Automated Valet Parking involves a car, potentially unoccupied, that can find a parking \\nspot and park itself. Bosch’s Valet Parking feature is a future concept (release date unclear) offering a new laser technology that operates without the assistance of GPS signals. Drivers drop the vehicle off at a design ated area near a parking garage entrance and pick it up at a designated area (Bosch, 2017) . \\nThis feature combines a variety of different connected and automated parking solutions being developed by Bosch. \\nTable 6. L4 Highly Automated Urban Valet Parking Features  \\nADS Features  \\nand \\nTactical and Operational \\nManeuvers  \\n \\n(X = demonstrated,  \\n? = speculated)  \\nCommercially Available? (Y/N)  \\nLevel of Automation (SAE 1 -5) \\nParking \\nMaintain Speed  \\nCar Following  \\nLane Centering  \\nLane Switching/Overtaking \\nEnhancing Conspicuity  \\nMerge  \\nNavigate On/Off Ramps  \\nFollow Driving Laws  \\nNavigate Roundabouts  \\nNavigate Intersection  \\nNavigate Crosswalk  \\nNavigate Work Zone  \\nN-Point Turn  \\nU-Turn  \\nRoute Planning  \\nBosch Valet Parking (2020)  N 4 X X ? ?  X   ?  ? ?  ? ? X20 Category 5, L4 Highly Automated Emergency Takeover  \\nIn the event a driver is in impending danger , Emergency Takeover assumes control of the vehicle and \\nguides it to a safe stop. Cameras inside the car track the driver’s head movement, while software uses \\nsensor data to estimate when a person needs help spotting or avoiding a potentially dangerous \\nsituation. Toyota’s Guardian system  is distinct from other ADS features and  operates in parallel with a \\nhuman rather than in series  (Goreham, 2017) . The system is designed to reduce complications of a \\nhandoff between the car and human driver, since the driver is expected to maintain control at all time s. \\nTable 7. L4 Highly Automated Emergency Takeover Featu res \\nADS Features  \\nand \\nTactical and Operational \\nManeuvers  \\n \\n(X = demonstrated,  \\n? = speculated)  \\nCommercially Available? (Y/N)  \\nLevel of Automation (SAE 1 -5) \\nParking  \\nMaintain Speed  \\nCar Following  \\nLane Centering  \\nLane Switching/ Overtaking  \\nEnhancing Conspicuity  \\nMerge  \\nNavigate On/Off Ramps  \\nFollow Driving Laws  \\nNavigate Roundabouts  \\nNavigate Intersection  \\nNavigate Crosswalk  \\nNavigate Work Zone  \\nN-Point Turn  \\nU-Turn  \\nRoute Planning  \\nToyota Guardian  N 4  X X X X X  X X        \\n \\nCategory 6, L4 Highly Automated Highway Drive Feature  \\nThe L4 Highway Drive system handles the entire DDT on a highway route, allowing the passenger to \\nengage in other tasks; the system is responsible for the fallback performance of DDT.  \\nBosch has publicly outlined its concept for its  Highway Pilot system that can assume all driving duties \\non open highways, from entrance ramp to exit ramp. According to Bosch, emerging technology will be \\naided by vehicle -to-vehicle and vehicle -to-infrastructure communication. Bosch expects a fully self -\\ndriving Highway P ilot by 2020 (Stoklosa, 2016) . Otto demonstrated a highly automated truck (Barber, \\n2016)  in 2016 in coordination with the Colorado Department of Transportation that was intended as an \\nSAE Internation al L4 system operating on highways.21 Table 8. L4 Highly Automated Highway Drive Features  \\nADS Features  \\nand \\nTactical and Operational Maneuvers  \\n \\n(X = demonstrated,  \\n? = speculated)  \\nCommercially Available? (Y/N)  \\nLevel of Automation (SAE 1-5) \\nParking \\nMaintain Speed  \\nCar Following  \\nLane Centering  \\nLane Switching/Overtaking \\nEnhancing Conspicuity  \\nMerge  \\nNavigate On/Off Ramps  \\nFollow Driving Laws  \\nNavigate Roundabouts  \\nNavigate Intersection  \\nNavigate Crosswalk  \\nNavigate Work Zone  \\nN-Point Turn  \\nU-Turn  \\nRoute Planning  \\nAudi Highway Pilot  N 4  X X X X ? X  ?       X \\nBosch Highway Pilot (2020)  N 4   X X X X ? X   ?             X \\nOtto Trucking (demonstration 2016)  N 4   X X X X ? X   ?             X \\n \\nCategory 7, L4 Highly Automated Vehicle/Transportation  Network Company (TNC) Feature  \\nL4 Highly Automated Vehicle/TNC enables the vehicle to pick up passengers or goods and drive to a \\ndestination without the need for an onboard driver. This feature may operate within a broad ODD , \\nwhich is explored in further detail in Chapter 3 . However, confirmation has not yet been provided that \\nthese features will operate in all ODDs, and thus they are categorized as L4 as opposed to full driving automation (L5). For example, these vehicle fleets may initially be limited to the cities in which they are tested. OEMs developing this technology have stated that they intend to pursue full autonomy. This feature could become commercially available as soon as 2020. Examples of this feature include the Google Car  (Waymo, 2017a) , Tesla Self -Drive  (Tesla, 2017) , Volkswagen I.D. Pilot Mode  \\n(Nishimo to, 2016) , Volvo IntelliSafe Auto Pilot (Volvo, 2017) , and Nissan Autonomous Drive  \\n(Nissan, 2017) .22 Table 9. L4 Highly Automated Vehicle/TNC Features  \\nADS Features  \\nand \\nTactical and Opera tional Maneuvers  \\n \\n(X = demonstrated,  \\n? = speculated)  \\nCommercially Available? (Y/N)  \\nLevel of Automation (SAE 1 -5) \\nParking  \\nMaintain Speed  \\nCar Following  \\nLane Centering  \\nLane Switching/Overtaking  \\nEnhancing Conspicuity  \\nMerge  \\nNavigate On/Off Ramps  \\nFollow Driving Laws  \\nNavigate Roundabouts  \\nNavigate Intersection  \\nNavigate Crosswalk  \\nNavigate Work Zone  \\nN-Point Turn  \\nU-Turn  \\nRoute Planning  \\nWaymo Automated TNC  N 4 X X X X X X X X X X X X X X X X \\nTesla Self -Drive  N 4 X X X X X X X X X X X X X X X X \\nVolkswagen I.D. Pilot  N 4? X X X X X X X X X X X X X X X X \\nVolvo IntelliSafe Auto Pilot  N 4 X X X X X X X X X X X X X X X X \\nNissan Autonomous Drive (2020)  N 4? X X X X X X X X X X X X X X X X \\nGM Cruise Automation  N 4 X X X X X X X X X X X X X X X X \\nUber Automated TNC  N 4 X X X X X X X X X X X X X X X X \\nHonda Automated Drive (2020)  N 4 X X X X X X X X X X X X X X X X \\nFord Automated TNC (2022)  N 4 X X X X X X X X X X X X X X X X \\nBaidu Automated TNC  N 4 X X X X X X X X X X X X X X X X \\nToyota Chauffeur  N 4 X X X X X X X X X X X X X X X X \\n \\nSummary of Generic ADS Features \\nTable 10 compares the generic ADS features. The tactical maneuver behaviors exhibited by each \\nfeature vary as a function of where and how they are intended to operate. Having more tactical \\nmaneuver be haviors does not necessarily indicate complexity. For example, low -speed shuttles may \\nexhibit most of the tactical maneuver behaviors, but their ODD is limited by speed and reduces the complexity of the technical problem, thus enabling near -term deployment .23 Table 10. Summary of Generic ADS Features  \\nGeneric ADS Features  \\nand \\nTactical and Operational Maneuvers  \\n(Summary)  \\n \\n(X = demonstrated,  \\n? = speculated)  \\nCommercially Available? (Y/N)  \\nLevel of Automation (SAE 1 -5) \\nParking  \\nMaintain Speed  \\nCar Following  \\nLane Centering  \\nLane Switching/Overtaking  \\nEnhancing Conspicuity  \\nMerge  \\nNavigate On/Off Ramps  \\nFollow Driving Laws  \\nNavigate Roundabouts  \\nNavigate Intersection  \\nNavigate Crosswalk  \\nNavigate Work Zone  \\nN-Point Turn  \\nU-Turn \\nRoute Planning  \\nL3 Conditional Automated Traffic Jam Drive (2018)  N 3  X X X             \\nL3 Conditional Automated Highway Drive (2020)  N 3  X X X X X X  X       X \\nL4 Highly Automated Low Speed Shuttle ( 2018)  Y 4 X X X X X X X  X X X X ? X X X \\nL4 Highly Automated Valet Parking (2020)  N 4 X X ? ?  X   ?  ? ?  ? ? X \\nL4 Highly Automated Highway Drive (2020)  N 4  X X X X ? X  ?       X \\nL4 Highly Automated Emergency Take -Over (?) N 4  X X X X X  X X        \\nL4 Highly Automated Vehicle/TNC (2020)  N 4 X X X X X X X X X X X X X X X X \\n \\nSUMMARY \\nThis chapter identified concept ADS features and illustrated how ADS functionality is emerging. \\nSpecifically, it described functionality and proposed timelines for commercial deployment across the \\ndifferent SAE International levels of driving automation. There is no clear correlation between level of \\ndriving automation and the timeline for commercial deployment. For L 3 systems, conditional \\nautomated traffic jam drive is expected in 2018, while conditional automat ed highway drive is not \\nexpected until 2020. For L4 systems, highly automated low speed shuttles are expected in 2018, and \\nother features are slated for 2020. A  figure showing ADS deployment timelines from SAE J3016 is \\nreproduced in F igure 6.24  \\n \\nFigure 6. ADS Feature Timeline by Level of Driving Automation  (SAE International, 2016)  \\n  \\nThe ADS features described in this chapter provide the basis for identifying ODD  attributes  in Chapter \\n3, OEDR capabilities in Chapter 4, test cases in Chapter 5, and FS/FO mechanisms in Chapter 6. \\nOperational descriptions of the features provide insights into where and when an ADS can operate. \\nThe tactical maneuver behaviors describe the functionality that test cases will need to evaluate. The generic names provide a simple and consistent naming system that is referenced throughout to describe concept ADS features.25 CHAPTER 3.  OPERATIONAL DESIGN DOMAIN  \\nOVERVIEW  \\nThis chapter describes the identification of attributes that can be used to define the ODDs for \\nADS . An ODD describes the specific operating domains in which an ADS feature is designed to \\nfunction with respect to roadway types, speed range, lighting conditions (day and/or night), weather conditions, and other operations  constraints . ODD will likely vary  for each ADS feature, \\neven if there is more than one ADS feature on a vehicle . The testing  framework presented in this \\nreport considers the potential range of ODDs and how ODDs factor into developing potential test cases.  \\nAPPROACH  \\nA three -stage approach  was taken to define the ODDs . \\n1. Review the literature, including popular media, press releases, technical journals, and \\nconference proceedings to identify key concepts, enumerate potential ODD characteristics, and examine approaches to ODD in other industries.  \\n2. Define and categorize ODD into a taxonomy that can be used by DOTs and industry to discuss ADS . \\n3. Describe ODDs in which concept ADS features may operate based on literature review and engineering judgment. \\nOver 50 literature sources were reviewed , includi ng OEM websites, press releases, USDOT  \\ndocuments, including NHTSA pre -crash scenario analysis and FHWA managed lane use case, as \\nwell as technical and international publications, including proceedings of the 2015 and 2016 \\nautomated vehicles  symposium s. Add itionally, the NHTSA fiscal year 2017 Budget Request to \\nCongressional Appropriations Committees  (NHTSA, 2016b)  identifies several ADS use cases \\nthat were considered when defining the ODD for this analysis. It should be noted that given the emerging and highly competitive nature of ADS technology, it is inherently difficult to obtain explicit and complete information about the intended ODD of a n ADS feature. In the absence of \\ninformation about an ODD, engineering judgement was used at times to define the ODD \\ntaxonomy and identify the ODD for concept ADS feature s.26  \\n Figure 7. The ODD Defini ng Process  \\nCertain pieces of information in the literature and media were particularly helpful with ODD \\nidentification and taxonomy definition, including the following. \\n• Descriptions in the product literature  \\no In some cases, ODDs have been explicitly defined  in the product literature and \\nthrough prototype testing and deployment materials, especially roadway types and \\nspeeds.  \\n• Videos  \\no Videos provide visual documentation of vehicles being tested in specific domains (e.g., weather conditions, physical infrastructu re, shared road users, etc.), which \\nserves as the basis for inferring the potential ODDs for these ADS features.  \\no Videos range from official marketing material to product research and testing \\nvideos to independent videos of released products for many differ ent ADS \\nfeatures that are being tested or introduced by OEMs. \\n• Perception systems  \\no Sensor suites drive ODD boundaries and limitations (e.g., dusty conditions hinder cameras more than radar). The perceptions systems proposed for the different \\nADS features were considered when identifying ODDs.  \\n• Testimonials \\no Anecdotal reports provide insights into what features of the environment are important, especially reports of systems having trouble with specific ODDs, including poor lane markings, hill crests/curves, etc.27 • ODDs from other domains  \\no ODDs from other domains inform categorization and approach (e.g., aviation \\nincludes airspace classes and transitions, presence of ground crews, workload on operator, etc.). \\nInfluences for Defining the ODD Framework  \\nThe literature revealed several early efforts to define and frame ODDs. The concepts put forth \\nare not in complete agreement and take the form of everything from public policy to industry guidelines to research. This section discusses sources that were influential in adv ancing the \\nframework put forth in this report.  \\nAutomated Driving Systems 2.0 – A Vision for Safety   \\nThe USDOT  definition of ODD is given in Federal  guidance  and is adopted for the purposes of \\nthis report. The definition indicates that ODD should be identified by the manufacturer, and \\nincludes example ODD categories . \\nEntities are encouraged to define and document the Operational Design Domain (ODD) \\nfor each ADS av ailable on their vehicles  as tested or deployed for use on public \\nroadways, as well as document the process and procedure for assessment, testing, and validation of ADS functionality with the prescribed ODD.  \\nThe definition goes on to describe how the ODD’s  boundary influences ADS operation. \\nThe ODD would include the following information at a minimum to define each ADS’s capability limits/boundaries: Roadway types (interstate, local, etc.) on which the ADS is \\nintended to operate safely; Geographic area (cit y, mountain, desert, etc.); Speed range; \\nEnvironmental conditions in which the ADS will operate (weather, daytime/nighttime, \\netc.); and other domain constraints  (NHTSA, 2017a) .\\n \\n2016 SAE J3016  \\nSAE J3016 has been adopted by USDOT  and defines and describes O DDs. The concepts put \\nforth in J3016 are adopted in this research and are consistent with USDOT ’s policy. ODD is not \\nexplicitly related to level of driving automation, except that for L 5, the ODD is described as \\n“unlimited.”  \\nJ3016 provides the following definition of ODD : “The specific conditions under which a given \\ndriving automation system or feature thereof is designed to function, including, but not limited \\nto, driving modes.”  \\n J3016 also provides example categories (see Figure 8) . \\nAn ODD may include one or more driving modes. For example, a given ADS may be designed to operate a vehicle only on fully access -controlled freeways and in low -speed \\ntraffic, high -speed  traffic, or in both driving modes.\\n328  \\nFigure 8. ODD Relative to Levels (SAE International, 2016)  \\n \\nThere have been questions and critiques regarding J3016. For example, the National Society of \\nProfessio nal Engineers  (Austin, 2016)  commented that:  \\nThe operational design domains proposed in SAE J3016 are overly broad and do not \\nadequately reflect the myriad of subdomains a vehicle may be required to enter and exit in the course  of a single route within an overall domain ( e.g., toll roads).  \\nAnother question that has arisen is  whether  the concept of an “unlimited” ODD at L 5 should be \\ntaken to the extreme (e.g., whiteout snow conditions) or whether it is limited in practice (e.g., to \\nthe same level as a reasonable human driver) . SAE J3016 is currently working on an update to \\nthe document in conjunction with ISO that will clarify several points, including concepts that \\nrelate to ODDs.  \\nCalifornia Policy   \\nSimilar to USDOT  and SAE  International , California draft regulations  (CA DMV, 2017)  \\ndescribe a concept for ODD that defines the boundary between ADS  and human operation, and \\nstate that the ODD is to be specified by the manufacturer . \\n[The manufacturer] shal l identify in the application the operational design domain in \\nwhich the subject autonomous vehicles are designed to operate and certify that the \\nvehicles are designed to be incapable of operating in the autonomous mode in areas outside of the disclosed OD D.29 The policy goes on to note that ODD elements can be identified as subtractive:  \\n…identify any commonly occurring or restricted conditions including but not limited to: \\nsnow, fog, black ice, wet road surfaces, construction zones, and geo- fencing by locati on \\nor road type, under which the vehicles are either designed to be incapable of operating or unable to operate reliably in the autonomous mode and certify that the vehicles are designed to be incapable of operating in autonomous mode under those conditions.  \\nIt also discusses the relationship with local legal codes within the geographically defined ODD:  \\n…a reference to the ordinances or resolutions from local authorities that specifies the operational design domains within the jurisdiction of the local aut horities that the \\nvehicles may be operated. \\nIn support of the California policy, California PATH conducted an analysis  (University of \\nCalifornia PATH Program, 2016)\\n that gathered expert feedback on “areas of operation,” which \\nwere defined as Rural, Urban, and Freeway/ Highway. This classification scheme was found to be \\ntoo blunt and indiscriminate and was replaced by ODD. This analysis also identified the \\nchallenge of handling the wide range of environmental, weather, and lighti ng conditions, and \\nsuggested using a compl ementary functional safety plan to address difficult- to-quantify \\nscenarios.  \\nPEGASUS Project  \\nThe PEGASUS Project is aimed at “establishing generally accepted quality criteria, tools and methods, as well as scenarios and situations for the release of highly automated driving functions  \\n(Winner, Wachenfeld, & Junietz, 2016) .”\\n The effort is focused on highway driving, and the \\nPEGASUS research team has identified several elements of a scene that pertain to ODD, \\nincluding traffic infrastructure (e.g., lanes, regulations, geometry), environmental conditions (e.g., surface grip from wetness, light, sun, fog, sensor obstacles), and traffic  (Hungar, 2017) .\\n  \\nOthers Referenced  \\nWhile not central to this analysis, influences from other industries  were considered . These \\ninclude aviation and the Department of Defense.  \\nThe aviation industry manages operational domains for traffic in the national airspace and space flight. Airspace volumes are designated into several classes, which specify operational characteristics and procedures. To operate in certain airspace domains, airplanes may be required to have certain equipage (e.g., transponders), and pilots may need to follow certain procedures (e.g., instrumented flight rules versus visual flight rules). These operational domain designations are influenced by complexity of the airspace and potential risks. For automobiles, ODD is similarly influenced by complexity (e.g., speed, traffic level), risks, equipage (e.g., sensors), and procedures (e.g., toll lanes).30 NASA’s missions operate in a limited domain that help to constrain design; for example, \\nmissions that are restricted to specific geographic areas or types of objects that may be encountered  (Wang & Hussein, 2012) . For automated flight systems, there are certain domain \\nconsiderations, such as air traffic, hazardous weather, terrain, and other obstructions and safety maneuvers  (Hayhurst, Maddalon, Miner, DeWalt, & McCormick, 2006) .\\n  \\nThe DOD considers operating domains for the design and use of unmanned systems; for example, roadways, littoral areas, forested areas, and various operating speeds (National Research Council, 2005) . \\nGuiding Principles  \\nSeveral guiding principles were developed based on the literature to identify and characterize the \\nODDs:  \\n• Need for an ODD taxonomy – A large variety of ODD dimensions exist, and a \\nstructure is needed to organize categories and facilitate discussion of system requirements, capabilities, and testing. \\n• Account for variations in operational environments  – ODDs may vary in nature. \\nSome can be predetermined (e.g., roadway type), while othe rs change in time (e.g., \\ntraffic conditions). Some can be divided into discrete categories (e.g., signage), while others vary along a continuous scale and may be difficult to quantify (e.g., rain, light, fog). \\n• Define what constitutes “operational scenario”  – An operational scenario is \\ndescribed in part by a set of ODD characteristics that describe the environment in which the feature is designed to perform.  \\n• Identify ODD boundaries  – ODD defines where the ADS can and cannot operate. \\nODD limits may vary by sub- trip or operational scenario due to confounding variables \\n(e.g., weather and illumination), non -deterministic software, design and testing, etc.  \\n(Bojarski, et al., 2016)  \\n• Identify Current ODD State (Self- Awareness)  – An ADS fe ature should be able to \\nidentify whether it is within the ODD and detect and respond to system engagement and disengagement restrictions  (University of California PATH Program, 2016) . This \\nmay include identifying transitions be tween certain ODD states (e.g., roadway type).  \\nDefining an ODD Taxonomy \\nWhile the literature provided many examples of ODD elements, no classification framework was \\nidentified. This work takes an initial step towards developing a taxonomy to organize the m any \\nODD elements identified in research. This ODD taxonomy takes the form of a hierarchy of categories and subcategories, each with definitions and, where appropriate, gradations. This taxonomy is meant to be descriptive, not normative, as it is envisioned that these elements may \\nbe organized into several different groupings. The taxonomy offers a structured approach to organize and identify various ODDs for ADS features, especially when there are several different31 possible combinations. Figure 9 shows the broad range of top -level categories and immediate \\nsubcategories.  \\n \\nFigure 9. ODD Classification Framework With  Top-Level Categories and Immediate Subcategories  \\nThe hierarchy extends into multiple sublevels, as shown in Figure 10. The “Environmental \\nConditions”  category was divided into four subcategories: weather, illumination, particulate \\nmatter, and road weather. Weather is further subdivided into rain, temperature, wind, and snow. For this research project, it was helpful to further subdivide rain into grada tions to capture the \\ndata that were collected on ADS features. For example, some ADS features had been tested in light rain, while others had been tested in heavy rain. Although the application of this taxonomy has been useful in the context of this resear ch project, further research and stakeholder \\nengagement would be beneficial in refining and objectively quantifying the categories and gradations.32  \\nFigure 10. Example of Hierarchical Levels in the Environmental Conditions Category  \\n \\nODD CATEGORY DESCRIP TIONS  \\nPhysical Infrastructure  \\nPhysical infrastructure refers to facilities and systems that serve a country, city, or area and \\nenable its economy to function. Physical infrastructure is typically characterized by technical \\nstructures, such as roads, bridges, tunnels, water supply, sewers, electrical grids, \\ntelecommunications, etc., that are for the most part interrelated. ADS features may depend on \\nsuch infrastructure elements, which are a critical part of the ODD environment. Subcategories of the main physical infrastructure elements are listed below; illustrative photos are provided in Figure 11.  \\nRoadway Types   \\n• Divided highway, undivided highway, arterial, urban, rural, parking, multi- lane, single \\nlane, high -occupancy vehicle (HOV) lane, on/off ramps, emergency evacuation routes, \\none-way, turn- only lanes, private roads, reversible lanes, intersections (signaled, U -\\nturns, 4- way/2 -way stop, roundabout, merge lanes, turn- only lanes, crosswalk, toll \\nplaza, railroad crossing)  (FHWA, 2012) . \\nRoadway Surfaces   \\n• Asphalt, concrete, mixed, grating, brick, dirt, gravel, scraped road, partially occluded, \\nspeed bumps, potholes, grass  (Gibbons, 1999).33 Roadway Edges   \\n• Line markers, temporary line markers, shoulder (paved or gravel), shoulder (grass), \\nconcrete barriers, grating, rails, curb, cones  (Sage, 2016). \\nRoadway Geometry  \\n• Straightaways, curves, hills, lateral crests, corners (regular, blind corners), negative obstacles, lane width (Huang, 2010).  \\n \\nFigure 11. Examples of Physical Infrastructure Elements  \\n \\nOperati onal Constraints  \\nThere are several operational constraints that need to be considered when designing and testing \\nADS applications. These include elements such as dynamic changes in speed limits, traffic characteristics, construction, etc. For example, an A DS entering a school zone is subjected to \\nlower speed limits and must respond appropriately to ensure the safety of its passengers and other road users. Some examples of the operational constraints are listed below. Illustrative photos are provided in Figure 12.  \\nSpeed Limit   \\n• Minimum and maximum speed limit (absolute, relative to speed limit, relative to \\nsurrounding traffic)  (Elpern -Waxman, 2016).34 Traffic Conditions   \\n• Minimal traffic, normal traffic, bumper- to-bumper/rush -hour traffic, altered (accident, \\nemergency vehicle, construction, closed road, special event)  (University of California \\nPATH Program, 2016).  \\n \\nFigure 12. Examples of Operational Constraints  \\n \\nObjects  \\nFor an ADS to properly navigate within an ODD, it must detect and respond to certain objects, \\nwhich is referred to as OEDR. OEDR is the focus of Chapter 4, but is discussed here in the context of identifying objects that can reasonably be expected to exist within the ODD. For example, a pedestrian may be expected at an intersection but rarely  on a freeway. Examples of \\nobjects and descriptions ar e provided in the text below and in Figure 13.  \\nSignage   \\n• Signs (e.g., stop, yield, pedestrian, railroad, school zone, etc.), traffic signals (flashing, \\nschool zone, fire department  zone , etc. ), crosswalks, railroad crossing, stopped buses, \\nconstruction signage, first responder signals, distress signals, roadway user signals , \\nhand signals  (FHWA, 2012).35 Roadway Users   \\n• Vehicle types (cars, light trucks, large trucks, buses, motorcycles, wide- load, \\nemergency vehicles, construction equipment, horse -drawn carriages/buggies), stopped \\nvehicles, moving vehicles (manual, autonomous), pedestrians, cyclists (CA DMV, \\n2016). \\nNon-roadway User Obstacles/Objects  \\n• Animals (e.g., dogs, deer, etc.), shopping carts, debris (e.g., pieces of tire, trash, \\nladders), construction equipment, pedestrians, cyclists  \\n \\nFigure 13. Examples of Objects  \\n \\nEnvironmental Conditions  \\nEnvironmental conditions play a crucial role in the safe operation of a variety of ADS \\napplications, and pose one of the biggest challenges to deployment , particularly early \\ndeployment . The environment can impa ct visibility, sensor fidelity, vehicle maneuverability, and \\ncommunications systems. Today, ADS technologies are tested most often in clear , rather than \\nadverse,  weather conditions. On average, there are over 5.7 million vehicle crashes each year. \\nApproxim ately 22 percent of these crashes—nearly 1.3 million—are weather -related  (Erdman, \\n2015) . Weather -related crashes are defined as crashes that occur in adverse weather (i.e., rain, \\nsleet, snow, fog, severe crosswinds, or blowing snow/sand/debris) or on wet, snowy, or icy pavement. Weather acts through visibility impairments, precipitation, high winds, and temperature extremes to affect driver capabilities, vehicle performance (i.e., traction, stability,36 and maneuverability), pavem ent friction, roadway infrastructure, crash risk, traffic flow, and \\nagency productivity (FHWA, 2017a) . It is thus important to consider a variety of environmental \\nconditions as part of the ODD. A few of these conditions are described below, and examples are \\nshown in Figure 14.  \\nWeather   \\n• Wind, rain, snow, sleet, temperature  \\n• On freeways, light rain or snow can reduce average speed by 3 to 13 pe rcent. Heavy \\nrain can decrease average speed by 3 to 16 percent. In heavy snow, average freeway \\nspeeds can decline by 5 to 40 percent. Free- flow speed can be reduced by 2 to 13 \\npercent in light rain and by 6 to 17 percent in heavy rain. Snow can cause free -flow \\nspeed to decrease by 5 to 64 percent. Speed variance can fall by 25 percent during rain (FHWA, 2017c) . \\nWeather -induced Roadway Conditions  \\n• Standing water, flooded roadways, icy roads, snow on road \\n• Capacity reductions can be caused by lane submersion due to flooding and by lane \\nobstruction due to snow accumulation and wind- blown debris. Road closures and \\naccess restrictions due to hazardous conditions (e.g., large trucks in high winds) also \\ndecrease roadway capacity  (FHWA, 2017) . \\nParticulate Matter  \\n• Fog, smoke, smog, dust/dirt, mud \\n• Low visibility can cause speed reductions of 10 to 12 percent. Visibility distance is reduced by fog and heavy precipitation, as well as wind- blown snow, dust, and smoke. \\nLow-visibility conditions c ause increased speed variance, which increases crash risk. \\nEach year, over 38,700 vehicle crashes occur in fog. Over 600 people are killed, and more than 16,300 people are injured in these crashes annually (FHWA, 2017b) .  \\nIllum ination  \\n• Day (sun: overhead, back- lighting, and front -lighting), dawn, dusk, night, street lights, \\nheadlights (regular and high- beam), oncoming vehicle lights (overhead lighting, back -\\nlighting, and front -lighting)  (FHWA, 2017a) .37  \\nFigure 14. Examples of Environmental Conditions  \\n \\nConnectivity  \\nConnectivity and automation are increasingly being integrated into cars and trucks with the \\nobjective of improving safety, mobility, and providing a better driving experience. Connectivity is an enabling technology that may define where an ADS feature can operate. For example, low -\\nspeed shuttles may depend on traffic light signal phase and timing messages to reduce the dependence on sensors alone to detect the signal. Other operational examples include eco -\\napproach and departure or  coordinated ACC  (Michel, Karbowski, & Rousseau, 2016) . \\nConnectivity constitutes a communications link between other vehicles, road users, remote fleet management operators, and physical and digital infrastructure elements. Some of these elements are described below. Illustrative photos are provided in Figure 15.  \\nVehicles  \\n• V2V communications (e.g., DSRC, Wi -Fi), emergency vehicles  \\nTraffic Density Information  \\n• Crowdsourced data (e.g., Waze) and V2I  \\nRemote Fleet Management Sy stem   \\n• A vehicle may be supported by an operations center that can perform remote \\noperation. (Aljaafreh et al., 2011)38 Infrastructure Sensors and communications  \\n• Work zone alerts, vulnerable road user, routing and incident management, GPS, 3- D \\nhigh- definition  maps  (Ellichipuram, 2016) , pothole locations, weather data, data on \\nthe cloud, etc.  \\n \\nFigure 15. Examples of Connectivity  \\nZones  \\nADS features may be limited spatially by zones. The boundaries of these zones may be fixed or \\ndynamic, and conditions that define a boundary may be based on complexity, operating procedures, or other factors. One example is work zones, which can confuse ADS  as the road \\nconfiguration (pavement markings and new lane alignments) differs from typical conditions. In a work zone, cones may replace double yellow lines, bollards may replace curbs, and construction worker hand signals may overrule traffic lights. Th ese cues designed for human drivers can \\nchallenge advanced computer systems (Marshall, 2017) . There are several other types of zones \\nthat are important to consider as potential elements of an ODD (see text below and Figure 16).  \\nGeo-fencing  (Crosbie, 2017)  \\n• Central business districts, school campuses, and retirement communities (for example, \\nCityMobil2 is fixed route and includes < 20 mph  (CityMobil2, 2013)  routes both on -\\nroad and off -road on pedestrian walkways).39 Traffic Management Zones \\n• May include temporary lane closures, dynamic traffic signs, variable speed limits, \\ntemporary or non- existent lane markings, hum an-directed traffic, loading/unloading \\nzones  \\nSchool/Construction Zones   \\n• Dynamic speed limit, erratic pedestrian and vehicular behaviors (Marshall, 2017)  \\nRegions/States   \\n• Any legal, regulatory, enforcement, tort, or other considerations (e.g., following distance, licensing, etc.)  (Bomey & Zambito, 2017)  \\nInterference Zones  \\n• Tunnels, parking garage s, dense foliage, limited GPS due to tall buildings, \\natmospheric conditions  \\n \\nFigure 16. Examples of Zones  \\n \\nODD Identification for ADS Features  \\nThe ODD taxonomy lends itself to serving as a checklist for identifying the ODD of an ADS \\nfeature. A comprehensive ODD checklist was generated based on the ODD taxonomy described above. To demonstrate a potential application of the checklist, the checklist was filled out for \\nthree theoretical ADS features. The generic L3 Conditional Traffic Jam Drive, L3 Conditional40 Highway Drive and L4 Highly Automated Vehicle/ TNC features were selected . The results are \\npresented in Appendix A. It should be noted that currently the manufacturer would determine  the \\nODD for a feature , and the ODD may vary for similar ADS features . The theoretical features \\npresented here are purely demonstrative, not representative of any commercially marketed ADS \\nfeature. An excerpt of the checklist for L3 Conditional Traffic Jam Drive is shown in Table 11, \\nwith the other ODD categories presented in the Appendix. Additional supporting material is  \\nprovided in Appendix A. \\nTable 11. Extract from ODD Checklist Defined for a Generic L3 Conditional Automated Traffic \\nJam Drive Feature  \\nODD CHECKLIST: L3 Conditional Traffic Jam Drive  \\nPHYSICAL INFRASTRUCTURE  \\nRoadway Types  \\nDivided  highway  Y \\nUndivided highway  \\nN Arterial  \\nUrban  \\nRural  \\nParking (surface lots, structures, private/public)  \\nManaged lanes (HOV, HOT, etc.)  Y \\nOn-off ramps  N \\nEmergency evacuation routes  \\nIntersection s  N \\nRoadway Surfaces  \\nAsphalt  Y \\nConcrete  \\nRoadway Edges & Markings  \\nLane markers  Must be clear  \\nTemporary  lane markers  N \\nShoulder (paved or gravel)  Limited to divided highway  \\nShoulder (grass) Limited to divided highway  \\nLane barriers  Barrier, concrete or metal  \\nRails Barrier, concrete or metal  \\nOPERATION CONSTRAINTS  \\nSpeed Limits  \\nMinimum speed limit 0 mph \\nMaximum speed limit < 37 mph  \\nTraffic Conditions  \\nTraffic density  Only heavy traffic with preceding vehicle to \\nfollow and convoy in adjacent lane41 SUMMARY \\nThe ODD defines when and where a vehicle is designed to function. This chapter reviewed the \\nODD literature, developed an ODD taxonomy, as reconciled with the OEM’s current definitions,  \\nand identified ODDs for ADS features. The ODD framework presented here lays the foundation \\nfor Chapter 4 ( OEDR) and Chapter 5 (Scenarios).  \\nTo test a vehicle’s ability to operate safely, ODD is considered in test development and \\nexecution. Scenarios consider a combination of ODD elements that can be used to describe conditions for test cases and scenarios; for example, a highway with a concrete surface with a light mist. Test f acilities are limited in their ability to re -create certain ODDs (e.g., urban \\nenvironments, hill crests) and may need to be upgraded with new infrastructure to support testing. Some ODD elements are difficult to quantify and re -create (e.g., weather), and may be \\naddressed through functional safety design practices and on- road testing. Other examples of \\nODDs are shown in Figure 17. A figure showing the significance of ODD relative to levels of driving automation from SAE J3016 is reproduced in Figure 18. \\n \\nFigure 17. Other Examples of ODD42  \\nFigure 18. Illustrates the Significance of ODD Relative to the Levels of Driving Automation  (SAE \\nInternational, 2016)  \\n \\nThere are several aspects to consider to expand upon the defined ODD characteristics. Comparisons with other ODD characterizations and working with OEMs to develop a consensus for definitions could improve the robustness of this taxonomy. Further investigation of ODD boundary conditions, and how ADS  can detect these boundaries will be important to \\nunderstanding disengagement events. For example, a minimal risk maneuver might differ based on on- board sensor configuration and availability of shoulders. Further, potential events like a \\nleaf obstructing a sensor or bird excrement on a windshield obstructing line of sight when the driver is involved in part of the driving task need to be taken into account . There is thus a need to \\nconsider a more exhaustive list and potential classifiers for MRCs and other non- roadway users. \\nAutomation experts in both automotive and aviation industries have cautioned that the differences in ODD between automobiles and airp lanes are so significant that the cross- learning \\nopportunities are quite limited. Finally, monitoring the reports from the PEGASUS project in Europe  is suggested .43 CHAPTER 4.  OBJECT AND EVENT DETECTION AND RESPONSE CAPABILITIES   \\nOVERVIEW  \\nThis cha pter descri bes the identification of  OEDR capabilities that enable ADS  to function safely \\nwithin their prescribed operational ODD. OEDR refers to “the subtasks of the DDT that include \\nmonitoring the driving environment  (detecting, recognizing, and classifying objects  and events \\nand preparing to respond as needed) and executing an appropriate response to such objects and events (i.e., as needed to complete the DDT and/or DDT fallback ”; SAE International, 2016) . \\nOEDR capabilities will play a key role  in developing sampl e tests for ADS . \\nTactical maneuver behaviors were identified in Chapter 2 for conceptual ADS  features. These \\nbehaviors largely focus on the elements of the DDT  related to real -time functions specified in \\nSAE J3016 (SAE International, 2016) . These behaviors notionally represent the control- related \\ntasks that are used as the ADS  navigates to reach its prescribed destination. While perfor ming \\nthese tactical maneuver behaviors, ADS  will inevitably interact with a variety of static and \\ndynamic  physical objects  that may alter how these behaviors are executed. SAE J3016 identifies \\nthe following real -time functions as elements of the DDT related to addressing these interactions \\nwith objects . \\n• Object and event detection, recognition, and classification  \\n• Object and event response  \\nThese functions can be generalized under the term  OEDR. OEDR repr esents the ability of the \\nADS  feature to detect any circumstance that is immediately relevant to the driving task and \\nimplement an appropriate response. One of the factors that determines the level of driving \\nautomation of an ADS is whether the human driver or ADS is responsible for monitoring the driving envir onment . ADS , which are the focus of this report, range from  SAE International L 3 \\nthrough L 5, which means that the ADS  feature is complet ing all aspects of monitoring the \\ndriving environment. \\nThe elements of the ADS  functional architecture shown in Figure 3 that are specifically relevant \\nto OEDR generally include hardware and software components that support  the following. \\n• Sensing (e.g., r adar, l aser scanners, cameras, etc. ) \\n• Perception (e.g., road feature classification, object segmentation and classification, \\netc.) \\n• World m odeling (e.g., persistent data mapping, dynamic obstacle tracking,  and \\nprediction, etc.)  \\n• Navigation and planning (e.g., path planning and motion control commands  to \\nimplement responses ) \\nThe sensing and perception elements of the architecture specifically support detection of relevant \\nobjects . World modeling supports the aggregation of perception and other information to identify \\nand understand events that may occur through interactions with those objects. Navigation and44 planning support s determination of the appropriate response to those events and interactions, and \\nthe generation of control commands to implement that response.  \\nAPPROACH  \\nThree of the generic ADS  features identified in Chapter 2 were selected for this OEDR analysis. \\nThis allowed for an evaluation of  a cross -section of operating environments and conditions , as \\nwell as driving scenarios. The three features selected were the following. \\n• L3 Conditional  Automated Traffic Jam Drive  \\n• L3 Conditional  Automated Highway Drive   \\n• L4 Highly Automated Vehicle /TNC  \\nThese features  were selected  to provide a cross -sectional representation of the wide variety of \\nODDs  presented in Chapter 3 . The L3 Conditional Automated Traffic Jam Drive f eature can \\ngenerally be expected to function in low -speed, stop- and-go traffic in areas where traffic jams \\nare common (e.g., highways, urban r oads). The L3  Conditional Automated Highway Drive  \\nfeature can generally be expected to function on higher speed roads (e.g., highways, limited \\naccess freeways) with typical levels of traffic. The L 4 Highly Automated Vehicle/TNC  feature \\ncan generally be exp ected to function in denser urban areas at low to moderate speeds and  be \\nexposed to a wide variety of interactions with other vehicles and vulnerable road users.  These \\nfeatures were also selected based on their expected timeline for availability to the pub lic. The \\ntwo L 3 features were considered near -term ADS  that will likely become available in the next few \\nyears. The L 4 feature was considered a mid -term ADS, albeit one that is currently the subject of \\nsignificant research.  \\nUsing the se selected conceptual ADS  features from  Chapter 2 and the notional ODDs identified \\nin Chapter 3  and expanded upon in Chapter 7.Appendix A  for the selected features, this chapter \\nwill review the process undertaken to identify notional capabilities for OEDR for ADS . This \\nprocess can be broken down into the following steps . \\n• Review  the literature to evaluate and leverage prior research . \\n• Identif y notional operational descriptions for features . \\n• Perform  analysis  to identify baseline ODDs.  \\n• Perform d riving s cenario a nalysis . \\n• Perform analysis to identify OE DR behaviors and corresponding responses .45  \\nFigure 19. OEDR Capability Identification Process  \\nThe d evelopment of a notional, representative ConOps  supported the identification of normal \\ndriving scenarios for each ADS  feature. The operations descriptions  explain the intended use of \\neach f eature and the circumstances in which it may be used. The operations descriptions are \\nlaunching points for identif ying the  operational needs of each f eature, including its OEDR \\ncapabilities.  \\nFollowi ng the evaluation of the operational needs of the selected ADS  features, a focusing \\nexercise established  baseline ODDs for each f eature t o further refine the analysis to identify \\nOEDR capabilities  for the three selected features . This exercise served to fr ame the OEDR \\nanalysis to account for the potential variability of certain ODD elements, as well as the \\nsubstantial number  of combinations and permutations of ODD elements. It is reasonable to \\nexpect that different organizations developing similar ADS  features will generate unique designs  \\nand implementations, and thus  will ultimately define different ODDs for their respective \\nsystems. For example, Vendor A designs and develops a n L3 Traffic Jam Drive f eature that can \\nonly operate on limited access highways where there are no pedestrians or pedalcyclists; while Vendor B designs a n L3 Traffic Jam Drive f eature with similar control capabilities but that  also \\nwork s on arterials and urban streets where pedestrians and pedalcyclists may be present . \\nSimilarly, there can be great diversity of abilities within specific categories of the ODD. For example, Vendor A ’s Traffic Jam Drive f eature may be capable of operating only in light rain, \\nwhile Vendor B ’s Traffic Jam Drive f eature can operate in both light and heavy ra in (light and \\nheavy rain are treated purely qualitatively for the purposes  of this example). A well -defined \\nODD helps  to determine the OEDR capabilities that may be necessary an d, as such, these ODD\\nAnalysis•Identify notional Concept of Operations \\n(ConOps )\\n•Identify baseline set of ODD elements\\nDriving \\nScenario \\nAnalysis•Identify expected hazards\\n•Identify unspecified / unexpected events\\n•Prioritize interactions based on risk \\n(frequency & severity)\\nOEDR \\nAnalysis•Identify OEDR behaviors\\n•Identify appropriate responses46 baseline ODDs delineate  the attributes of the ODD for each selected feature for the purposes of \\nidentifying OEDR capabilities . It should also be noted again that the developing OEMs and \\nentities ultimately  define the ODD for their respective f eatures and , as such, t hese baseline \\nODDs  are intended to be notional and descriptive, rather than normative. The baseline ODDs  \\nalso serve to support the development of sample test scenarios and procedures described in  \\nChapter 5.  \\nWith the ODD baselines established for each f eature, a survey and analysis of the driving \\nscenarios that fall out of the operations descriptions led to  the identif ication of  relevant objects \\nand interactions that the ADS  could enc ounter . These objects and events are derived from an \\nevaluation of normal driving scenarios for a given ADS  feature operating in its ODD, includ ing: \\n• Expected hazards (e.g., vehicles, pedestrians, etc.) ; \\n• Unspecified/unexpected events (e.g., construction zones, emergency vehicles, etc.) ; \\nand \\n• Key infrastructure elements (e.g., traffic signs and signals, road markings, etc.) . \\nPrior work conducted by California PATH to define behavioral competencies (Nowakowski, \\nShladover, Chan, & Tan, 2015)  informed this evaluation of driving scenarios . Table 12 \\nreproduces a working list of critical driving maneuvers identified by PATH across a variety of driving environments. The driving environments correspond to certain attributes of the ODD at a high level. This list produced by PATH served as a starting point that was extended and refined based on the hierarchical ODD taxonomy developed in Chapter 3.  \\nTabl e 12. California PATH Minimum Behavioral Competencies (Nowakowski, Shladover, Chan, & \\nTan, 2015)  \\nCritical Driving Maneuvers Freeway  Rural \\nHighway  City \\nStreets  Valet \\nParking  Low -\\nSpeed \\nShuttles  \\nDetect System Engagement/Disengagement \\nConditions Including Limitations by Location, \\nOperating Condition, or Component \\nMalfunction  \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\nDetect & Respond to Speed Limit Changes \\n(Including Advisory Speed Zones)  \\uf0fc \\uf0fc \\uf0fc  \\uf0fc \\nDetect Passing and No Passing Zones       \\nDetect Work Zones, Temporary Lane Shifts, \\nor Safety Officials Manually Directing Traffic  \\uf0fc \\uf0fc \\uf0fc   \\nDetect and Respond to Traffic Control \\nDevices   \\uf0fc \\uf0fc   \\nDetect and Respond to Access Restrictions \\nsuch as One- Way Streets, No -Turn Locations, \\nBicycle Lanes,  Transit Lanes, and Pedestrian \\nWays    \\uf0fc \\uf0fc \\uf0fc47 Critical Driving Maneuvers Freeway  Rural \\nHighway  City \\nStreets  Valet \\nParking  Low -\\nSpeed \\nShuttles  \\nPerform High Speed Freeway Merge       \\nPerform a Lane Change or Lower Speed \\nMerge    \\uf0fc   \\nPark on the Shoulder or Transition the \\nVehicle to a Minimal Risk State (Not \\nRequired for SAE L3)      \\nNavigate Intersections & Perform Turns    \\uf0fc  \\uf0fc \\nNavigate a Parking Lot & Locate Open \\nSpaces     \\uf0fc  \\nPerform Car Following Including Stop & Go \\nand Emergency Braking  \\uf0fc \\uf0fc \\uf0fc \\uf0fc  \\nDetect & Respond to Stopped Vehicles  \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\nDetect & Respond to Intended Lane \\nChanges /Cut-Ins \\uf0fc \\uf0fc \\uf0fc   \\nDetect & Respond to Encroaching Oncoming \\nVehicles   \\uf0fc \\uf0fc \\uf0fc  \\nDetect & Respond to Static Obstacles in \\nRoadway  \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\nDetect & Respond to Bicycles, Pedestrians, \\nAnimals, or Other Moving Objects   \\uf0fc \\uf0fc \\uf0fc \\uf0fc \\nDetect Emergency Vehicles  \\uf0fc \\uf0fc \\uf0fc   \\n \\nNext, the evaluation of driving scenarios e stimate d the  risk associated with the various objects \\nand events. This risk analysis help s to prioritize scenarios for testing and evaluation.  Risk is \\nqualitatively estimated by considering the likelihood of an e vent or interaction  occurring, and the \\nresulting severity of the ADS  incorrectly responding to the interaction (e.g., a response that \\nresults i n a collision with the object). This analysis also used NHTSA pre -crash data for \\nprioritiz ing scenarios. The prioritization was  based on frequency of occurrence and severity \\n(number resulting in injuries or fatalities) (Najm, Smith, & Yanagisawa, 2007) . Table 13 shows \\npre-crash data for two -vehicle light -vehicle crashes involving manually driven vehicles . \\nFollowing the development of the working list of tactical maneuver behaviors in Chapter 2, the \\nlist of objects and events was refined into a working list of OEDR behaviors that notionally represent a set of testable perception -related scenario s. \\nControl actions were then identified to support safe responses to the identified combinations of \\nobjects and events.  These actions are seated in the tactical maneuver behaviors identified in \\nChapter 2 and PATH behavioral competencies reproduced in Table 12 above . The control action \\noptions are further informed by a task decomposition exercise. This decomposition, in some \\ncases, breaks the behaviors down into their more specific control -related actions. The National48 Institute of Standards and Technology 4D/RCS Reference Model Architecture for Unmanned \\nVehicle Systems was leveraged (Barbera, Horst, Schlenoff, & Aha, 2004)  for this analysis . \\nTable 13. Pre -Crash Scenarios of Two -Vehicle Light -Vehicle Crashes (Najm, Smith, & Yanagisawa, \\n2007)  \\nNo. Scenario  Frequency  Rel. Freq.  \\n1 Lead Vehicle Stopped  792,000  20.46%  \\n2 Vehicle s Turning at Non -Signalized Junctions  419,000  10.83%  \\n3 Lead Vehicle Decelerating  347,000  8.96%  \\n4 Vehicle s Changing Lanes - Same Direction  295,000  7.62%  \\n5 Straight Crossing Paths at Non -Signalized Junctions  252,000  6.52%  \\n6 Running Red Light  233,000  6.02%  \\n7 Vehicle s Turning - Same Direction  220,000  5.68%  \\n8 LTAP/OD4 at Signalized Junctions  205,000  5.29%  \\n9 Lead Vehicle Moving at Lower Constant Speed  186,000  4.82%  \\n10 LTAP/OD at Non -Signalized Junctions  181,000  4.68%  \\n11 Backing Up Into Another Vehicle  131,000  3.38%  \\n12 Vehicle s Not Making a Maneuver - Opposite Direction  94,000  2.43%  \\n13 Vehicle s Drifting - Same Direction  91,000  2.35%  \\n14 Following Vehicle Making a Maneuver  74,000  1.92%  \\n15 Control Loss Without Prior Vehicle Action  52,000  1.33%  \\n16 Vehicle s Parking - Same Direction  47,000  1.21%  \\n17 Running Stop Sign  43,000  1.12%  \\n18 Evasive Action Without Prior Vehicle Maneuver  37,000  0.95%  \\n19 Vehicle Turning Right at Signalized Junctions  34,000  0.89%  \\n20 Control Loss With Prior Vehicle Action  26,000  0.68%  \\n21 Non -Collision Incident  25,000  0.64%  \\n22 Lead Vehicle Accelerating  16,000  0.41%  \\n23 Vehicle s Making a Maneuver - Opposite Direction  13,000  0.33%  \\n24 Evasive Action With Prior Vehicle Maneuver  8,000  0.21%  \\n25 Vehicle Failure  8,000  0.20%  \\n26 Animal Crash Without Prior Vehicle Maneuver  6,000  0.14%  \\n27 Road Edge Departure Without Prior Vehicle Maneuver  3,000  0.08%  \\n28 Pedestrian Crash Without Prior Vehicle Maneuver  2,000  0.05%  \\n29 Road Edge Departure With Prior Vehicle Maneuver  2,000  0.04%  \\n30 Pedestrian Crash With Prior Vehicle Maneuver  1,000  0.02%  \\n31 Pedalcyclist Crash Without Prior Vehicle Maneuver  1,000  0.02%  \\n32 Other  28,000  0.73%  \\n \\n                                                 \\n4  *Left Turn Across Path/Opposite Direction49 FINDINGS  \\nBaseline ODDs  \\nThe ODD checklists referenced in Chapter 3 and the samples presented in Appendix A \\nnotionally represent the ODDs for ADS  features based on available data . The baseline  ODDs are \\nsimilarly summarized  here for the selected  ADS  features.  \\nL3 Conditional Automated Traffic Jam Drive Feature  \\nFor the L 3 Conditional Automated Traffic Jam Drive f eature, a notional operational use case of a \\ndriver on a limited -access highway or urban arterial road encountering slow, stop- and-go traffic \\nthat is expected to persist for a period of time  was considered . As described in Chapter 2, this \\nfeature implements lateral and longitudinal control to maintain the current lane of travel and a \\nsafe following distance behind an immediate lead vehicle.  This will likely rely on a combination \\nof cameras for lane tracking and radar for lead vehicle ranging. \\nTable 14. L3 TJD Baseline ODD –  Physical Infrastructure  \\nODD Elements  Examples  \\nRoadway Types  Interstates, freeways, divided highways undivided \\nhighways, arterials, urban, bridges, multi -lane, \\nsingle -lane, one -way, tunnels  \\nRoadway Surfaces  Asphalt, concrete , mixed  \\nRoadway Edges and Markings  Lane markers, temporary lane markers, concrete \\nbarriers, curbs, cones  \\nRoadway Geometry  Straight, curves, hills  \\n \\nTable 15. L3 TJD Baseline ODD –  Operational Constraints  \\nODD Elements  Examples  \\nMinimum Speed Limit  0 kph (0 mph)  \\nMaximum Speed Limit  59 kph (37 mph) (notionally)  \\nTraffic Density  Immediate lead vehicle  \\n \\nTable 16. L3 TJD Baseline ODD –  Environmental Conditions  \\nODD Elements  Examples  \\nWeather  Clear, calm  \\nWeather -induced Roadway Conditions  Dry \\nIllumination  Day, dawn/dusk  \\n \\nTable 17. L3 TJD Baseline ODD - Connectivity  \\nODD Elements  Examples  \\nDigital Infrastructure  Optional to determine if inside or outside of zone  \\n(e.g., geofence, infrastructure zone)50 Table 18. L3 TJD Baseline ODD - Zones  \\nODD Elements  Examples  \\nRegions/States  Adhere to State /local laws  \\nSchool/Construction  Construction zones  \\n \\nL3 Conditional Automated Highway Drive Feature  \\nFor the L 3 Conditional Automated Highway Drive  feature, a notional use case of a driver on a \\nlimited access highway encountering nominal, free -flow traffic conditions allowing for high-\\nspeed driving was considered . The f eature implements lateral and longitudinal control to \\nmaintain the current lane of travel, achieve the specified speed, and if necessary alter that speed \\nto follow an immediate lead vehicle at a safe following distance. This f eature m ay also \\nimplement automatic lane changing, potentially initiated by the occupant activating a turn signal or automatically to maintain the target speed if it is safe and prudent to do so.  \\nTable 19. L3 HWD Baseline ODD –  Physical Infrastructure  \\nODD Elements  Examples  \\nRoadway Types  Interstates, freeways, divided highways undivided \\nhighways, arterials, urban, bridges, multi -lane, \\nsingle -lane, one -way, tunnels  \\nRoadway Surfaces  Asphalt, concrete, mixed  \\nRoadway Edges and Markings  Lane markers, temporary lane markers, concrete \\nbarriers, curbs, cones  \\nRoadway Geometry  Straight, curves, hills  \\n \\nTable 20. L3 HWD Baseline ODD –  Operational Constraints  \\nODD Elements  Examples  \\nMinimum Speed Limit  72 kph (45 mph) (notiona lly) \\nMaximum Speed Limit  112 kph (70 mph) (notionally)  \\nTraffic Density  Minimal, normal  \\n \\nTable 21. L3 HWD Baseline ODD –  Environmental Conditions  \\nODD Elements  Examples  \\nWeather  Clear, calm  \\nWeather -induced Roadway Conditions  Dry \\nIllumination  Day, dawn/dusk  \\n \\nTable 22. L3 HWD Baseline ODD - Connectivity  \\nODD Elements  Examples  \\nDigital Infrastructure  Optional to determine if inside or outside of zone51 Table 23. L3 HWD Baseline ODD - Zones  \\nODD Elements  Examples  \\nRegions/States  Adhere to State /local laws  \\nSchool/Construction  Construction zones  \\nInterference  Urban canyons  \\n \\nL4 Highly Automated Vehicle /TNC Feature  \\nFor the L 4 Highly Automated Vehicle/ TNC f eature, a use case of an unmanned  TNC vehicle \\nbeing hailed by a passenger in a dense urban area  was considered . \\nTable 24. L 4 HAV/TNC Baseline ODD –  Physical Infrastructure  \\nODD Elements  Examples  \\nRoadway Types  Arterials, urban, bridges, multi -lane, single -lane, \\none-way, turn -only, rail crossings, bridges, bicycle \\nlanes, crosswalks , tunnels  \\nRoadway Surfaces  Asphalt, concrete, mixed  \\nRoadway Edges and Markings  Lane markers, temporary lane markers, concrete \\nbarriers, curbs, cones  \\nRoadway Geometry  Straight, curves,  hills, varying lane widths  \\n \\nTable 25. L 4 HAV/TNC Baseline ODD –  Operational Constraints  \\nODD Elements  Examples  \\nMinimum Speed Limit  0 kph (0 mph)  \\nMaximum Speed Limit  72 kph (45 mph) (notionally)  \\nTraffic Density  Minimal, normal, heavy  \\n \\nTable 26. L 4 HAV/TNC Baseline ODD –  Environmental Conditions  \\nODD Elements  Examples  \\nWeather  Clear, calm  \\nWeather -induced Roadway Conditions  Dry \\nIllumination  Day, dawn/dusk  \\n \\nTable 27. L 4 HAV/TNC Baseline ODD - Connectivity  \\nODD Elements  Examples  \\nDigital Infrastructure  Optional digital map, optional GPS52 Table 28. L 4 HAV/TNC Baseline ODD - Zones  \\nODD Elements  Examples  \\nGeofencing  CBDs , school campuses, communities, fixed \\nroutes  \\nTraffic Management Zones  Temporary road/lane closures, dynamic traffic \\nsigns, human -directed traffic, loading/unloading \\nzones, temporary lane markers  \\nRegions/States  Adhere to State /local laws  \\nSchool/Construction  School/construction zones  \\nInterference  Urban canyons, tunnels, foliage  \\n \\nBaseline OEDR Behaviors  \\nThe developed baseline ODDs were used to identify important objects and events that ADS  \\ncould feasibly encounter within those ODDs. Those relevant objects and events are presented for \\nthe selected ADS  features. The events of interest are based on some manner of interaction \\nbetween the subject ADS  and an identified object.  Figure 20 shows a notional depiction of how \\nsome events were categorized in the vicinity immediately around the ADS . Interactions with \\nobstacles were indicated as occurring in a frontal, side, or rear zone. The ta bles presented below \\ninclude a notional set of objects and events that an ADS could encounter in a baseline ODD. The events in bold type represent interactions that were used for test development in Chapter 5. Some of the events were considered lower priority for testing for safety assessment, as they did not fall within the immediate collision zone around the subject vehicle (SV). P otential maneuver and \\ncontrol actions that the ADS  could implement in response to the objects and events  were also \\nidentified . \\n \\nFigure 20. Notional Crash-Relevant Zones  Frontal \\nZoneFrontal \\nZoneFrontal \\nZone\\nRear \\nZoneRear \\nZoneRear \\nZoneSide \\nZoneSide \\nZone53 L3 Conditional Automated Traffic Jam Drive Feature  \\nTable 29. L3 TJD Summary of Roadway User Events  \\nObject s Event s/Interaction s \\nVehicles (e.g., cars, light trucks, heavy trucks, \\nbuses, motorcycles)  Lead vehicle d ecelerating  (frontal ), lead vehicle \\nstopped (frontal ), lead vehicle accelerating  \\n(frontal ), changing lanes  (frontal/side) , cutting in  \\n(adjacent ), turning  (frontal ), encroaching \\nopposing vehicle (frontal/side) , encroaching \\nadjacent vehicle ( frontal/side) , entering roadway \\n(frontal/side) , cutting out (frontal)  \\nPedestrians  Crossing road – inside crosswalk (frontal ), \\ncrossing road – outside crosswalk  (frontal ), \\nwalking on sidewalk/shoulder  \\nPedalcyclists  Riding in lane  (frontal ), riding in adjacent lane  \\n(frontal/side) , riding in dedicated lane  \\n(frontal/side) , riding on sidewalk/shoulder, \\ncrossing road – inside crosswalk  (frontal/side) , \\ncrossing road – outside crosswalk  (frontal/side ) \\n \\nTable 30. L3 TJD Summary of Non -Roadway User Events  \\nObject s Event s/Interaction s \\nAnimals5 Static in lane (frontal), moving into/out of lane \\n(frontal/side), static/moving in adjacent lane \\n(frontal), static/moving on shoulder  \\nDebris6 Static in lane (frontal)  \\nOther dynamic objects (e.g., shopping carts)  Static in lane (frontal/side) , moving into/out of \\nlane (frontal/side)  \\n \\nTable 31. L3 TJD Summary of Signs and Signals Events  \\nObject s Event s/Interaction s \\nTraffic signs7 Stop, yield, speed limit, crosswalk, railroad \\ncrossing, school zone  \\nTraffic signals7  Intersection, railroad crossing, school zone  \\nVehicle signals  Turn signals  \\n \\n                                                 \\n5 Animals that may have safety impacts, such as causing physical damage to ADS or harm to its occupants (e.g., deer, moose)  \\n6 Debris that may have safety impacts, such as causing physical damage to ADS or harm to its occupants (e.g., large tires)  \\n7 Compliant with the Manual on Uniform Traffic Control Devices54 Table 32. L3 TJD Summary  of Other Objects of Interest  \\nObject s Event s/Interaction s \\nEmergency vehicles  Lights and sirens activated (frontal/side), passing \\non shoulder (side/rear), encroaching, driving \\nwrong direction (frontal/side), violating \\nprecedence/right -of-way (frontal/side/rear)  \\nSchool buses  Lights and signs activated (frontal), s topped in \\nlane or adjacent lane (frontal/side), stopped in \\nopposing/undivided lane (frontal/side)  \\n \\nL3 Conditional Automated Highway Drive Feature  \\nTable 33. L3 HWD Summary of Roadway User Events \\nObject s Event s/Interaction s \\nVehicles  (e.g., cars, light trucks, heavy trucks, \\nbuses, motorcycles)  Lead vehicle decelerating (frontal), lead vehicle \\nstopped (frontal), lead vehicle accelerating (frontal), changing lanes (frontal/side), cutting in \\n(adjacent), turning (frontal), encroaching \\nopposing vehicle (frontal/side), encroaching \\nadjacent vehicle (frontal/side), entering roadway \\n(frontal/side ), cutting out (frontal)  \\nPedestrians  Crossing road  (frontal) , walking on shoulder  \\nPedalcyclists  Riding in lane  (frontal) , riding in adjacent lane  \\n(frontal/side) , riding in dedicated lane  \\n(frontal/side) , riding on shoulder, crossing road  \\n(frontal/side)  \\n \\nTable 34. L3 HWD Summary of Non -Roadway User Events  \\nObject s Event s/Interaction s \\nAnimals5 Static in lane (frontal) , moving into/out of lane \\n(frontal/side) , static/moving in adjacent lane \\n(frontal), static/moving on shoulder  \\nDebris6 Static in lane (frontal)  \\nOther dynamic objects (e.g., shopping carts)  Static in lane (frontal/side) , moving into/out of \\nlane (frontal/side)  \\n \\nTable 35. L3 HWD Summary of Signs and Signals Events  \\nObject s Event s/Interaction s \\nTraffic signs7 Stop, yield, speed limit , railroad crossing, school \\nzone  \\nTraffic signals7  Intersection (at grade), railroad crossing, school \\nzone  \\nVehicle signals  Turn signals55 Table 36. L3 HWD Summary of Other Objects of Interest  \\nObject s Event s/Interactio ns \\nEmergency vehicles  Lights and sirens activated (frontal/side), passing \\non shoulder (side/rear), encroaching, driving \\nwrong direction (frontal/side), violating \\nprecedence/right -of-way (frontal/side/rear)  \\nSchool buses  Lights and signs activated (frontal), stopped in \\nlane or adjacent lane (frontal/side), stopped in \\nopposing/undivided lane (frontal/side)  \\n \\nL4 Highly Automated Vehicle /TNC Feature  \\nTable 37. L4 HAV /TNC Summary of Roadway User Events  \\nObject s Event s/Interaction s \\nVehicles (e.g., cars, light trucks, heavy trucks, \\nbuses, motorcycles)  Lead vehicle decelerating (frontal), lead vehicle \\nstopped (frontal), lead vehicle accelerating (frontal), changing lanes (frontal/side), cutting in \\n(adjacent), turning (frontal), encroa ching \\nopposing vehicle (frontal/side), encroaching \\nadjacent vehicle (frontal/side), parking \\n(frontal/side ), entering roadway (frontal/side) , \\ncutting out (frontal)  \\nPedestrians  Crossing road  – inside crosswalk  (frontal) , \\ncrossing road – outside crosswalk  (frontal) , \\nwalking on sidewalk/shoulder  \\nPedalcyclists  Riding in lane  (frontal) , riding in adjacent lane  \\n(frontal/side) , riding in dedicated lane  \\n(frontal/side) , riding on sidewalk/shoulder, \\ncrossing road  – inside crosswalk  (frontal) , \\ncrossing road – outs ide crosswalk  (frontal)  \\n \\nTable 38. L4 HAV/TNC Summary of Non -Roadway User Events \\nNon -roadway Users  \\nAnimals5 Static in lane (frontal) , moving into/out of lane \\n(frontal/side) , static/moving in adjacent lane \\n(frontal), static/moving on shoulder  \\nDebris6 Static in lane (frontal)  \\nOther dynamic objects (e.g., shopping carts)  Static in lane (frontal/side) , moving into/out of \\nlane (frontal/side)56 Table 39. L4 HAV/TNC Summary  of Signs and Signals Events  \\nSigns and Signals  \\nTraffic signs7 Stop , yield , speed limit , crosswalk , railroad  \\ncrossing , school zone, access restric tion (e.g., \\none-way), work zone  \\nTraffic signals7  Intersection , railroad crossing , school zone  \\nVehicle signals  Turn signals  \\n \\nTable 40. L4 HAV/TNC Summary of Other Objects and Events of Interest  \\nOther Objects of Interest  \\nEmergency vehicles  Lights and sirens activated (frontal/side/rear), \\npassing on shoulder (side/rear), encroaching \\n(frontal/side/rear), driving wrong direction \\n(frontal/side/rear), violating precedence/right -\\nof-way (frontal/side/rear)  \\nSchool buses  Lights and signs activated (frontal/side), stopped \\nin lane or adjacent lane (frontal/side), stopped in \\nopposing/undivided lane (frontal/side)  \\nOther traffic control devices7  Cones , barrels , safety officials (e.g., handheld \\nsigns, flags, or hand signals)  \\n \\nTable 41 shows a summary of the objects and events highlighted in bold from the preceding \\ntables , generalized into a working list of OEDR behavior capabilities . While not directly related \\nto a specific object, operating outside of the defined ODD was also identified as an important event for OEDR, and is relevant to all of the selected features. These OEDR behaviors are intended to be a companion to the list of ta ctical maneuver behaviors identified and presented in \\nChapter 2. These OEDR behaviors provide d the basis for the development of preliminary tests in \\nChapter 5. As previously mentioned, several other attempts have been made to develop similar \\nsets of behaviors and conditions that are important, including the California PATH program behavioral competency analysis (Nowakowski, Shladover, Chan, & Tan, 2015)  and NHTSA pre -\\ncrash scenario analysis (Najm, Smith, & Yanagisawa, 2007) . Waymo also recently released a \\nvoluntary safety self -assessment that incl uded a list of behavioral competencies above and \\nbeyond those included in the PATH analysis  (Waymo, 2017b) . A comparison of the behavior \\ncombined list of OEDR behaviors and tactical maneuver behaviors from Chapter 2 with those from the PATH, NHTSA, and Waymo analyses is provided in Appendix D.57 Table 41. OEDR Behavior Capabilities  \\nDetect & Respond to Speed Limit Changes  Detect & Respond to Relevant School Buses  \\nDetect & Respond to Encroaching, Oncoming \\nVehicles  Detect & Respond to Relevant Emergency \\nVehicles  \\nPerform Vehicle Following  Detect & Respond to Relevant Pedestrians  \\nDetect & Respond to Relevant Stopped Vehicles  Detect & Respond to Relevant Pedalcyclists  \\nDetect & Respond to Relevant Lane Changes /Cut-\\nins Detect & Respond to Relevant Animals  \\nDetect & Respond to Relevant Static Obstacles in \\nLane  Detect & Respond to Relevant Vehicle Cut -\\nout/Reveal  \\nDetect &  Navigate Work Zones  Detect & Respond to Relevant Vehicle Roadway \\nEntry  \\nDetect & Respond to Relevant Safety Officials  Detect & Respond to Relevant Adjacent Vehicles  \\nDetect & Respond to Relevant Access Restrictions  Detect & Respond to ODD Boundary Transit ion \\nDetect & Respond to Relevant Dynamic Traffic \\nSigns   \\nThe detection of objects and events may occur in multiple ways. ADS  will likely employ a suite \\nof perception sensors —potentially to include some combination of radar, lidar, cameras, and \\nultrasonic sensors —that can support detection and recognition of many of these objects and \\nevents. This path relies on supporting algorithms to parse and interpret the data provided by \\nthose sensors.  V2V and V2I communications capability, via DSRC or other technology, can also \\nsupport detection and recognition in some capacity. If available, SAE J2735 B asic S afety \\nMessages include information on vehicle position, speed, and heading that could supplement or \\naugment measurements taken by an ADS ’s onboard perception sens ors. Other data, such as \\nintersection signal, phase, and timing data could be broadcast through digital infrastructure to provide information on the state of a traffic signal. Furthermore, many prototype ADS  under \\ndevelopment rely on onboard, high- fidelity  digital maps that have been collected and optimized a \\npriori . These maps may include three -dimensional  information about static objects and \\ninfrastructure, including the roadway itself. Maps may also include important navigation \\nmetadata, such as the number of lanes on a road segment and other important lane characteristics (e.g., directionality , left turn, bus -only), speed  limits, and presence of traffic control devices or \\nmarkings (e.g., stop signs, traffic signals, crosswalks). This map information can similarly be used to supplement or augment an ADS ’s onboard sensor data (or vice  versa ) or could be used \\nindependently to support the detection of certain objects and events. N o assumptions re garding \\nthe mechanism for implementing detection were made when compiling the list of objects and \\nevents.  \\nAssuming an ADS  has correctly detected a safety -critical object or event, it then implements  an \\nappropriate response. The response will ideally be a stable control action or maneuver that \\nallows the ADS  to maintain a safe avoidance distance from all relevant obstacles in the \\nimmediate crash vicinity, and that continues to follow the applicable rules and etiquette  of the \\nroad, to the best extent possible.  The identified responses that notionally fit these criteria include:58 • Follow Vehicle – I mplement lateral and/or longitudinal  control actions to maintain a \\nsafe8 following distance from an immediate lead vehicle, while cont inuing to follow \\nthe current lane of travel . \\n• Accelerate –  Implement longitudinal control actions to increase speed, as appropriate \\nand lawful . \\n• Decelerate –  Implement longitudinal control actions to  decrease speed, as appropriate.  \\n• Stop – I mplement longitudinal control actions to decelerate in a safe and stable \\nmanner  to a complete stop . \\n• Yield – R elinquish right -of-way to another road user . \\n• Change Lane – I mplement longitudinal and/or  lateral control actions to shift into an \\nadjacent lane. \\no Abort Lane Change – Cancel the maneuver to shift into an adjacent lane (remain \\nin or return to original lane).  \\n• Pass – I mplement longit udinal and /or lateral control actions to shift into an adjacent \\nlane to accelerate to desired speed . \\no Abort Pass –  Cancel man euver to shift into an adjacent lane (remain in or return  \\nto original lane).  \\n• Turn – I mplement lateral and longitudinal control actions to transition from current \\nroad/lane to connecting road/lane . \\n• Shift Within Lane – I mplement lateral and/or longitudinal c ontrol actions such that the \\nADS  does not follow the center  (or near -center)  of the current lane but remains fully \\nwithin the current lane. \\n• Shift Outside of Lane – I mplement lateral and/or longitudinal control actions such that \\nthe ADS  partially or fully moves outside of the current lane of travel  (i.e., one or more \\nwheels cross the lane boundary) . \\n• Move Out of Travel Lane/Park – I mplement lateral and longitudinal control actions \\nsuch that the ADS  fully exits the current active lane of travel onto a shoulder or \\nparking lane and stops . \\n• Transition to MRC:  \\no Return Control to Fallback- ready User – R eturn longitudinal and lateral control to \\nhuman occupant/driver (while providing sufficient warning) . \\no ADS  Implements Minimal Risk Maneuver – Implem ent lateral and/or \\nlongitudinal control actions to achieve a minimal risk condition (see Chapter 6) . \\nThese control actions and maneuvers represent a variety of opti ons for an ADS  to respond to \\nobjects and events of interest. Table 42 through Table 53 show mappings of  these responses to \\nthe objects and events identified in Table 29 through Table 40 . Again, t hese mappings are \\nintended to be notional rather than normative. It should a lso be noted again that , as an ADS ’s \\nODD will be specified by the OEM or developer, some of these objects and events may fall \\noutside the final ODD. These cases may be captured by the event representing operation outside \\nof the ODD, for which the appropria te response may likely be to transition to a n MRC. \\n                                                 \\n8 Could be defined by State or local regulations, but notionally should ensure vehicle can decelerate safely to avoid a collision.59 L3 Conditional Automated Traffic Jam Drive Feature  \\nTable 42. L3 TJD Response Mapping - Roadway Users  \\nEvent  Response  \\nLead vehicle decelerating  Follow vehicle, decelerate, stop  \\nLead  vehicle stopped  Decelerate, stop  \\nLead vehicle accelerating  Accelerate, follow vehicle  \\nLead vehicle turning  Decelerate, stop  \\nVehicle changing lanes  Yield, decelerate, follow vehicle  \\nVehicle cutting in  Yield, decelerate, stop, follow vehicle  \\nVehicle entering roadway  Follow vehicle, decelerate, stop  \\nOpposing vehicle encroaching  Decelerate, stop, shift within lane, shift outside of \\nlane  \\nAdjacent vehicle encroaching  Yield, decelerate, stop  \\nLead vehicle cutting out  Accelerate, decelerate, stop  \\nPedestr ian crossing road – inside crosswalk  Yield, decelerate, stop  \\nPedestrian crossing road – outside of crosswalk  Yield, decelerate, stop  \\nPedalcyclist riding in lane  Yield, follow  \\nPedalcyclist riding in dedicated lane  Shift within lane9 \\nPedalcyclist  crossing road – inside crosswalk  Yield, decelerate, stop  \\nPedalcyclist crossing road – outside crosswalk  Yield, decelerate, stop  \\nLead vehicle decelerating  Follow vehicle, decelerate, stop  \\nLead vehicle stopped  Decelerate, stop  \\nLead vehicle accelerating  Accelerate, follow vehicle  \\nTable 43. L3 TJD Response Mapping - Non-Roadway Users  \\nEvent  Response  \\nDebris static in lane  Decelerate, stop  \\nDynamic object in lane  Decelerate, stop  \\nDynamic object moving into/out of lane  Decelerate, stop  \\n \\nTable 44. L3 TJD Response Mapping - Other Events of Interest  \\nEvent  Response  \\nOperating outside of ODD  Transition to MRC (fallback -ready user)  \\n \\n                                                 \\n9 Could be informed by State or local regulations.60 L3 Conditional Automated Highway Drive Feature  \\nTable 45. L3 HWD Response Mapping - Roadway Users  \\nEvent  Response  \\nLead vehicle decelerating  Follow vehicle, decelerate, stop, change lane, pass  \\nLead vehicle stopped  Decelerate, stop, change lane, pass  \\nLead vehicle accelerating  Accelerate, follow vehicle  \\nLead vehicle turning  Decelerate, stop, change lane, pass  \\nVehicle changing lanes  Yield, decelerate, follow vehicle  \\nVehicle cutting in  Yield, decelerate, stop, follow vehicle, change \\nlane  \\nVehicle entering roadway  Follow vehicle, decelerate, stop, change lane, pass  \\nOpposing vehicle encroaching  Decelerate, stop, shift within lane, shift outside of \\nlane, change lane  \\nAdjacent vehicle encroaching  Yield, decelerate, stop, shift within lane, shift \\noutside of lane, change lane  \\nLead vehicle cutting out  Accelerate, de celerate, stop  \\nPedestrian crossing road – inside crosswalk  Yield, decelerate, stop  \\nPedestrian crossing road – outside of crosswalk  Yield, decelerate, stop  \\nPedalcyclist riding in lane  Yield, follow, change lane, pass  \\nPedalcyclist  riding in dedicated lane  Shift within lane10, change lane  \\nPedalcyclist crossing road – inside crosswalk  Yield, decelerate, stop  \\nPedalcyclist crossing road – outside crosswalk  Yield, decelerate, stop  \\n \\nTable 46. L3 HWD Response Map ping - Non-Roadway Users  \\nEvent  Response  \\nAnimal static in lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\nAnimal moving into/out of lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\nDebris static in lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\nDynamic object in lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\nDynamic object moving into/out of lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\n \\nTable 47. L3 HWD Response Mapping - Signs and Signals  \\nEvent  Response  \\nSpeed limit change  Accelerate, decelerate  \\n \\n                                                 \\n10 Could be informed by State or local regulations.61 Table 48. L3 HWD Response Mapping - Other Events of Interest  \\nEvent  Response  \\nOperating outside of ODD  Transition to MRC (fallback -ready user)  \\n \\nL4 Highly Automated Vehicle /TNC Feature  \\nTable 49. L4 HAV/TNC Response Mapping - Roadway Users  \\nEvent  Response  \\nLead vehicle decelerating  Follow vehicle, decelerate, stop, change lane, pass  \\nLead vehicle stopped  Decelerate, stop, change lane, pass  \\nLead vehicle accelerating  Accelerate, follow vehicle  \\nLead vehicle turning  Decelerate, stop, change lane, pass  \\nVehicle changing lanes  Yield, decelerate, follow vehicle  \\nVehicle cutting in  Yield, decelerate, stop, follow vehicle, change \\nlane  \\nVehicle entering roadway  Yield, decelerate, stop, change lane, pass  \\nVehicle cutting out  Accelerate, d ecelerate, stop, change lane, pass  \\nOpposing vehicle encroaching  Decelerate, stop, shift within lane, shift outside of \\nlane, change lane  \\nAdjacent vehicle encroaching  Yield, decelerate, stop, shift within lane, shift \\noutside of lane, change lane  \\nLead vehicle cutting  out Accelerate, decelerate, stop  \\nLead vehicle parking  Decelerate, stop, change lane, pass  \\nPedestrian crossing road – inside crosswalk  Yield, decelerate, stop  \\nPedestrian crossing road – outside of crosswalk  Yield, decelerate, stop  \\nPedalcyclist riding in lane  Yield, follow, change lane, pass  \\nPedalcyclist riding in adjacent lane  Yield, shift within lane  \\nPedalcyclist riding in dedicated lane  Shift within lane11, change lane  \\nPedalcyclist crossing road – inside crosswalk  Yield, decelerate, stop  \\nPedalcyclist crossing road – outside crosswalk  Yield, decelerate, stop  \\n \\nTable 50. L4 HAV/TNC Response Mapping - Non-Roadway Users  \\nEvent  Response  \\nAnimal static in lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\nAnimal moving into/out of lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\nDebris static in lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\nDynamic object in lane  Decel erate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\nDynamic object moving into/out of lane  Decelerate, stop, change lane, pass, shift within \\nlane, shift outside of lane  \\n                                                 \\n11 Could be informed by State or local regulations.62 Table 51. L4 HAV/TNC Response Mapping - Signs and Signals  \\nEvent  Response  \\nStop sign  Decelerate, stop  \\nYield sign  Decelerate, yield, stop  \\nSpeed limit sign  Accelerate, decelerate  \\nCrosswalk sign  Decelerate, yield, stop  \\nRailroad crossing  Decelerate, yield, stop  \\nSchool zone  Decelerate, yield, stop  \\nAccess restriction  Stop, turn, change lane, transition to MRC (ADS), \\nmove out of travel lane/park  \\nWork zone  Decelerate, yield, change lane, shift within lane, \\nshift outside of lane  \\nIntersection signal s Decelerate, stop, accelerate, yield, turn  \\nRailroad crossing signal  Decelerate, stop  \\nSchool zone signal  Decelerate, yield, stop  \\n \\nTable 52. L4 HAV/TNC Response Mapping - Other Objects of Interest  \\nEvent  Response  \\nEmergency vehicle (active) static  Decelerate, yield, stop, change  lane, pass, shift \\nwithin lane, shift outside of lane  \\nEmergency vehicle (active) passing  Decelerate, yield, stop, change lane, shift within \\nlane, shift outside of lane  \\nEmergency vehicle (active) encroaching  Decelerate, yield, stop, change lane, shift within \\nlane, shift outside of lane  \\nEmergency vehicle (active) driving wrong \\ndirection  Decelerate, yield, stop, change lane, shift within \\nlane, shift outside of lane  \\nEmergency vehicle (active) violating precedence  Decelerate, yield, stop  \\nSchool bus (active) stopped in lane  Yield, stop  \\nSchool bus (active) stopped in adjacent lane  Yield, stop  \\nSchool bus stopped in opposing/undivided lane  Yield, stop  \\nOther traffic control devices  Dependent on scenario configuration12 \\n \\nTable 53. L4 HAV/TNC Response Mapping for Other Events of Interest  \\nEvent  Response  \\nOperating outside of ODD  Transition to MRC (fallback -ready user or ADS)  \\n \\nSUMMARY \\nThis chapter identified a set of baseline ODDs for the selected ADS features to frame  the \\nanalysis of driving scenarios and the identification of OEDR capabilities. Relevant objects and \\nevents that an ADS could reasonably be expected to encounter  within its ODD  were then \\n                                                 \\n12 Any of the listed responses could be appropriate for temporary or alternative traffic control devices (e.g., hand signals, flags), depending on \\nthe situation and context.63 identified . These o bjects and events were generalized into a set of 19 OEDR- related behaviors \\nfor further evaluation. A  number of the potential control -related actions an ADS  could \\nimplement  in response to the objects and events  were also identified . The responses were  then  \\nmapped to the identified key objects and interacti ons. While ADS  features brought to marke t \\nmay inevitably have specified ODDs that differ from the baselines, the OEDR capabilities \\nidentified using these baselines capture a significant cross- section  of potential OEDR -related \\nbehaviors. The baseline ODDs and OEDR capabilities  will serve to inform and drive the \\nconstruction of a flexible testing framework , and specific tests that can be performed within that \\nframework  in Chapter 5.64 CHAPTER 5.  PRELIMINARY TESTS AND EVALUATION METHODS  \\nOVERVIEW  \\nThis chapter describes the development of  preliminary tests and evaluation methods to support \\nthe assessment of ADS  for safe deployment . This builds  on findings reported in Chapter 2, \\nChapter 3, and Chapter 4. The test methods and procedures were developed using engineering \\njudgments , previous  test procedure  development experience , functional requirements, and use \\ncases. The test framework and procedures developed gave special consideration to achieving \\nrepeatability , reliability, and practicality. Lastly, many  challenges associated with testing ADS  \\nand further research needed to help address  these challenges  were identified . Challenges \\nincluded those related to the technology itself as well as test execution. While this task did not \\ninvolve any actual testing, the findings  may inform future physical and virtual tests.  \\nThe current automotive certification landscape in the U nited States involves  OEMs and  suppliers \\nto self -certify that each piece of regulated equipment and each regulated vehicle is compliant \\nwith relevant Federal Motor Vehicle Safety Standards . NHTSA’ s authority includes the ability to \\nselect vehicles and equipment to verify compliance wit h these standards, and to pursue \\nenforcement actions when it finds a noncompliance or defect posing a safety risk. To support \\nthis, NHTSA’ s Office of Vehicle Safety Compliance audit s and verifies compliance, and its \\nOffice of Defects Investigation explores  safety issues to determine if a safety -related defect \\nexists. N o assumptions about the structure of  the future automotive certification landscape that \\nincludes ADS  were made. Rather, the aim was to develop a n example of a  flexible evaluation \\nframework and common test scenarios. The resulting framework focuses on common test scenarios that can be leveraged and applied across multiple testing techniques.  \\nA goal was  to develop the framework such  that it could be used for testing in a variety of ways, \\nincludin g: \\n• Black -box t esting – The functionality of the system is tested,  while t he internal design \\nand implementation of the system are largely unknown or unexposed to the tester . \\n• White -box testing –T he internal structure or workings of a system are tested as \\nopposed to its overall functionality.  \\nAn example of black- box testing in the context of an ADS  assessment would be to evaluate it s \\nobstacle avoidance capabilities. In this example, the test may involve positioning a large static obstacle along an ADS’s int ended route and observing its ability to avoid a collision with the \\nobject while continuing to navigate to its desired destination. In this case, only the resulting navigation outcome is evaluated to answer one primary question:  \\n• Did the ADS  avoid the obsta cles in a safe and stable manner?65 An example of white -box testing in the same context would involve measuring the outputs of \\none or more of the ADS ’s perception and navigation algorithms to answer a multitude of \\nquestions, potentially including:  \\n• At what ra nge did the ADS  detect the obstacle? \\n• Did the ADS  correctly classify the type of obstacle? \\n• Did the ADS  correctly estimate the location of the obstacle?  \\n• Did the ADS  correctly estimate the size of the obstacle?  \\n• How quickly did the ADS  decide to react? \\n• How sta ble was the control response?  \\nIn some cases, black -box testing may be sufficient for safety verifications of ADS  or other \\nsystems; however, there is significant value in answering the questions associated with white-\\nbox testing. Answe ring these questions s upports a deeper  understanding of the performance \\nbounds of a system . A goal was to establish a testing framework that cou ld benefit and support \\ngovernment and industry  with both black- box and white -box testing, as ADS  are developed and \\ndeployed.  \\nAPPROACH  \\nTo identify appropriate methods to evaluate ADS , a review and assessment  of existing testing \\nmethods and tools  was performed . This evaluation served to develop an understanding of how \\ntesting is currently being executed for vehicles capable of various  levels of  automation. It also \\nserved t o identify potential gaps in this  existing testing framework, which led  to the \\nidentification of additional and modified tools and methods to fill those gaps  and helped create a \\ntesting framework . This assessment incl uded a meeting with crash avoidance test engineers at \\nNHTSA’ s Vehicle Research and Test ing Center in Ohio to discuss their current testing of  \\nvehicles capable of SAE International L 1 and L 2 driving automation . Findings from the previous \\ntasks were presented and initial thoughts on the steps to develop a useful set of test methods and actual tests  were provided. \\nA common test scenario framework that could be used broadly across the various testing methods and tools was then established . This framework built upon the findings  of the previous \\ntasks to include the principal elements of ADS  operation (tactical maneuver, O DD, and OEDR) \\nthat have a direct impact on their overall safety.  Each of these elements can be viewed as an \\ninput or integrated component in the overall test scenario. The framework was developed in such \\na way that it could be used for both black- box and white -box testing. Each of the core scenario \\ncomponents can be applied similarly for both black -box and white -box analyses ; the differences  \\ncome in the ability to inject inputs and take  output  measurements at various levels  within the \\nsystem under test. As part of this analysis, key interfaces where this injection and measurement could take place were identified . \\nWith this scenario framework established, notional test procedures for a subset of the important scenarios were developed. The structure of the procedures was  based on prior tests related to66 connected -vehicle technology (Howe, Xu, Hoover, Elsasser, & Barickman, 2016) . Aspects of \\nthese procedures include the following. \\n• Test subject and purpose  \\n• Test personnel, facilities, and equipment  \\n• Test scenario  \\no Inputs  \\no Initial conditions  \\no Execution  \\no Data measurement and  metrics  \\nSeveral  guiding principles were identified to support the development of the testing framework \\nand the test procedures themselves. \\n• Testing variables should be isolated, not integrated \\n• Test environments should be characterized or controlled for tes t repeatability  \\n• Test metrics should not contain inherent thresholds  \\n• Test methods should allow for sufficient dynamic range  \\n• Tests should be conducted at the lowest level of integration possible  \\n• Low-level tests should help create boundary conditions for high -level integrated \\nsystem tests  \\n• Parameterization of testing variables and conditions should focus on a “ reasonable \\nworst case ” \\nFinally, challenges associated with testing ADS  were identified . ADS  add a significant level of \\ncomplexity to a base vehicle p latform that can make their assessment more difficult  in many \\nways . These challenges were broken down into two main categories:  (1) c hallenges associated \\nwith developing tests and metrics , and (2) c hallenges associated with test execution .67  \\nFigure 21. ADS  Test and Evaluation Method Development  Process  \\nFINDINGS  \\nTesting Architecture  \\nAvailable literature and reports on current ADS  testing activities conducted by both government \\nand industry  were reviewed . The review identified several  ways that these tests are primarily \\nbeing conducted.  \\n• Modeling and simulation  \\n(M&S)  \\n• Closed -track testing  \\n• Open -road testing  \\nThese three techniques of fer a \\nmultifaceted testing architecture with \\nvarying degrees of  test control, and \\nvarying degrees of fidelity in the test environment . In many cases, two or \\nmore of these techniques can be used in parallel or in an iterative fashion to progressively evalua te a complex \\nsystem such as an ADS .  Test \\nFramework•Identify appropriate test framework\\n•Identify new / modified test tools\\nScenario \\nFramework•Identify / develop test scenario \\nframework\\nTest \\nProcedures•Develop test scenario procedures\\nChallenges•Identify testing challenges\\nModeling & \\nSimulation\\nTrack \\nTesting\\nOpen -Road \\nTesting\\nFigure 22. Primary Testing Methods68 Modeling and Simulation \\nM&S  rely on a virtual environment with virtual agents to generate knowledge about an ADS ’s \\nbehavior without the need for a physical vehicle and actual testing in the real world. The base \\nvehicle platform and the underlying ADS  components need to be modeled physically and/or \\nmathematically to the extent that the behavior of the virtual system can mimic that of the real system to the desired degree of fidelity. Similarly, the virtual environment in which the ADS  will \\nbe operating is modeled to the desired degree of fidelity. The higher the fidelity of these models, the more closely they represent the actual nature of the vehicle or environment, which results in more substantive data for analysis.  \\nSimulation testing provides several  advantages:  \\n• Controllability  – Simulation affords an unmatched ability to control many  aspects of \\na test . \\n• Predictability  – Simulation is designed to run as specified, so there is little \\nuncertainty as to how the test will run. \\n• Repeatab ility – Simulation allows a test to be run many time s in the same fashion, \\nwith the same inputs and initial conditions . \\n• Scalability – Simulation  allows for generation of a large number and type of \\nscenarios.  \\n• Efficien cy – Simulation includes a  temporal component, which allows it to be sped up \\nfaster than real time so that many tests can be run in a relatively short amount of time . \\nThese features are important for the testing of complex systems. Simulation may also serve as a \\nrelatively cheaper option for initial testing, as opposed to building up one or more fully \\nfunctional test vehicles.  Simulation environments are also faster to implement and deploy and \\nmay be able to test a broader range of conditions.  \\nThere are several approaches to M&S  that may be applied to support the validation and \\nverification of ADS  with existing tools. Examples of the applications are discussed in this \\nsection and described more expansively in Appendix B. Appendix B  also includes a breakdown \\nof tools by functional area.  \\nSeveral sub fields within the field of M&S  that could be used  for ADS  testing  were identified . \\n• Software -in-the-loop (SIL) simulation  \\n• Hardware -in-the-loop (HIL) simulation  \\n• Vehicle -in-the-loop (VIL) simulation  \\nSIL simulation might be viewed as a traditional simulation system where a subset or all of the \\nunderlying ADS  software is incorporated into the modeled vehicle to drive the physical response \\nto stimuli. This could include processing modeled sensor data that then feed into world -\\nmodeling, decision- making, and motion- planning algorithms. The output of the motion -planning \\nalgorithm could be fed into the vehicle model to then induce the virtual vehicle’s motion.69 HIL simulation incorporates some level of physical hardware and equipment into the simulation \\nenvironment  to provide real data inputs and processing for some parts of the system . For \\nexample, an actual radar may be tied into the simulation to provide live range data for the virtual \\nADS  to process and enact a response to, or an actual ele ctronic  control unit could be tied into the \\nvirtual system to study how the physical production- intent hardware functions . Alternatively, a \\nreal heavy -duty vehicle pneumatic  brake actuation system could be installed on a static stand and \\ntied into the simulator (Salaani, Mikesell, Boday, & Elsasser, 2016) . The brake signals generated \\nby the virtual ADS  model could be sent to the brake system to collect data to understand the \\nactual dynamic response to certain conditions and stimuli.  \\nFinally, VIL simulation can allow for a somewhat more integrated test and analysis by \\nleveraging the production- intent vehicle and subsystems. The ADS  platform could be placed on a \\nroller test bench , such as a chassis- dynamometer, to allow physical actuation of the steering, \\nthrottle, and brake systems to get the wheels rolling and turning, while the vehicle remains in \\nplace. The simulation system could be tied into bot h the roller bench and the vehicle itself. The \\ninterface with the vehicle could allow for injection of sensor data to simulate  terrain and objects \\nand injection of map data to support routing and decision- making, among other things. The \\ninterface with the roller bench could facilitate simulation of road surface conditions (e.g., roughness, traction loss). Alternatively, virtual scenarios and objects could be injected into a real-world test environment , with the actual ADS  running on a track and reacting to the virtual \\nscenarios (Kallweit, Prescher, & Butenuth, 2017) . Communications infrastructure, such as \\nDSRC, could be integrated into the simulation to provide V2V or V2I data exchange  to inject \\nthese virtual objects or scenarios.  \\nFigure 23 shows a generalized ADS  simulation architecture diagram. The diagram calls out \\nexternal inputs that could be simulated and injected into a test, inputs that can otherwise be \\ncontrolled or measured, as well as outputs that can be measured.  The nature of the simulation \\n(e.g., whit e-box versus black- box) could allow for other interfaces for data injection and \\nmeasurement.70  \\nFigure 23. Notional ADS  Simulation Architecture  \\nM&S  testing offer s several  additional benefits to address some of the challenges associated with \\ntesting ADS . The magnitude of the number of scenarios an ADS  could encounter, along with the \\nmagnitude and variability of the components that make up a scenario (e.g., ODD, OEDR) , likely \\npresent an impractical set of test cases. M&S  can be leverag ed to inform testing requirements \\nand prioritize test scenarios for additional testing using the other techniques of the proposed \\ntesting architecture. Simulation can be used as a tool to assess the impact of the sensitivity  of \\nODD and OEDR to the accuracy  of ADS . The wide variety of  test case parameters (e.g., sensor \\nerrors, types of intersections, types of objects) can be varied efficiently to estimate the potential associated risk. This can inform the development of risk profiles that can help prioritize  those \\nparameters and scenarios. Additionally, simulation can easily allow for fault injection to test failure modes and the ADS ’s responses to those failures.  \\nSeveral disadvantages also exist to the use of M&S. It is difficult to model systems and physica l \\nproperties with full -fidelity, which may impact how well the simulation environment mimics the \\nreal world. There is also a wide variety of commercially available simulation tools, as well as vendor -developed tools, with distinctive features and capabilit ies. This presents challenges to \\nperform comparisons of results across the different tools.  \\nMeasurable\\nControllable / \\nKnown71  \\nFigure 24. Modeling and Simulation Used to Inform Test Requirements and Prioritize Test \\nScenarios  \\n \\nClosed -Track Testing  \\nRunning tests in a real -world environment is an important component of assessing ADS . Putting \\nphysical vehicles through a gamut  of lifelike  scenarios allows for an evaluation of full system \\nperformance that may not be practical using M&S  techniques. Rather  than presenting virtual \\nobjects and environments to a vehicle that is modeled with potentially limited fidelity, as is the \\ncase in simulation, physical testing presents real obstacles or obstacle surrogates to a production -\\nlevel vehicle using actual senso rs and software running on target platforms. Testing in a closed -\\ntrack or road -course setting  is one way  to achieve such lifelike testing conditions.  \\nMany organizations developing ADS  technology either have their own closed- access proving \\ngrounds or  have access to similar proving grounds through partnerships. Independent proving \\ngrounds also exist. Additionally, USDOT  recently designated 10 proving ground pilot sites to \\nencourage ADS  testing and data sharing (USDOT, 2017) . Teams with expertise in CV and ADS \\ntechnology and with available test facilities to support evaluation of those technologies, including closed test tracks, have organized these proving ground pilot sites  across the country  to \\nmeet those goals.  \\nTrack testi ng provides a few  advantages compared to M&S  or open- road testing.  \\n• Controllab ility – Track testing allows for control over many of the test variables, \\nincluding certain  aspects of ODD and OEDR.  \\n• Improved f idelity  – Track testing  involve s functional, physica l ADS  and lifelike \\nobstacles and environmental conditions . \\n• Transferab ility – Track testing scenarios can be replicated in different locations.  \\n• Repeatab ility – Track testing allows for multip le iterations of tests to  be run in the \\nsame fashion, with the same inputs and initial conditions . OEDR \\nCharacteristicsSimulated \\nSensor \\nErrorsScenarios\\nRepresentative ScenariosShared \\nRoad UsersRoadway \\nTypesV2V \\nInteractions\\nModeling & \\nSimulation72 Conversely, closed- track testing also suffers from several  drawbacks  that present challenges to \\nits utility in assessing and evaluating ADS . \\n• Prolonged  and cost ly –Track testing can t ake a significant amount of time to set up \\nand execute, resulting in elevated costs . \\n• Limited variability  – Track testing facility infrastructure and conditions  may be \\ndifficult to modify to account for a wide variety of test variables (e.g., ODD \\nconditions) . \\n• Personnel and e quipment needs  – Track testing may need specialized test equipment \\n(e.g., obstacle objects, measurement devices, safety driver ). \\n• Potentially hazardous  – Track testing with physical vehicles and real obstacles \\npresents a potentially uncertain and hazardous environment to the test participants \\n(e.g., safety driver and experiment observers) . \\nFigure 25 shows a generalized ADS  track testing architecture diagram. The diagram calls out \\nexternal inputs and conditions that could be controlled or measured during a test, as well as \\noutputs that could be measured.  The nature of the test (e.g., white -box versus black -box) could \\nallow for different  interfaces for data injection and measurement.  In a black -box testing scenario, \\nthe primary measured output is the navigation outcome, which could include an OEDR -related \\nresponse as described  in Chapter 4. Alternatively, a white -box testing scenario could incorporate \\nmeasurement at a number of other points within the architecture, including the outputs of sensor -\\nfusion, decision- making, and motion- planning stages. This proposed white -box scenario presents \\nadditional  challenges, such as gaining access to necessary subsystem interfaces for relevant data \\ncollection.  It should be noted that elements of the real -world environment, including \\nenvironment al conditions (e.g., road geometry, road surface, and infrastructure) and  tempo -\\nspatial motions of objects , can largely be controlled in track settings. Other conditions, such as \\nweather and ambient lighting, cannot necessarily be controlled. It should also be noted that, \\nregardless of whether some of those conditions can be controlled and replicated or not, the sheer \\nvariability of some ODD and OEDR -related conditions (e.g., quality of lane markers, amount of \\nrain or snow, roughness of road, orientation of objects and infrastructure) may make testing \\ncompleteness intractable. P rioritization of testing scenarios based on risk profiles was identified \\nas a key factor  in test scenario selection.73  \\nFigure 25. Notional ADS  Track Testing Architecture  \\nOpen- Road Testing  \\nPublic roads offer a “real -world laboratory” to support testing and evaluation of ADS . Several  \\nentities are actively testing prototype ADS  in public, open -road settings to support ongoing \\ndevelopment and refinement  (General Motors, 2016) , (Krok, 2017) , (Guardian, 2015) , (Lomas, \\n2017) . In addition to allowing a  full performance assessment of the  prototype systems, public \\nroads expose the systems to an extremely wide variety of real -world conditions related to ODD \\nand OEDR that would not be feasible with established closed test tracks.   \\nHowever, open- road testing for ADS  also has several  drawbacks.  \\n• Lack of  controllability  – Public -road scenarios do not afford much, if any, control \\nover ODD and OEDR conditions . \\n• Lack of replicability  – Public -road scenarios are difficult to replicate exactly in \\ndifferent locations . \\n• Lack of repeatability  – Public -road scenario s are difficult to repeat exactly over \\nmultiple iterations . \\n• Limited scalability  – Public -road scenarios may not scale up well , as ADS  may \\nrequire additional data, such as a priori  digital maps . \\nFigure 26 represents a notional ADS  test architecture for open -road testing. It is important to \\nnote that very few of the system inputs are controllable or known. L ittle to no control exists over \\nthe primary system inputs (e.g., environmental conditions and real -world  information).  This \\ntesting technique may present a reasonable and critical  “final step” for evaluating systems further \\nalong in the development process.  \\nMeasurable\\nControllable / \\nKnown74  \\nFigure 26. Notional ADS  Open -Road Testing Architecture  \\nEfforts have been , and currently are , underway to provide guidance to developing organizations \\non the safe testing and validation of ADS , including in public -road settings  (SAE International, \\n2015; NHTSA, 2016a) . Some State s have investigated similar guidance  or, in some cases, \\nlegislation that governs the testing and deployment of ADS  on public roads within their State  \\nboundaries (Nowakowski, Shladover, Chan, & Tan, 2015) . Sinc e 2012, 41 State s and districts \\nhave considered such legislation (National Conference of State Legislatures, 2017) , although the \\ndegree to which this legislation addresses some of the primary concerns is uncertain and/or \\nvaried . In California, which has a considerable number  of companies testing ADS  on public \\nroads, t he California Department of Motor Vehicles requires those companies to submit annual \\ndisengagement reports that detail the number of autonomous miles driven, and th e number and \\nnature of safety driver interventions per test vehicle  (State of California Department of Motor \\nVehicles, 2017) . \\nTest Scenarios  \\nThe previous chapters summarized several  important functional components that drive the safe \\ndeployment of ADS , and the next chapter will summarize a final important component . The \\nfollowing components were identified as collectively making  up the core aspects of a common \\nADS  test scenario . \\n• Tactical maneuver behaviors  \\n• ODD elements  \\n• OEDR capabilities  \\n• Failure mode behavior s \\nMeasurable\\nControllable / \\nKnown75 Tactical maneuver behaviors relate to the immediate control -related task s the ADS  is executing \\nas part of the test (e.g., lane following, lane change, turning). The relevant ODD elements \\ngenerally define the operating environment in which the ADS  is navigating during the test (e.g., \\nroadway type, traffic conditions, or environmental conditions). OEDR capabilities relate directly to the objects and events the ADS  encounters during the test (e.g., vehicles, pedestrians, traffic \\nsignals). Finally, s ome tests may include injection or simulation of errors or faults that induce \\nfailures at various stages  within the ADS ’s functional architecture . Failure modes will be \\ndiscussed in more detail in Chapter 6.  \\nTest scenarios can be composed of one or more elements of each of these core components, visualized as the individual dimensions of the  multidimensional test matrix in Figure 27. Each of \\nthese components may be included in a checklist identifying the aspects of each category that are incorporated in a given test.  \\n \\nFigure 27. ADS  Test Scenario Matrix  \\nFor example, a sample ADS  test scenario for the L4 Highly Automated Vehicle /TNC f eature \\nmay be notionally described by the items indicated in Table 54. In this scenario, the primary \\ntactical maneuver behavior is the ADS  performing a low -speed merge into an adjacent lane. The \\nprimary OEDR behavior under test is detecting and responding to other vehicles in the target adjacent lane. The nominal ODD conditions place the test on a straight, flat arterial road  with \\nnon-degraded lane markers, nominal traffic, and a maximum speed limit of 72 kph ( 45 mph). \\nThe test occurs during the day with clear and dry conditions , and the ADS  is functioning as \\ndesigned.  \\nThis method of specifying a scenario descriptor could be established as a series of checklists:  one \\nchecklist for each dimension of the scenario test matrix shown in Figure 27. This \\nmultidimensional checklist approach would provide the high -level structure of the scenario test.76 Table 54. Sample ADS  Scenario Test Descriptor  \\nScenario Elements  Example  \\nTactical Maneuver Behavior s Perform lane change/low -speed merge  \\nODD Elements  Arterial roadway type  \\nAsphalt roadway surface  \\nLane markers  \\nStraight, flat  \\n72 kph (45 mph) speed limit  \\nNominal traffic  \\nClear, dry weather  \\nDaylight  \\n… \\nOEDR Behavior s Detect and respond to relevant adjacent  vehicle s (frontal, \\nside, rear)  \\nFailure Mode Behavior s N/A \\nThe underlying components of each category are then further defined and quantified to fully \\ndevelop a n actionable  set of scenario test procedures. For example, t he tactical maneuver \\nbehavior  could be further  specified to indicate  the direction of the lane change and how it will be \\ninduced (e.g., shift to adjacent left lane due to upcoming left turn). The  ODD elements could be \\nfurther  specified to indicate  radius of curvature and pitch for the  test road, time  of day and sun \\nposition at which the test will be conducted, and presence of surrounding infrastructure, if any. The OEDR behaviors could be further specified to indicate  the number of obstacle vehicles and \\ntheir initial conditions (e.g., positions, speeds, orientations) and trajectories during the test. Failure mode components could be further  specified to indicate  the exact failure that will be \\ninduced (e.g., GPS receiver failure) , as well as how and when it will be  induced (e.g., unplugging \\ncoaxial cable between GPS antenna and receiver after  ADS  has begun moving and before it \\nbegins changing lanes).  \\nAdditional information is necessary to further set the stage for the actual execution of the tests , \\nincluding vehicles (subject and object vehicles) and their roles. G eneral test procedures were \\nmodeled on prior tests conducted by NHTSA for CV technology, specifically a test for a n FCW  \\nsystem for commercial vehicles (Howe, Xu, Hoover, Elsasser, & Barickman, 2016) . Aspects of \\nthose test procedures include  the following. \\n• Ambient conditions  \\n• Sample t est personnel  \\n• Sample t est facilities  \\n• Sample t est equipment  \\n• Sample t est scenario  \\no Description  \\no Purpose  \\no Sample i nitial conditions  \\no Sample metrics77 o Sample e xecution of procedure  \\no Sample t rial validity  \\no Sample e valuation criteria  \\nA more detailed sample set of test scenarios and procedures  for the selected generic features, \\nincluding performing low -speed lane changes or merges,  are outlined in Appendix C . Each of \\nthese scenarios was generated for one of the selected generic features by identifying the elements \\nof the proposed test matrix in Figure 27. The  procedures define a test for a single scenario. There \\nare numerous  relevant scenarios related to an ADS  performing a low -speed merge, some of \\nwhich are shown in Figure 28, as well as most of the other behaviors . In these scenario \\nvisualizations, the ADS  is highlighted in green. These scenarios show a hypothetical progression \\nof testing, starting with a simple case with no vehicles in the adjacent lane and iteratively getting more complex to a situation where the vehicles in the adjacent lane are spaced such that there is insufficient room for the ADS  to safely merge.  \\n \\nFigure 28. Sample Low -Speed Merge Test Scenarios \\nThe scenario framework described here is flexible enough to support the de finition of test \\nscenarios that can apply to simulation, closed -track, and open -road testing. Some elements of the \\ntest procedures described above are more relevant to closed -track or open- road testing; however, \\nthose  elements can likely be modified or ignored for simulation -based testing (e.g., test \\npersonnel, test facilities).  The core components of the scenarios (tactical maneuver behaviors, \\nODD, OEDR behaviors, failure mode behaviors) lend themselves well to  configuration for  all \\nlegs of the testing architecture.  They also lend themselves well to defining scenarios for both \\nblack -box and white -box testing. One of the significant differences  for white -box testing will be \\nidentifying key interfaces for data measurement  to support performance metrics for evaluation  \\nthat may otherwise be unavailable for black -box testing techniques .  \\nThe framework can be leveraged to facilitate a progression of testing, where certain conditions are modified to in crease complexity (e.g., speeds and  trajectories  of the subject vehicle and \\nobstacles). This type of test progression supports identification of  behavior and performance78 boundaries and limits. Furthermore, the scenario framework lends itself well to constructing \\ncombinations or sequences of scenarios to extend an ADS  evaluation to include more \\ncomprehensive operational tests. Testing of specific scenarios or behaviors, while important, \\nmay have limited utility in assessing the safe operation of an ADS . Combining scenarios into \\noperational tests provide s a means to evaluate the system and assess the test space.  \\nTesting Challenges  \\nThe previous sections in this chapter have identified a framework to develop ADS  scenario tests, \\nand the methods to execute those tests. While this framework provides a flexible means to conduct ADS  evaluation, the challenges associated with these evaluations are numerous.  This \\nsection builds off prior work to identify several key challenges associated with testing ADS  \\n(Koopman & Wagner, 2016) . The list of cha llenges presented is not comprehensive but  is rather \\nintended to provide an initial working list.  \\nTwo primary categories of challenges to consider  when developing and conducting tests  were \\nidentified : (1) c hallenges associated with ADS  technology, and (2) c hallenges associated with \\ntest execution . \\nChallenges associated with ADS  technology focus on some of the characteristics of the \\ntechnology and the underlying implementations of the integrated hardware and software systems:  \\n• Probabilistic  and non- deterministic algorithms  – To meet some of the temporal \\nneeds  related to ADS  decision -making, many developers are leveraging algorithms \\nthat rely on heuristics  or probability to provide a “best guess” relatively quickly. This \\nleaves the system open to makin g incorrect decisions or decisions that vary from one \\niteration to the next, even when presented with identical or near -identical conditions. \\nThis lack of a repeatable system output  emphasizes that new testing methodologies  \\nmay be needed.  Probabilistic and non -deterministic algorithms are often used when \\nthe State  space is extremely large or even unbounded, making complete testing of all \\nconditions virtually impossible.  \\n• Machine learning  algorithms  – Many developers are also leveraging algorithms, \\nsuch a s convolutional neural networks, that allow the system to learn from experience \\nas it is exposed to new  conditions and scenarios. This similarly could result in the \\nADS  responding differently in tests with similar or identical situations.  \\n• Digital mapping  needs – Some prototype ADS (typically L 4 or L5 systems) us e a \\npriori  digital map information for localization and obstacle mapping. This effectively \\nlimits the geographic areas in which the ADS can function, and subsequently be \\ntested.  \\n• Regression testing  – Th e advent of over -the-air updates to software and firmware will \\nallow ADS  developers to push out new features and fix defects rapidly. These updates \\ncould potentially have significant impacts on overall system performance that may augment or even invalidate  prior test results.79 The c hallenges associated with the  execution of tests on ADS  highlight the expansiveness of the \\nconditions that  vehicles may encounter and handle with minimal, if any, input or guidance from \\na human. These challenges, among others, include:  \\n• Testing completeness – The number of tests or miles driven (Kalra & Paddock , \\n2016)  required to achieve statistical significan ce to claim  safe operation could be \\nstaggering.  \\n• Testing execution controllability  – Without a driver to direct the vehicle, new tools \\nor methods may be needed to direct the ADS  to conduct the test in the desired manner \\n(e.g., follow desired route/trajector y, force encounters with objects) . \\n• Testing scalability  – It will be difficult to achieve significant coverage of the variety \\nand combination of conceivable test conditions, particularly related to ODD and \\nOEDR.  \\n• Unknown or unclear constraints /operating cond itions  – There are a substantial \\nnumber of real -world corner cases (e.g., missing lane markers, missing signage) that \\nmay present the ADS  with a situation in which it does not have all the necessary \\ninformation. The appropriate response may be clear (e.g., transition to MRC ); \\nhowever, identifying and testing against all those corner cases may be intractable . \\n• Degraded testing  – Testing against ideal conditions provides a good starting point but  \\nestablishing tests against even “reasonable worst case” scenarios (e.g., degraded lane markers, rain, snow, shadows) will be cumbersome . \\n• Infrastructure considerations  – Changes to key infrastructure elements (e.g., road \\nsurface, lane markings, signs) may have substantial impacts on ADS  performance.  \\n• Laws and regulations  – Driving laws vary within and across State  lines, can change, \\nand in some cases and to a certain extent are open to interpretation. Successful tests \\nagainst certain laws and regulations may  not be transferable.  \\n• Assumptions  – Establishing tests with certain assumptions or expectations (e.g., other \\nvehicles obey rules of road and follow driving etiquette) may oversimplify the scenarios such that they are unrealistic or lose value from an assessment standpoint . \\nInternational ADS  Testing Programs  \\nA few international programs related to ADS  testing that may be relevant or complement  the \\ngoals of this research  were identified .  \\nAdaptIVe  \\nThe AdaptIVe Automated Driving project , which recently concluded, involved 28 partners from \\neight different countries in Europe to further applications for automated driving through \\ncollaborative development and testing (AdaptIVe, 2017) . The program addressed SAE \\nInternational L 1 through L4 systems, and evaluated other aspects of automated driving, including \\nhuman factors and legal issues. The AdaptIVe project evaluated several  scenarios that were \\ncategorized as the following.80 • Close -distance scenarios – garage parking (L3), stop- and-go tra ffic (L3), safe stop \\n(L4) \\n• Urban scenarios – city chauffeur (L3), safe stop (L4)  \\n• Highway scenarios – lane change (L3), lane/vehicle following (L3), safe stop (L4)  \\nThe program also addressed evaluation methods for ADS  for four key areas . \\n• Technical assessment  – performance of ADS  features  \\n• User -related assessment – interaction between user and ADS  features  \\n• In-traffic assessment – effects of ADS  on surrounding traffic and non- users \\n• Impact assessment – effects of A DS features on safety and environmental aspects  \\nPEGASUS  \\nPreviously referenced in Chapter 3, t he PEGASUS P roject  has goal s of: \\n• Defining standardized procedures for ADS  testing and experiment ation  in simulation, \\non test stands, and in real environments ; \\n• Developing a continuous and fl exible tool chain to safeguard automated driving ; \\n• Integrating tests in the development process at an early stage ; and  \\n• Creating a cross- manufacturer method for safeguarding highly automated driving \\nfunctions . \\nThe program involves 17 partners, including OEMs , Tier 1 suppliers, test labs, and scientific \\ninstitutes. An important aspect of the program is the identification and generation of scenarios at \\nvarious levels  of abstraction. Furthermore, the program seeks to implement some of these \\nscenario tests using simulation, closed- track testing, and open- road testing, and seeks to identify \\nformal performance metrics for those test techniques.  Similar to this work, a subset of available \\nADS features was selected for analysis and testing.  \\nSUMMARY \\nThis task identifie d and developed a n example of a  flexible testing framework for ADS , as well \\nas preliminary tests and procedures. The framework leverages existing testing techniques, \\nnamely M&S , closed -track testing, and open- road testing. Each of these techniques has \\nadva ntages and disadvantages for assessing the performance of ADS  features, but when used \\ntogether in a potentially iterative process, they can provide a comprehensive evaluation framework . M&S  can provide significant coverage of a wide variety of test conditions in an \\nefficient manner. M&S  can be used to perform test variable sensitivity analyses and  can help to \\nprioritize scenarios for further evaluation. Closed -track testing uses physical sys tems and objects \\nto set up lifelike scenarios in a controlled setting. Open -road testing affords an opportunity to \\nassess full system performance in a real -world, unpredictable , and uncontrollable environment. \\nThis chapter established a flexible ADS  test scenario framework that built on the other key \\ntesting components  identified in this research —tactical maneuver behaviors, ODD elements,81 OEDR behaviors, and failure mode behaviors. This framework identified a multidimensional \\napproach to specifying the key test scenario data inputs, based on those four test components. \\nThis framework is flexible enough to add or modify specific items within those components, as new maneuvers or OEDR behaviors are identified, and allows for the efficient design  of new \\ntests. The flexibility of the framework is also manifest in that it can be used for all the testing techniques mentioned above. High-level test procedures are proposed for a set of sample \\nscenarios to further define how tests could be executed and what data to collect to measure performance.  \\nSeveral  challenges were identified with the assessment of ADS  that could be categorized as \\nchallenges associated with the ADS  technology itself and challenges associated with executing \\ntests on ADS . To a certain extent, the testing architecture and scenario framework can be \\nleveraged to address some of those challenges. The chapter a lso described  international research \\nprograms that share the common  goal of finding ways to assess the performance of ADS .82 CHAPTER 6.  FAIL- OPERATIONAL AND FAIL- SAFE MECHANISMS  \\nOVERVIEW  \\nThis chapter describes an  assessment approach to FO and FS mechanisms for an ADS . ADS s \\nwill us e FO and FS mechanisms when the system does not function as intended. The se \\nmechanisms enable  an ADS  to attain an MRC that removes the vehicle and its occupants from \\nharm’s way, to the best extent possible. Defining, testing, and validating FO and FS strategies for \\nachieving a n MRC are important steps in ensuring the safe operation and deployment of ADS . \\nMRC is defin ed in SAE J3016 as : \\nA condition to which a user or an ADS may bring a vehicle after performing the DDT \\nfallback  in order to reduce the risk of a crash when a given trip  cannot or should not be \\ncompleted. \\nSAE J301 6 further state s: \\nAt level 3, given a DDT performance -relevant system failure in the ADS  or vehicle, the \\nDDT fallback -ready user  is expected to achieve a minimal risk condition when s/he \\ndetermines that it is necessary  \\n \\nAt levels 4 and 5, the ADS  is capable of automatically achieving a minimal risk condition \\nwhen necessary (i.e., due to ODD exit, if applicable, or a DDT performance -relevant \\nsystem failure in the ADS  or vehicle ). The characteristics of automated achievement of a \\nminimal risk condition at levels 4 and 5 will vary according to the type and extent of the system failure, the ODD (if any) for the ADS feature  in question, and the particular \\noperating conditions when the system failure  or ODD exit occurs. It may entail \\nautomatically bringing the vehicle to a stop within its curre nt travel path, or it may entail \\na more extensive maneuver designed to remove the vehicle from an active lane of traffic and/or to automatically return the vehicle to a dispatching facility.  \\nAs described in Chapter 5, the sample test framework includes failure mode behavior as one \\nimportant high- level dimension in defining test scenarios and procedures. The efforts undertaken \\nin this task help to frame how failure mo de behavior plays into that larger testing architecture , \\nwith the goal of evaluating an ADS  feature’s ability to achieve a n MRC. \\nAPPROACH  \\nAs stated previously, the appropriate failure mitigation strategy and resulting MRC is largely dependent on the type and nature of failures the ADS  experiences. To this end, an understanding \\nof potential ADS  failure modes is necessary. As such, a high -level failure analysis  was \\nperformed. The results of this analysis informed the assessm ent of FO and FS me chanisms. A \\nvariety of failure and hazard analysis techniques exist, including fault tree analysis, system \\nFMEA, FMECA , system -theoretic process analysis, and HazOp . System FMEA was identified \\nand selected as an initial approach  to devel op the high- level analysis needed to identify potential83 failures in  each subsystem of the representative functional architecture, as well as their causes \\nand impacts .  \\nFMEA analyses typically occur early in the design phase of a system, or potentially iter atively \\nthroughout the design, development, and testing phases. The general goal is to attempt to identify \\nand correct or address potential malfunctions before the system is available to  customers. An \\nFMEA can generally be broken down into the following st eps. \\n1. Identify potential failure modes  \\n2. Identify potential causes and effects of those failure modes  \\n3. Prioritize the failure modes based upon risk  \\n4. Identify an appropriate corrective action or mitigation strategy  \\nIn this process, existing reports and literature on ADS  failures, including from the Defense \\nAdvanced Research Projects Agency Grand and Urban Challenge s (DARPA, 2008) , as well as \\nengineering judgments  and prior experience in ADS  development and testing were leveraged and \\nconsidered. It was  assumed that a detailed failure analysis employing a range of techniques noted \\nabove has been performed on the base vehicle platform, and therefore efforts  were focused on \\ncomponents specifically related to the ADS . This allowed for a deeper dive into the ADS  \\nfunctional architecture presented in Figure 3. A more detailed architecture diagram, which  is a \\nworking diagram from the SA E International ORAD committee,  provided the basis for the high-\\nlevel FMEA  and is shown in Figure 2. Furthermore, failures that could have safety implications, \\nas opposed to failures that are merely an inconvenience, were prioritized . \\nA notional FMEA worksheet was used to perform the analys is, a summary of which is shown in \\nTable 55. The components of that worksheet are described as follows . \\n• Architecture Element s – System/subsystem from ADS  functional  architecture (e.g., \\nsensors – radar)  \\n• Function – P urpose the element serves (e.g., acquire range data to obstacles)  \\n• Failure Mode s – Possible ways the element can fail (e.g., hardware failure – loss of \\npower)  \\n• Potential Causes  – Potential reasons failure occurred (e.g., power cable disconnected)  \\n• Potential Effects  – Potential downstream implications of failure (e.g., object \\nsegmentation algorithm fails to identify lead vehicle, resulting in collision with lead \\nvehicle)  \\n• Occurrence  (O) – M easure of the likelihood the failure will occur  \\n• Severity  s – Measure of the severity of the effects if the failure did occur  \\n• Detectability  (D) – M easure of the ability of the system to detect the failure  \\n• Risk Priority Number (RPN)  – Overall measure of  risk associated with failure, \\ncomposed of occurrence  (O), severity (S), and detectability  (D): (𝑅𝑅𝑅𝑅𝑅𝑅 =𝑂𝑂∙𝑆𝑆𝐷𝐷�) \\n• Process Controls – M ethods or actions to eliminate or mitigate failure84 Table 55. Notional Worksheet for ADS FMEA  \\nArchitecture \\nElement s Function  Failure \\nMode s Potential \\nCauses  Potential \\nEffects  Occurrence  Severity  Detectability  RPN  \\nSensors  Lidar                 \\n  Radar                  \\n  …                 \\n \\nThis worksheet includes quantitative measures of occurrence, severity, and detectability to \\nultimately prioritize the failure modes according to their significance and risk . For this analysis, \\nthe types of failures and their impacts were of more interest t han their overall risk; however, the \\nteam completed the exercise for completeness. T he three metrics were evaluated  on a notional 0-\\n10 scale, with larger values indicating failures occurring more frequently, with higher severity, and with higher detectabil ity. Values for each were assigned based on research team discussion \\nand insight.  \\nThe failure modes and their implications in relation to the ADS  tactical maneuver behaviors \\nidentified in Chapter 2 and the OEDR behaviors identified in Chapter 5 were highlighted and \\nsummarized . As these behaviors  are common across many of the ADS  features, this then \\nprovided a similar mapping between failure modes and  those features.  \\nThe last  step outlined in the FMEA proc edure  above was completed to identify conceptual  FO \\nand FS mechanisms to mitigate identified failures.  FS mechanisms are employed when the ADS  \\ncannot continue to operate due to a significant failure. When this type of failure occurs, the system should fail in a predictable, controlled manner to the MRC. FO  mechanisms are \\nemployed when a failure occurs,  but the ADS  is still able to operate, albeit potentially with \\nreduced capabilities or only for a limited duration.  A variety of potential FS and FO options for \\nADS , as well as advantages, disadvantages, an d potential limitations for each  were identified and \\ndescribed . \\nThe test architecture and framework from Chapter 5  was revisited to incorporate testing and \\nvalidating failure mode behavior. The comprehensive testing architecture presented includes options for M&S , closed- track testing, and open- road testi ng. Inducing failures to evaluate an \\nADS ’s response adds a level of complexity and risk that may necessitate modified approaches or \\nprocedures to execute tests.  \\nSeveral other programs and ongoing activities related to failure mitigation techniques for ADS  \\nwere identified . USDOT’s Functional Safety Analysis of Automated Lane Centering Controls  \\n(Brewer & Najm, 2015)  program also include s analysis of failure mode s, and the SAE \\nInternational ORAD committee is currently discussing failure strategies for ADS .85 FINDINGS  \\nFailure Modes and Effects  \\nThe FMEA was broken down by architecture subsystems to identify potential key failures at \\neach step through the ADS  “pipeline .” \\n• Sensing and communication \\n• Perception  \\n• Navigation and c ontrol  \\n• HMI  \\nSensing  and Communication  \\nFailures related to sensing and communication focus  on hardware and software related to \\nexteroception, proprioception, and communication. Sensors related to exteroception acquire data \\nabout the external environment around the vehi cle. Some examples of exteroceptive sensors \\ninclude  radar, lidar, cameras, and ultrasonics. Sensors related to proprioception acquire data \\nabout the internal state of the vehicle, most commonly to support localization. Some examples of proprioceptive sensors include GPS, inertial measurement units, gyroscopes, wheel speed \\nsensors, compasses, steering wheel sensors, and brake pedal sensors. Communication equipment , \\nsuch as DSRC, cellular technology (3G/4G/LTE/5G), Wi -Fi, and Bluetooth, provide s wireless \\none-way or two -way transmission of data with other roadw ay users or with infrastructure.  The \\ndata acquired through communication could include information on other vehicles or roadway \\nusers (individual roadway users or larger traffic volumes and patterns), as well as information on \\nrelevant incidents, warnings, or infrastructure changes /updates  (e.g., traffic accidents , emergency \\nvehicles,  and temporary construction zones).  \\nFailure modes associated with exteroceptive sensors include loss of power, loss of data  \\nconnection, internal hardware failures, and emitter/receiver fouling (e.g., mud, dirt). Failure \\nmodes associated with  proprioceptive sensors similarly include loss of power, loss of data \\nconnection, internal hardware failures, and poor calibration/alignme nt. Failure modes associated \\nwith communication equipment  similarly include loss of power, loss of data connection, internal \\nhardware failure, and loss of external signal. Additionally, many of these sensors need software \\ndrivers that process the raw data coming from each sensor into data that are more ADS -friendly. \\nThese software drivers may fail, or may fail to produce the data at the desired rate, although this \\nmay similarly be caused by an internal fault or failure of the equipment itself.  \\nThe downstream effects of exteroceptive sensor failures could lead to the ADS  failing to detect \\nand track relevant obstacles  (e.g., fails to segment or classify another vehicle) , or the ADS  \\ninaccurately characterizing relevant obstacles (e.g., incorrectly estimates position or shape of object) . The effects of proprioceptive sensor failures could lead to the ADS  failing to accurately \\nestimate its internal state (e.g., relative and/or absolute position, orientation, speed). The effects of communication equipm ent failures could lead to the ADS  failing to account for or act on86 relevant warnings or updates  (e.g., fails to detect and react  to lane closure) . These failures \\nultimately lead to the ADS  being unable to perceive and model the surrounding environment  \\naccurately . \\nPerception  \\nFailures associated with  perception focus primarily on software algorithms related to sensor \\nprocessing, localization, and world modeling. Sensor processing involves algorithms to support \\nperception field segmentation (near -field/mid -field/far -field), roadway/terrain segmentation and \\nclassification, and object segmentation and classification. Localization involves algorithms for \\nabsolute and relative state estimation. World modeling involves algorithms to aggregate  \\ninformation from digital maps and other static and dynamic obstacle maps into a common coordinate frame, as well as incorporating known traffic rules and other virtual information (e.g., geo-fencing). \\nFailure modes associated with sensor processing include failing to model or detect the information for which the sensor was designed or  providing suboptimal results. Failure modes \\nassociated with localization include failing to estimate the state of the ADS , or more likely \\nproviding an inaccurate estimate. Failure modes associated with world modeling include failing \\nto appropriately combine and register the disparate data into a cohesive model or map, or more \\nlikely providing a suboptimal model or map. Failure modes for these perception tasks also include typical software failures, such as memory corruption , control flow errors, or calculation \\nerrors.  Similarly, these algorithms will be running on computing hardware, which could \\nexperience any of a number of failures , including internal hardware failures, loss of power, or \\nloss of data connection.  \\nThe downstream effects of failures associated with sensor processing could lead to the ADS  \\nignoring undetected objects or roadway features or  misinterpreting them . The effects of failures \\nassociated with localization include the ADS  losing track of its position and/or orientation and \\nbeing unable to safely navigate. The failures associated with world modeling lead to the system \\nmisrepresenting the environment in which the ADS  is operating. This could also include the \\nADS  failing to recognize that it is crossing an ODD or OEDR operational boundary. In general, \\nthese failures could lead to the ADS  making suboptimal or unsafe navigation decisions. \\nNavigation  and Control  \\nFailures associated with navigation focus primarily on software algorithms related to mission planning, maneuver/ trajectory  planning, and steering and speed control . Mission planning \\ninvolves algorithms to derive a high- level route for the ADS  to follow from its in itial location to \\na desired destination, potentially to include roads to follow and turns to take, and potentially considering travel time or distance. Man euver and trajectory  planning involve  algorithms to \\niteratively determine appropriate and safe motion s that allow the ADS  to make progress along its \\nhigh- level route. This includes determining the appropriate  tactical maneuver behaviors \\nidentified in Chapter 2, su ch as lane following, lane switching, merging, navigating intersections,87 and executing U -turns , as well as the optimal paths for the vehicle to follow  to execute those \\nbehaviors  and the appropriate and safe speeds at which to follow the prescribed path. St eering \\ncontrol involves algorithms to convert the initial, near- field segments of those paths into control \\ninputs to the steering actuator . Speed control involves algorithms to convert the target speed \\nalong the desired trajectory into control inputs to the ADS  throttle and brake actuators.  \\nFailure modes associated with mission planning include algorithm  failures where the high- level \\nroute is not generated (e.g., missing connect ion in digital map), or an inefficient or suboptimal \\nroute is generated  (e.g., route is not the shortest distance or duration possible). Failures \\nassociated with maneuver  planning include algorithm  failures  where a necessary maneuver is not \\nplanned (e.g., turn not recognized ) or an incorrect or inappropriate maneuver is planned (e.g., \\nincorrect lane change planned before upcoming turn) . Failures associated with trajectory \\nplanning include algorithm failures where  a feasible trajectory is not found to implem ent a \\nmaneuver (e.g., path to execute lane change  not generated, even if a feasible one exists, and \\nvehicle continues in current lane) , or the trajectory generated is incorrect or suboptimal. Failures \\nassociated with steering and speed control include algorithm failures where control inputs are not \\ngenerated or  are incorrect or suboptimal  in relation to the planned trajectory . \\nThe effects of failures associated with mission planning may include the ADS  being unable to \\nreach its desired destination or  follow ing an inefficient route to get there. Effects of failures \\nassociated with maneuver planning include the ADS  getting stuck or needing to recalculate its \\nmission route, or potentially executing unsafe maneuvers. Effects of failures associated with trajectory planning include the ADS  getting stuck, or potentially following unsafe paths. Effects \\nof failures associated with steering or speed control include the ADS  not accurately following its \\nplanned path, or not safely and stably maintaining the target speed. These lower -level navigation \\nfailures could have dire consequences in cases where the vehicle is navigating in complex \\nenvironments around many dynamic obstacles , ultimately leading to collisions . \\nHuman -Machine Interface \\nFailures associated with the vehicle interface  focus on hardware and software failures related to \\nvisual displays or audible or tactile warnings  that may otherwise be necessary to facilitate an \\noperator takeover . The HMI is crucial for occupied ADS  where the occupant may need to \\nperform the functions of a fallback -ready user in the event of a major failure. The HMI provide s \\ninformation about the state of the environment, as well as the internal state of the system  and its \\nability to function as inte nded. If any of this information is not provided, or the information \\nprovided is incorrect, the operator may either fail to retake control of the vehicle when necessary \\nor may lack vital information  or context to facilitate a safe takeover.   \\nFailure modes associated with the HMI include internal hardware failures such as a display, \\nspeaker, or tactile mechanism not function ing as intended (e.g., display screen dies, steering \\nwheels fails to vibrate). They also include software failures related to the presen tation of relevant88 data or warnings for the operator (e.g., misrepresenting automation status, not issuing an audible \\nwarning of imminent collision).  \\nDownstream effects of these failures include a delay in an operator retaking control of the \\nvehicle when requested, or the operator being uninformed that a takeover is necessary. Alternatively, the operator could successfully retake control, but could make poor decisions based on the misrepresentation or lack of data provided. These types of failures may be m itigated \\nin L4 systems, as the ADS  achieves  the MRC; however, for a L 3 system , these types of failures \\ncould be pertinent to safety . \\nSummary  \\nIn general, many of the ADS  failure modes described above could be attributed to failures of \\ninformation. T hese wer e summarized into three primary categories as failures attributed to:  \\n• No data – I nformation is absent altogether  \\n• Inadequate quality data – I nformation is of poor or degraded quality  \\n• Latent data  – Information is delayed or old  \\nFor each of these three categories, the temporal nature of the failure is also a key component to the resolution. Information failures can be transient/intermittent or persistent. Intermittent or transient data failures may be mitigated by filtering or the  recursive nature of many of the \\nelements of the functional architecture. They may also be more difficult to detect. Persistent data failures may be more severe but are also likely to manifest themselves relatively quickly and be \\neasier to detect. Many ADS  architectures will provide robustness to some of these failures by \\nfusing and filtering data from multiple sources (e.g., fusing data from a suite of perception sensors, filtering data from multiple relative and absolute localization sensors, e xtended Kal man \\nfilters). This robustness may still have a limited functional time horizon in the event of persistent \\nerrors or failures (e.g., state estimation drift accumulation).  \\nThe progression or propagation of failures through the ADS  architecture also presents a \\nchallenge. Small errors or faults that occur early in the pipeline (e.g., sensing failures)  may \\nultimately develop into more significant errors or faults at the end of the pipeline (e.g., the perception system does not identify an adjacent vehicle , resul ting in the navigation subsystem \\ngenerating a trajectory that leads to a collision).  Similarly, small simultaneous errors in disparate \\nsubsystems could potentially lead to unintended or  undesired emergent behavior. Providing \\nconfidence or other measures of  quality for output data at each step along the pipeline could \\nsupport identification of faults or failures early and allow for mitigation.  \\nThe effects of these failures were summarized into four primary categories, although each may build off the others . \\n• Suboptimal performance (e.g., hugging one side of a lane, driving slower than \\nallowed, taking an inefficient route or trajectory)89 • Unexpected/unpredictable behavior (e.g., sudden acceleration/deceleration, erratic \\nsteering oscillation)  \\n• Unsafe behavior (e.g., driving out of desired lane, not reacting to relevant obstacles)  \\n• Collisions  \\nFailures that result in suboptimal performance may mostly be benign and be more of an \\ninconvenience than a safety concern, although it may still be beneficial to identify and qua ntify \\nthem. Failures that result in unexpected or unsafe behavior or collisions are certainly a safety concern and need to receive careful consideration when developing a failure response strategy.  \\nLike the vastness of potential ODD s presented in Chapter 3, a wide variety of failure modes are \\npossible at each stage of the ADS  functional architecture. Coupling this with the extensive \\ncombination and propagation space of failures presents a significant challenge to deploying ADS  \\nsafely. The nature and extent of a single failure or sequence of failures plays a key role in determi ning the appropriate failure response.  \\nADS  Behavior Mapping  \\nAfter completing the FMEA for the ADS  architecture, the various failure modes and effects were \\nsummarized and mapped  to the relevant tactical maneuver and OEDR behaviors for the three \\ndown- sampled  ADS  features (L3 Traffic Jam Drive , L3 Highway Drive , and L4 Highly \\nAutomated Vehicle /TNC). This notionally provides a mapping from the specific failures \\nidentified in the FMEA, to the generalized failures summarized in the previous section, to the \\nbehavi ors implemented by various ADS  features.  \\nThis exercise could be extended to the other features identified in Chapter 2. A more thorough \\nanalysis and mapping could eventually provide a means to identify potential failure effects that are manifested in the testing architecture outlined in Chapter 5 . For example, if an ADS  under \\ntest could not safely and continuously maintain its specified lane, the test team could follow the detailed mapping back to identify possible root causes (e.g., relative localization solution instability caused by intermittent power failure in camera ta sked with detecting and tracking lane \\nmarkers).  \\nTable 56. L3 Traffic Jam Drive Failure  Mode/Effects Summary  \\nBehavior Failure  Effect s \\nFail to maintain lane  Impact adjacent vehicle or infrastructure  \\nFail to maintain safe following distance  Impact lead vehicle  \\nFail to detect and respond to maneuvers by other \\nvehicles  Impact lead or adjacent vehicles  \\nFail to detect relevant obstacle s in or near lane  Impact obstacle s \\nFail to identify ODD/OEDR boundary  Operate outside of ODD/OEDR capabilities90 Table 57. L3 Highway Drive  Failure Mode/Effects Summary  \\nBehavior Failure  Effect s \\nFail to maintain lane  Impact adjacent vehicle or infrastructure  \\nFail to maintain safe following distance  Impact lead vehicle  \\nFail to  maintain appropriate/safe speed  Exceed speed limit, lose stability, impact lead \\nvehicle  \\nFail to detect and respond to maneuvers by other \\nvehicles  Impact lead or adjacent vehicles  \\nFail to detect relevant obstacle s in or near lane  Impact obstacle s \\nFail to identify ODD/OEDR boundary  Operate outside of ODD/OEDR capabilities  \\n \\nTable 58. L4 Highly Automated Vehicle /TNC Failure Mode/Effects Summary  \\nBehavior Failure  Effect s \\nFail to maintain lane  Impact adjacent vehicle or infrastructure  \\nFail to maintain safe following distance  Impact lead vehicle  \\nFail to maintain appropriate/safe speed  Exceed speed limit, lose stability, impact lead \\nvehicle  \\nFail to maneuver appropriately/safely (e.g., lane \\nchange, intersection)  Impact vehicle s or infrastructure  \\nFail to detect and respond to maneuvers by other \\nvehicles  Impact lead or adjacent vehicles  \\nFail to detect relevant obstacle s in or near lane  Impact obstacle s \\nFail to obey traffic rules and etiquette  Impact vehicle s \\nFail to recognize and respond to nonstandard \\nhazards (e.g., work zones, emergency vehicles)  Navigate unsafely, impact obstacle s \\nFail to identify ODD/OEDR boundary  Operate outside of ODD/OEDR capabilities  \\n \\nFailure Mitigation Strategies  \\nBased on the general failure modes identified, potential failure mode responses  and strategies \\nwere identified . This effort focused on FS strategies for cases where the ADS  cannot continue to \\noperate due to a significant failure, and FO  strategies for cases where the ADS  could continue to \\noperate even in the face of a failure.  \\nFail-Safe Mechanisms  \\nThe primary goal of a n FS strategy  is to rapidly achieve a n MRC  where the vehicle and \\noccupants are safe. Three candidate FS mechanisms were considered for further evaluation.  \\n• Transition to fallback- ready user control  \\n• Safely stop in lane of travel  \\n• Safely m ove out of travel lane and stop91 For L 3 systems, requesting intervention by a fallback- ready user may be the primary FS strategy. \\nThis assumes that an operator is present and at tentive  to the HMI.  Furthermore , there is an \\nassumption that the  information being provided by the ADS  through the HMI  is appropriate to \\nreengage the operator . A challenge with this strategy is providing sufficient warning to the \\noperator before an interve ntion is needed. Prior s tudies have shown that the timing of this \\nwarning in L2 and L 3 systems can be substantial , depending on the nature of the event and the \\nalert provided (Blanco et al., 2015) . Furthermore, the ADS  feature needs to continue to function \\nuntil that transition occurs. Additional questions and challenges arise if the user is not fallback -\\nready (e.g., asleep and does not notice intervention request). This intervention request may also \\nbe a feasible FS st rategy for a L4 system, again assuming a fallback -ready user is present,  and \\nthe necessary information is available; however, L4 systems can achieve the MRC in the event \\nan operator is unavailable  or fails to act . \\nThe strategy of stopping in the current la ne of travel is a debated  approach with the technical and \\npolicy community. In this case, the ADS  may rapidly but safely decelerate to a stop while \\nmaintaining its current lane. The actions and time needed are minimal; however, there is considerable disagr eement as to whether this is a safe state for the vehicle, its occupants , and \\nother road users. The ODD and driving conditions play a role in answering this question. For example, stopping in an active lane of travel on a lower -speed urban road with good visibility  \\nmay be a relatively safe condition, whereas stopping in an active lane of travel on a higher -speed \\nrural highway after a blind curve may not fit the intent of  a safe state. The frequency, nature , and \\nexten t of the failure also play into answering  that question. For example, if one or more of the \\nADS ’s primary sensors fails and it cannot detect adjacent obstacles, stopping in an active lane of \\ntravel may be safer than attempting to maneuver out of the travel lanes to stop. Remote fleet \\nmanagement i ntegration could further support this strategy if a remote operator could be hailed \\nto assist in maneuvering the vehicle to a safe state.  \\nFinally, an ADS  maneuvering safely out of the active roadway and stopping/parking presents an \\nappealing FS mechanism. The frequency, nature , and extent of the failures, as well as the initial \\ndriving conditions, again play a role in determining if this is a viable strategy. For example, if the vehicle  is in a middle lane of a large freeway , a complicated set o f maneuvers conducted over a \\nsubstantial period of time may be necessary  to shift one or more lanes around adjacent traffic to \\nbe able to merge onto a shoulder or safe area to achieve the MRC. If one or more of  its primary \\nsensors has failed  or if no shoul der or safe harbor is available, then this strategy may be \\nimpractical.  \\nFail-Operational Mechanisms  \\nFO strategies allow the ADS  to continue to function, even in the event of one or more failures. It \\nis important to note that this operation may only be supported for a limited duration, or potentially with a reduced set of capabilities. T hree primary FO  mechanisms were considered for \\nfurther analysis .92 • Hardware/software redundancy  \\n• Adaptive compensation  \\n• Degraded operations  \\no Reduced top speed  \\no Reduced level of aut omation  \\no Reduced ODD  \\no Reduced maneuver capabilities  \\no Reduced OEDR capabilities  \\nIntegrating redundant hardware or software , which is more of a design strategy, provides \\nbackups for critical pieces of equipment or logical processes. For example, multiple identi cal \\nECUs running a steering control application could be installed on an ADS . In the event the \\nprimary ECU experienced a hardware failure, a logic mechanism could trigger the system to \\nbegin responding to outputs from the secondary ECU. This strategy may i mprove reliability and \\nrobustness from an operational standpoint  so as to allow the ADS  to continue to function. \\nHowever , this strategy increases cost, complexity, and potentially the “footprint” of the ADS  \\nfeature (e.g., needs additional power and cabling, takes up additional space).  \\nAdaptive compensation allows an ADS  subsystem to compensate for a failure in one or more \\ncomponents by relying more on other complementary components or processes, if available. For example, if a G PS receiver suffers a hardware failure and is providing noisy or intermittent data, \\nthe state estimation system could potentially reduce the weight of the GPS data and increase the weight on other available sensors (e.g., IMU, wheel -speed sensors) to conti nue to provide a \\nrobust, filtered solution. This strategy may work particularly well for subsystems that already \\nfuse data from multiple sources (e.g., perception and localization) , although possibly not for \\nothers . It is also possible that this compensati on technique is only effective for a limited amount \\nof time  (e.g., state estimator drift could cause vehicle to lose track of its absolute position over \\ntime if GPS or other absolute data are  not acquired) . This strategy may become less practical as \\ndevelopers seek to minimize components on their ADS  to move to market.  \\nFinally, a variety of degraded modes of operation exist that could allow an ADS  to continue to \\nfunction after a failure . Operating at a reduced speed is a useful tool for mitigating faults or  \\nfailures that are associated with constrained resources (e.g., network bandwidth, processing power, processing latency/lag). This strategy provides the ADS  additional time to evaluate a \\nscenario and make navigation decisions; however, it may be impractical or unsafe in some driving scenarios (e.g., freeway, HOV lane) . Operating at a reduced level of automation is \\nanother option, albeit one that may shift responsibility of one or more aspects of the DDT or fallback performance (e.g., reduction from L 4 to L 3 implies  a fallback -ready user  is available). \\nThis strategy may include emphasis on driver state monitoring, if applicable, to ensure that the operator is attentive and aware of the circumstances. It may therefore be impractical for ADS  \\nfeatures without a defined driver (e.g., L4 or L5 Highly Automated Vehicle /TNC feature, \\nautomated delivery vehicle). Operating with a  reduced ODD further limits the conditions and \\ndomain s in which the ADS  can function (e.g., daytime only, low -speed only).93 SUMMARY \\nThis task considered and analyzed potential failure modes for a generic ADS , and possible  \\nfailure mitigation strategies. A  high- level system FMEA was performed to identify failure modes \\nand their implications for the primary subsystems within the ADS  functional architecture . \\nFailures were primarily related to failures of information resulting from both physical and logical \\nfaults and errors. T he failure modes were generalized according to the severity of their effects, \\nand mapped to the tactical maneuver behaviors and OEDR behaviors identified in Chapter 2 and \\nChapter 4, respectively, as well as to the down -selected ADS  features.  \\nPotential mechanisms that allow ADS  to either fail safely when a critical failure occurs such that \\nthe vehicle cannot continue to function as designed, or  fail operationally when a failure occurs \\nsuch that the vehicle can continue to function, were identified and evaluated. FS strategies \\ngenerally attempt to achieve a n MRC as efficiently as possible, while FO  strategies generally \\nattempt to continue to perform the primary elements of the DDT, albeit potentially for a limited duration or with a reduced set of  capabilities. The identified FS and FO  strategies each have \\nadvantages and disadvantages. A hierarchy of these mechanisms may be necessary, as the \\nappropriate failure mitigation strategy will largely depend on the nature and extent of the \\nfailures, as well as the initial conditions present when the failure occurs.  \\nThe test scenario  framework and testing architecture were revisited to incorporate evaluation of \\nfailure response into the proposed architecture, as described in Chapter 5.  Failure mode behavior \\nlends itself to being included as a fourth dimension in the test scenario framework ( shown in \\nFigure 27) . M&S  may be well -suited  to efficiently and effectively evaluat e the wide variety of \\npotential failure modes  an ADS  could experience, as well as the wide var iety of initial conditions \\nin which it could fail. Common root causes of some failure modes, including noise and latency, \\ncan be modeled for virtual testing. Fault injection and failure analysis can occur safely in a virtual environment, but they present hazards when using real systems during closed -track or \\nopen- road testing. Furthermore, M&S  can support failure mode analysis early and iteratively \\nthrough the ADS  design and development process, long before prototype test vehicles or systems \\nare available.94 CHAPTER 7.  SUMMARY AND CONCLUSI ONS  \\nA functional  testing architecture and framework is an approach to support the safe deployment of \\nADS and  evaluate and assess their performance. This report describes an example  of a testing \\narchitecture and a scenario -based test framework.  Efforts focused on the testing of ADS  (SAE  \\nInternational  L3–L5), where the ADS  is fully capable of  all aspects of the DDT . To facilitate the \\nidentification of the testing architecture and framework , common and r elevant operational  \\ncomponents  for ADS  were identified and evaluated , specifically  these.  \\n• ADS  features \\n• ODD  \\n• OEDR  \\n• FO and FS strategies  \\nPrototype ADS  that have been conceived or that are currently under development  were surveyed . \\nA working list of 24 such proprietary systems  were identified  by performing a literature review \\nand interacting with stakeholders and  categorized into seven generic ADS  features. T hree of \\nthese generic features were down- selected to focus the remaining anal yses. P otential ODDs for \\nADS  were surveyed and identified, and a hierarchical ODD taxonomy was developed . An ADS ’s \\nODD is specified by the developing entity, but this taxonomy provides an early step in \\nestablishing an example of a common language that coul d be used. I mportant obstacles and \\nevents that ADS  are likely to encounter within their ODD  and potential response maneuvers and \\nactions were surveyed and identified. The objects and events were derived from an evaluation of \\nthe expected normal driving sce narios for the given ADS  features. P otential mitigation strategies \\nthat an ADS  could employ in the event of a failure  were also identified and evaluated . Both FO \\nand FS strategies were identified and assessed  for cases where the ADS  can or cannot continue to \\nfunction as intended.  \\nThe primary contribution of this report is the conceptual development of a test scenario framework that incorporates elements of each of these operational components. The framework uses a checklist -type approach to identify  high- level scenario tests by specifying relevant tactical \\nmaneuvers, ODD, OEDR, and potential failures. Each of these components are then further \\nspecified to develop a comprehensive set of procedures for a given scenario test. The scenario framework lends itself  well to being applied across the three testing techniques identified for the \\ntesting architecture ( M&S , closed -track testing, and open- road testing), although specific test \\nprocedures and implementations will vary, depending on the technique and tools use d. This test \\nscenario framework and the sample test procedures developed can provide a launching point to more comprehensive ADS  test development and ultimately, test execution. Figure 29 shows a \\nsample ADS test scenario visualization, with the principal elements notionally specified.  (In this \\nfigure, POV stands for principal other vehicle.)95  \\nFigure 29. Sample ADS Test Scenario  \\nThe expansivenes s of conceivable ODD, OEDR, and failure conditions presents a significant \\nchallenge to achieving comprehensive testing, even considering the test scenario framework \\nidentified during this project and described in this report. The concept of risk associated with driving scenarios, notionally based on probability and severity of occurrence, has helped focus the analyses of ODD, OEDR , and failure modes to identify an appropriate testing process. A \\n“reasonable worst case” approach may prove sufficient for gener al safety assessments; however, \\nit is necessary to extend testing beyond the reasonable cases to understand the performance boundaries and limitations of ADS . This report  also identifies M&S  capabilities and tools as a \\npotential approach to addressing the expansiveness of these test components, as well as their potential combinations. M&S  provide a number of features and advantages that make it suitable \\nto play a role in this type of testing . \\n• Highly repeatable and reliable  \\n• Rapid and inexpensive compared to other testing techniques  \\n• Able to cover a wide range of scenarios and conditions efficiently  \\n• Allow for assessment of impact of the sensitivity of those scenarios and conditions on \\nADS  performance  \\n• Allow for variance of test parameters to support estimation o f risk  \\n• Able to establish integrity of ADS  subsystems to reduce overall system testing \\nrequirements  \\n• Well -suited for certain types of fault  injection96 APPENDIX A.  OPERATIONAL DESIGN DOMAIN SAMPLES  \\nL3 CONDITIONAL TRAFF IC JAM DRIVE \\nODD CHECKLIST: L3 Conditional Traffic Jam Drive  \\nPHYSICAL INFRASTRUCTURE  \\nRoadway Types  \\nDivided highway  Y \\nUndivided highway  \\nN Arterial  \\nUrban  \\nRural  \\nParking (surface lots, structures, private/public)  \\nBridges  \\nMulti -lane /single lane  Multi -lane  \\nManaged lanes (HOV, HOT ,13 etc.)  Y \\nOn-off ramps  N Emergency evacuation routes  \\nOne way  \\nIf barriers present  Private roads  \\nReversible lanes  \\nIntersection Types  \\n- signaled  \\n- U-turns  \\n- 4-way vs. 3 -way vs. 2 -way \\n- stop sign  \\n- roundabout  \\n- merge lanes  \\n- left turn across traffic, one -way to one -way \\n- right turn  \\n- multiple turn lane  \\n- crosswalk  \\n- toll plaza  \\n- railroad crossing  Signaled (4 -way, 3 -way), toll \\nplaza  \\nOther    \\nRoadway Surfaces  \\nAsphalt  \\nY Concrete  \\nMixed  \\nGrating  \\nn/a Brick  \\nDirt \\n                                                 \\n13 HOT - high occupancy toll97 Gravel  \\nScraped road  \\nPartially occluded  \\nSpeed bumps  \\nPotholes  \\nGrass  \\nOther    \\nRoadway Edges & Markings  \\nLane markers  Clear markers  \\nTemporary  lane markers  N \\nShoulder (paved or gravel)  Limited to divided highway  \\nShoulder (grass)  Limited to divided highway  \\nLane barriers  Barrier, concrete or metal  \\nGrating  Y \\nRails  Barrier, concrete or metal  \\nCurb  N \\nCones  N \\nOther    \\nRoadway Geometry  \\nStraightaways  Y \\nCurves  \\nn/a Hills  \\nLateral crests  \\nCorners (Regular, Blind)  \\nNegative obstacles  \\nLane width  \\nOther  \\nOPERATION CONSTRAINTS  \\nSpeed Limits  \\nMinimum Speed Limit  0 mph  \\nMaximum Speed Limit  < 37 mph  \\nRelative to Surrounding Traffic  n/a \\nOther    \\nTraffic Conditions  \\nTraffic density  Only heavy traffic with \\npreceding vehicle to follow and \\nconvoy in adjacent lane  \\nAltered (Accident Emergency vehicle, \\nConstruction, Closed road, Special event)  n/a \\nOther98 OBJECTS  \\nSignage  \\nSigns ( e.g., stop, yield, pedestrian, railroad, \\nschool zone, etc.)  \\nN Traffic Signals (regular, flashing, school zone, fire \\ndept. zone)  \\nCrosswalks  \\nRailroad crossing  \\nStopped buses  \\nConstruction signage  \\nFirst responder signals  \\nDistress signals  \\nRoadway user signals  \\nHand signals  \\nOther    \\nRoadway Users  \\nVehicle types (cars, light trucks, large trucks, \\nbuses, motorcycles, wide -load, emergency \\nvehicles, construction or farming equipment, \\nhorse -drawn carriages/buggies)  Cars, trucks  \\nStopped vehicles  N \\nOther automated vehicles  Y \\nPedestrians  N \\nCyclists  N \\nOther    \\nNon -Roadway Users Obstacles  \\nAnimals (e.g., dogs, deer, etc.)  \\nN Shopping carts  \\nDebris (e.g., pieces of tire, trash, ladders)  \\nOther    \\nENVIRONMENTAL CONDITIONS  \\nWeather  \\nWind  \\nNo information available at this \\ntime, but potentially may \\ninclude mild rain and typical \\ntemp eratures  Rain  \\nSnow  \\nSleet  \\nTemperature  \\nOther    \\nWeather -Induced Roadway Conditions  \\nStanding Water  \\nNo information available at this \\ntime  Flooded Roadways  \\nIcy Roads  \\nSnow on Road99 Other    \\nParticulate Matter  \\nFog \\nNo information available at this \\ntime  Smoke  \\nSmog  \\nDust/Dirt  \\nMud  \\nOther    \\nIllumination  \\nDay (sun: Overhead, Back- lighting and Front -\\nlighting)  \\nNo information available at this \\ntime  Dawn  \\nDusk  \\nNight  \\nStreet lights  \\nHeadlights (Regular & High -Beam)  \\nOncoming vehicle lights (Overhead Lighting, \\nBack -lighting & Front -lighting)  \\nOther    \\nCONNECTIVITY  \\nVehicles  \\nV2I and V2V communications  May have V2I to warn if driver \\nincapacitated  \\nEmergency vehicles  N \\nOther    \\nRemote Fleet Management System  \\nDoes the system require an operations center?  \\nN Does remote operation expand ODD or support \\nfault handling?  \\nOther    \\nInfrastructure Sensors  \\nWork zone alerts  \\nN Vulnerable road user  \\nRouting and incident management  \\nOther    \\nDigital Infrastructure  \\nGPS Y \\n3-D Maps  Y \\nPothole Locations  No information available at this \\ntime  Weather Data  \\nInfrastructure Data  \\nOther100 ZONES  \\nGeofencing  \\nCBDs  \\nNo information available at this \\ntime  School Campuses  \\nRetirement Communities  \\nFixed Route  \\nOther    \\nTraffic Management Zones  \\nTemporary Closures  \\nNo information available at this \\ntime  Dynamic Traffic Signs  \\nVariable Speed Limits  \\nTemporary or Non -Existent Lane Marking  \\nHuman -Directed Traffic  \\nLoading and Unloading Zones  \\nOther    \\nSchool/construction zones  \\nDynamic speed limit  No information available at this \\ntime  Erratic pedestrian  \\nVehicular behaviors  \\nOther    \\nRegions/ State s \\nLegal /Regulatory  No information available at this \\ntime  Enforcement Considerations  \\nTort  \\nOther    \\nInterference Zones  \\nTunnels  \\nNo information available at this \\ntime  Parking Garage  \\nDense Foliage  \\nLimited GPS \\nAtmospheric Conditions  \\nOther101 L3 CONDITIONAL HIGHW AY DRIVE  \\nODD CHECKLIST: L3 Conditional Highway Drive  \\nPHYSICAL INFRASTRUCTURE  \\nRoadway Types  \\nDivided highway  Y \\nUndivided highway  \\nN Arterial  \\nUrban  \\nRural  \\nParking (surface lots, structures, private/public)  \\nBridges  \\nMulti -lane /single lane  Multi -lane/ single lane  \\nManaged lanes (HOV, HOT, etc.)  Y \\nOn-off ramps  Y \\nEmergency evacuation routes  Y \\nOne way  \\nIf barriers present  Private roads  \\nReversible lanes  \\nIntersection Types  \\n- signaled  \\n- U-turns  \\n- 4-way vs. 3 -way vs. 2 -way \\n- stop sign  \\n- roundabout  \\n- merge lanes  \\n- left turn across traffic, one -way to one -way \\n- right turn  \\n- multiple turn lane  \\n- crosswalk  \\n- toll plaza  \\n- railroad crossing  Merge lanes, no intersections, \\nlimited infor mation on other \\nelements  \\nOther    \\nRoadway Surfaces  \\nAsphalt  \\nY Concrete  \\nMixed  \\nGrating  \\nn/a Brick  \\nDirt \\nGravel  \\nScraped road  \\nPartially occluded102 Speed bumps  \\nPotholes  \\nGrass  \\nOther    \\nRoadway Edges & Markings  \\nLane markers  Clear markers  \\nTemporarily lane markers  N \\nShoulder (paved or gravel)  Limited to divided highway  \\nShoulder (grass)  Limited to divided highway  \\nLane barriers  Y \\nGrating  Y \\nRails  Y \\nCurb  N \\nCones  N \\nOther    \\nRoadway Geometry  \\nStraightaways  Y \\nCurves  \\nn/a Hills  \\nLateral crests  \\nCorners (Regular, Blind)  \\nNegative obstacles  \\nLane width  \\nOther  \\nOPERATION CONSTRAINTS  \\nSpeed Limits  \\nMinimum Speed Limit  0 mph  \\nMaximum Speed Limit  Speed limit (55 -70 mph)  \\nRelative to Surrounding Traffic  n/a \\nOther    \\nTraffic Conditions  \\nTraffic density  No traffic restrictions  \\nAltered (Accident Emergency vehicle, \\nConstruction, Closed road, Special event)  n/a \\nOther    \\nOBJECTS  \\nSignage  \\nSigns ( e.g., stop, yield, pedestrian, railroad, \\nschool zone, etc.)  \\nN Traffic Signals (regular, flashing, school zone, fire \\ndept. zone)  \\nCrosswalks  \\nRailroad crossing103 Stopped buses  \\nConstruction signage  \\nFirst responder signals  \\nDistress signals  \\nRoadway user signals  \\nHand signals  \\nOther    \\nRoadway Users  \\nVehicle types (cars, light trucks, large trucks, \\nbuses, motorcycles, wide -load, emergency \\nvehicles, construction or farming equipment, \\nhorse -drawn carriages/buggies)  Cars, trucks  \\nStopped vehicles  N \\nOther automated vehicles  Y \\nPedestrians  N \\nCyclists  N \\nOther    \\nNon -Roadway Users Obstacles  \\nAnimals (e.g., dogs, deer, etc.)  \\nY Shopping carts  \\nDebris (e.g., pieces of tire, trash, ladders)  \\nOther    \\nENVIRONMENTAL CONDITIONS  \\nWeather  \\nWind  \\nNo information available at this \\ntime, but potentially may \\ninclude mild rain and typical \\ntemp eratures  Rain  \\nSnow  \\nSleet  \\nTemperature  \\nOther    \\nWeather -Induced Roadway Conditions  \\nStanding Water  \\nNo information available at this \\ntime  Flooded Roadways  \\nIcy Roads  \\nSnow on Road  \\nOther    \\nParticulate Matter  \\nFog \\nNo information available at this \\ntime  Smoke  \\nSmog  \\nDust/Dirt  \\nMud104 Other    \\nIllumination  \\nDay (sun: Overhead, Back -lighting and Front -\\nlighting)  \\nNo information available at this \\ntime  Dawn  \\nDusk  \\nNight  \\nStreet lights  \\nHeadlights (Regular & High -Beam)  \\nOncoming vehicle lights (Overhead Lighting, \\nBack -lighting & Front -lighting)  \\nOther    \\nCONNECTIVITY  \\nVehicles  \\nV2I and V2V communications  May have V2I to warn if driver \\nincapacitated  \\nEmergency vehicles  N \\nOther    \\nRemote Fleet Management System  \\nDoes the system require an operations center?  \\nN Does remote operation expand ODD or support \\nfault handling?  \\nOther    \\nInfrastructure Sensors  \\nWork zone alerts  \\nN Vulnerable road user  \\nRouting and incident management  \\nOther    \\nDigital Infrastructure  \\nGPS Y \\n3-D Maps  Y \\nPothole Locations  No information available at this \\ntime  Weather Data  \\nInfrastructure Data  \\nOther    \\nZONES  \\nGeofencing  \\nCBDs  \\nNo information available at this \\ntime  School Campuses  \\nRetirement Communities  \\nFixed Route  \\nOther105 Traffic Management Zones  \\nTemporary Closures  \\nNo information available at this \\ntime  Dynamic Traffic Signs  \\nVariable Speed Limits  \\nTemporary or Non -Existent Lane Marking  \\nHuman -Directed Traffic  \\nLoading and Unloading Zones  \\nOther    \\nSchool/construction  zones  \\nDynamic speed limit  No information available at this \\ntime  Erratic pedestrian  \\nVehicular behaviors  \\nOther    \\nRegions/ State s \\nLegal /Regulatory  No information available at this \\ntime  Enforcement Considerations  \\nTort  \\nOther    \\nInterference Zones  \\nTunnels  \\nNo information available at this \\ntime  Parking Garage  \\nDense Foliage  \\nLimited GPS  \\nAtmospheric Conditions  \\nOther106 L4 HIGHLY AUTOMATED TNC \\nODD CHECKLIST: L4 Highly Automated TNC  \\nPHYSICAL INFRASTRUCTURE  \\nRoadway Types  \\nDivided highway  \\nY Undivided highway  \\nArterial  \\nUrban  \\nRural  \\nParking (surface lots, structures, private/public)  \\nBridges  \\nMulti -lane /single lane  \\nManaged lanes (HOV, HOT, etc.)  \\nNo information available at this time  On-off ramps  \\nEmergency evacuation routes  \\nOne way \\nPrivate roads  \\nReversible lanes  \\nIntersection Types  \\n- signaled  \\n- U-turns  \\n- 4-way vs. 3 -way vs. 2 -way \\n- stop sign  \\n- roundabout  \\n- merge lanes  \\n- left turn across traffic, one -way to one -way \\n- right turn  \\n- multiple turn lane  \\n- crosswalk  \\n- toll plaza  \\n- railroad crossing  Yes to signalized intersections, 4 -way, \\n3-way, and 2 -way intersections, stop \\nsigns, left turn across traffic, right \\nturn.  \\n \\nNo information on roundabout, \\nmerge, multiple turn lane, toll plaza \\nand railroad crossings  \\nOther    \\nRoadway Surfaces  \\nAsphalt  Y Concrete  \\nMixed    \\nGrating  \\nNo information is available  Brick  \\nDirt \\nGravel  \\nScraped road  \\nPartially occluded107 Speed bumps  \\nPotholes  \\nGrass  \\nOther    \\nRoadway Edges & Markings  \\nLane markers  Clear markers  \\nTemporarily lane markers  \\nNo information available, but several \\nof these are likely to be needed to \\nenable travel across a city, including \\nconcrete barrier, grating, rail, curb  Shoulder (paved or gravel)  \\nShoulder (grass)  \\nConcrete barriers  \\nGrating  \\nRails  \\nCurb  \\nCones  \\nOther    \\nRoadway Geometry  \\nStraightaways  \\nY Curves  \\nHills  \\nLateral crests  \\nCorners (Regular, Blind)  \\nNegative obstacles  \\nLane width  \\nOther    \\nOPERATION CONSTRAINTS  \\nSpeed Limits  \\nMinimum Speed Limit  At least 35 mph is likely to be needed \\nto traverse a city  Maximum Speed Limit  \\nRelative to Surrounding Traffic  n/a \\nOther    \\nTraffic Conditions  \\nTraffic density  All conditions  \\nAltered (Accident Emergency vehicle, \\nConstruction, Closed road, Special event)  Y \\nOther    \\nOBJECTS  \\nSignage  \\nSigns ( e.g., stop, yield, pedestrian, railroad, \\nschool zone, etc.)  \\nYes, most if not all of these will be \\nnecessary  to operate across a city  Traffic Signals (regular, flashing, school zone, fire \\ndept. zone)  \\nCrosswalks  \\nRailroad crossing108 Stopped buses  \\nConstruction signage  \\nFirst responder signals  \\nDistress signals  \\nRoadway user signals  \\nHand signals  \\nOther    \\nRoadway Users  \\nVehicle types (cars, light trucks, large trucks, \\nbuses, motorcycles, wide -load, emergency \\nvehicles, construction or farming equipment, \\nhorse -drawn carriages/buggies)  Y Stopped vehicles  \\nOther automated vehicles  \\nPedestrians  \\nCyclists  \\nOther    \\nNon -Roadway Users Obstacles  \\nAnimals (e.g., dogs, deer, etc.)  \\nY Shopping carts  \\nDebris (e.g., pieces of tire, trash, ladders)  \\nOther    \\nENVIRONMENTAL CONDITIONS  \\nWeather  \\nWind  \\nLikely limited capability  Rain  \\nSnow  \\nSleet  No information available at this time  Temperature  \\nOther    \\nWeather -Induced Roadway Conditions  \\nStanding Water  \\nNo information available at this time  Flooded Roadways  \\nIcy Roads  \\nSnow on Road  \\nOther    \\nParticulate Matter  \\nFog \\nLimited capability  Smoke  \\nSmog  \\nDust/Dirt  \\nMud  \\nOther109 Illumination  \\nDay (sun: Overhead, Back -lighting and Front -\\nlighting)  \\nY Dawn  \\nDusk  \\nNight  \\nStreet lights  \\nHeadlights (Regular & High -Beam)  \\nOncoming vehicle lights (Overhead Lighting, \\nBack -lighting & Front -lighting)  No information available at this time  \\nOther    \\nCONNECTIVITY  \\nVehicles  \\nV2I and V2V communications  No de finitive information; \\nconnectivity is being tested by many \\npotential implementers  \\nEmergency vehicles  No information available  \\nOther    \\nRemote Fleet Management System  \\nDoes the system require an operations center?  \\nNo information available at this time  Does remote operation expand ODD or support \\nfault handling?  \\nOther    \\nInfrastructure Sensors  \\nWork zone alerts  \\nNo information available at this time  Vulnerable road user  \\nRouting and incident management  \\nOther    \\nDigital Infrastructure  \\nGPS \\nNo information available at this time  3-D Maps  \\nPothole Locations  \\nWeather Data  \\nInfrastructure Data  \\nOther    \\nZONES  \\nGeofencing  \\nCBDs  Y \\nSchool Campuses  \\nNo information available at this time  Retirement Communities  \\nFixed Route  \\nOther110 Traffic Management Zones  \\nTemporary Closures  \\nNo information available at this time  Dynamic Traffic Signs  \\nVariable Speed Limits  \\nTemporary or Non -Existent Lane Marking  \\nHuman -Directed Traffic  \\nLoading and Unloading Zones  N  \\nOther    \\nSchool/construction zones  \\nDynamic speed limit  \\nNo information available at this time  Erratic pedestrian  \\nVehicular behaviors  \\nOther    \\nRegions/ State s \\nLegal /Regulatory  \\nNo information available at this time  Enforcement Considerations  \\nTort  \\nOther    \\nInterference Zones  \\nTunnels  No information  \\nParking Garage  Y \\nDense Foliage  \\nNo information  Limited GPS  \\nAtmospheric Conditions  \\nOther111 APPENDIX B.  MODELING AND SIMULATION FOR SCENARIO TESTING  \\nAs described in Chapter 5, M&S could offer a good basis for scenario testing  of ADS . \\nSimulation -based tests feature highly repeatable and reliable testing platforms due to the \\ncontrolled environments established by the models. Additionally, software -based simulation \\nprovides  a rapid and inexpensive testing platform. In addition, certain types of M&S enable \\ncontrolled testing of micro - to macro -scale models (e.g., vehicle subsystems or a large -scale \\ntransportation network , respectively ). The modular nature of M&S tools  makes them suitable for \\nthe testing of systems or subsystems or both.  \\nADS s are complex , with multiple subsystems interacting with each other. Modeling \\ntransportation networks enable s the testing of ADS  in their entirety and individual subsystems \\nunder different operational environments. Such M&S -based methods are increasingl y becoming \\nthe industry method of choice for certain types of testing of ADS  and ADS subsystems before \\nthey go into the field for controlled -environment and open- road field tests .14 \\nConsider the functional diagram of an ADS . As shown in Figure 30 below, a typical ADS \\nconsists of five modules/processes which are active as an iterative list that is enacted at a high \\nfrequency.  \\n \\nFigure 30. Simplified ADS Functional Flow Diagram  \\nThe modules/processes are:  \\n1. Sensing – A  variety of sensors , such as radar, lidar , etc., detect  external stimuli and \\ncommunica te with external agents, such as other vehicles, the cloud environment, and \\ninfrastructure.  \\n2. Perception and Mapping – High-accuracy localization and output from sensing and \\ncommunication are used to understand the externalities that the vehicle is subject to.  \\n                                                 \\n14 For example, Alphabet’s Waymo has been using a custom -designed simulation system named “Carcraft,” to test its self -driving vehicle \\nsoftware under different o perational characteristics and detection parameters. Similarly, automated driving OEMs use software such as \\nCognata to conduct “virtual tests” of its systems prior to deploying the code for on -road tests.112 3. Develop W orld M odel – A world model is developed based on the perception and \\nmapping tha t defines the persistent and transient state of the vehicle.  \\n4. Navigation /Planning De cisions – Navigation and planning are performed based on the \\npath- planning algorithms defined within the ADS.  \\n5. Vehicle D ynamics and C ontrol  – Vehicle dynamic and control processes take place as a \\nconsequence of navigation and planning decisions and trajectory calculations.  \\nPlease note that this set of iterative processes represents a simplified ADS  and that each of the \\nprocesses consists of smaller processes and subsystem s. M&S may be a suitable method to test \\nthe entire system or individual subsystems and is being used effectively by industry to \\ncontinuously improve driving algorithms. Applications of M&S in testing  of ADS are numerous \\nand are supported by different types of  simulation:  \\n1. Parameter c haracterization – By simulating a range of operational parameters such as \\nvisibility, sensing, communication delay, and world model completeness, this kind of \\ntesting will help evaluate the parameters that form the ODD of the ADS.  \\n2. Subsystem t esting – Based on the functional diagram, M &S can be used to test different \\nsubsystems. For example, a sensor fusion simulation tool can be used to assess how noises in the provided sensor data transform to the developed world model and associated ADS  actions.  \\n3. Decision modules  – M&S can also be used to perform system testing under different \\noperational conditions to allow testing of the entire ADS based on its navigation decisions under each event. \\n4. Fault detection – M&S can also be used to evaluate a system or subsystem’s ability to recognize and resp ond to faults or failures.  \\nSome of these use cases are described further below . \\nParameter Characterization  \\nTo support the validation and verification of ADS , it is vital to understand the range of \\noperational parameters that form the system ’s ODD. F ull-range parameter testing will help to \\ndetermin e that range and  is conducted through Monte Carlo simulations of different parameters \\nthat define an ODD. For example, the range of visibility under which the machine -vision \\nalgorithm can confidently parse the sensor data can be assessed by providing sensor cloud data \\nthat emulates different levels of lighting.  \\nSubsystem Testing  \\nAs discussed in Chapter 5, the modular nature  of simulations allows SIL and HIL  simulations. \\nThese are excellent options when conducting subsystem testing, where components of a fully \\nknown simulation setup are replaced with testable subsystems. For example, to  test the \\nnavigation and path- planning algorithms, a n SIL system can be configured where the path-\\nplanning algorithms interact with a variety of world  models and provide output to the vehicle \\ndynamics models. By assessing the stability of the models to deal with different situations, \\nsubsystem testing can be done to support overall performance assessment .113 HIL tests can be performed, for example, to assess how sensors react to identifying objects  (such \\nas sign boards and pedestrians under different lighting conditions ) by how they translate to the \\ndevelopment of world models. C onducting subsystem testing involves emulating an ADS as a \\nmodular system that is representative of the feature . Several simulation programs exist that can \\nbe used to emulate components of a typical ADS. Some examples are p rovided in the following \\ntable.  \\nTable 59. Simulation Software Examples  \\nSimulated  \\nADS \\nProcess  Simulation Type  Description  Example Software \\nApplications  \\n1a, 2  Sensor Fusion  Represents applications that emulate sensor \\ndata when an environment is presented to \\nthem. The sensor data could be developed \\neither in the form of vector graphics or as a \\nsensor point cloud.  MATLAB ADS \\nToolbox  \\n1b V2V/V2I \\nCommunication  Represents applications that emulate \\ncommunications interaction between vehicles and other infrastructure elements so that parameters such as latency and error rates can \\nbe incorporated into data packets.  Riverside Modeler, \\nOMNET , etc. \\n3 Simulate World \\nModels  Represents applications that emulate the world \\nmodel, either based on sensor data or from a known environment.  Cognata, MATLAB \\nADS  \\n5 Vehicle \\nDynamics  Represents applications that emulate the \\nphysical characteristics of a vehicle when \\nsubject to path -planning and navigation \\ndecisions.  Simulink, CarSim , \\netc. \\nProcess  Transportation \\nNetwork Modeling  Represents applications that can emulate V2V , \\nV2I, and vehicle -to-pedestrian interaction with \\nrespect to the navigation of each of the \\nelements in a transportation network.  Vissim, Aimsun, \\nTransModeler , etc. \\n \\nFault Detection  \\nAs discussed in Chapter 6, ADS  may be prone to a wide variety of faults that could lead to the \\nsystem not performing as expected or intended. Many types of errors can be modeled and \\nincorporated into a virtual environment to induce faults or failures (e.g., sensor noise, hardware failure). M&S can be used to efficiently and safely replicate a significant amount of the potential faults and failures, and therefore allow for analysis of the ADS ’s implemented failure mitigation \\nstrategies. Critical failures can be induced to elicit a n FS response, while non- critical failures can \\nbe induced to eli cit an FO  response.114 APPENDIX C.  SAMPLE TEST PROCEDURES  \\nPERFORM LANE CHANGE/ LOW -SPEED MERGE  \\nODD Characteristics  \\n• Multi -lane divided highway (or similar)  \\n• Asphalt or concrete  \\n• Straight, flat  \\n• Clear lane markers  \\n• Clear sky, dry, daylight  \\nOEDR Characteristics  \\n• Optional object vehicle s \\nFailure Behavior s \\n• None  \\nTest Protocol  \\nVehicle Platforms  \\nSubject Vehicle– T he vehicle equipped with the ADS  feature being tested.  \\nPrincipal Other Vehicles – The primary object vehicles for which the detection and response of \\nthe subject vehicle are being tested.  \\nVehicle Roles \\nThe SV is a light -duty vehicle equipped with an ADS  feature that is being evaluated.  \\nThe POV s are other  fully functional (operational brake lights, etc.) light- duty vehicle s (e.g., \\nsedan, SUVs , pickup trucks , etc.) or vehicle surrogates . If a vehicle surrogate is used, it would \\nideally be frangible and should possess similar mobility and detection characteristics as a regular \\nlight-duty vehicle . \\n• Ability to be towed or remotely controlled to follow the test course  \\n• Ability  to achieve test  speeds  \\n• Similar visual appearance  \\n• Similar radar  and/or lidar reflectivity115 Test Scenarios  \\nTable 60. Perform Lane Change Test Scenarios \\nManeuver  SV Speed  \\nkph (mph)  POV15 Speed \\nkph (mph)  Location of POV_1 Location of POV_2  Location of \\nPOV_3  \\nBaseline 15  \\nPLC_B_15  24 \\n(15) N/A N/A N/A N/A \\n \\nBaseline 25  \\nPLC_B_25   40 \\n(25) N/A N/A N/A N/A \\nBaseline 35  \\nPLC_B_35  56 \\n(35) N/A N/A N/A N/A \\nSimple Positive 15  \\nPLC_SP_15  24 \\n(15) 24 \\n(15) Rear bumper 6  m \\n(20 ft)  in front of SV \\nfront bumper  N/A N/A \\nSimple Positive 25  \\nPLC_SP_25  40 \\n(25) 40 \\n(25) Rear bumper 6  m \\n(20 ft)  in front of SV \\nfront bumper  N/A N/A \\nSimple Positive 35  \\nPLC_SP_35  56 \\n(35) 56 \\n(35) Rear bumper 6  m \\n(20 ft)  in front of SV \\nfront bumper  N/A N/A \\nComplex Positive 15  \\nPLC_CP_15  24 \\n(15) 24 \\n(15) Rear bumper 8 m \\n(25 ft)  in front of SV \\nfront bumper  Front bumper 25  ft (8 \\nm) behind SV rear \\nbumper  N/A \\nComplex Positive 25  \\nPLC_CP_25  40 \\n(25) 40 \\n(25) Rear bumper 8 m \\n(25 ft)  in front of SV \\nfront bumper  Front bumper 25  ft (8 \\nm) behind SV rear \\nbumper  N/A \\nComplex Positive 35  \\nPLC_CP_35  56 \\n(35) 56 \\n(35) Rear bumper 8  m \\n(25 ft)  in front of SV \\nfront bumper  Front bumper 25  ft (8 \\nm) behind SV rear \\nbumper  N/A \\nSimple Negative 15  \\nPLC_SN_15  24 \\n(15) 24 \\n(15) Rear bumper ≤ 5  m \\n(15 ft)  in front of SV \\nfront bumper  Front bumper even \\nwith SV front bumper  Front bumper ≤ \\n15 ft (5 m) behind \\nSV rear bumper  \\nSimple Negative 25  \\nPLC_SN_25  40 \\n(25) 40 \\n(25) Rear bumper ≤ 6  m \\n(20 ft)  in front of SV \\nfront bumper  Front bumper even \\nwith SV front bumper  Front bumper ≤ \\n20 ft (6 m) behind \\nSV rear bumper  \\nSimple Negative 35  \\nPLC_SN_35  56 \\n(35) 56 \\n(35) Rear bumper ≤ 8  m \\n(25 ft)  in front of SV \\nfront bumper  Front bumper even \\nwith SV front bumper  Front bumper ≤ \\n25 ft (8 m) behind \\nSV rear bumper  \\n                                                 \\n15 Principal other vehicle116  \\nTest Scenario Sample Visualizations  \\n \\nFigure 31. Merge Test Scenario  \\n \\nGeneral Procedures  \\nAmbient Conditions  \\n• The ambient temperature shall be between 0  ˚C (32 ˚F) and 38 ˚C (100 ˚F).  \\n• The maximum wind speed shall be no greater than 10 m/ s (22 mph). \\n• Tests should not be performed during periods of inclement weather. This includes, but \\nis not limited to, rain, snow, hail, fog, smoke, or ash. \\n• Unless specified otherwise, the tests shall be conducted during daylight hours with \\ngood atmospheric visibility (defined as an absence of fog and the ability to see clearly \\nfor more than 5,000 m). The test shall not be conducted with the vehicle oriented into the sun during very low sun angle conditions (the sun is oriented 15 degrees or less from horizontal) , where low sun angles degrade forward visibility for the test vehicle \\noperators.  \\n• Unless stated otherwise, all tests shall be conducted such that there are no overhead signs, bridges, or other significant structures over, or near, the testing site. Eac h trial \\nshall be conducted with no vehicles, obstructions, or stationary objects within one lane width of either side the vehicle path.117 Personnel  \\nA test execution team would include a n SV  safety driver, an experimenter, and one or more POV \\noperator s, and potentially external observers. The team would typically coordinate using person -\\nto-person radios for communication.  \\nThe SV safety driver would be skilled in the operation of the ADS  feature under test. This skill \\nand knowledge would include familiarity wit h the ADS  feature user interface, activation and \\ndeactivation procedures, and potential failure modes. The safety driver must be capable of \\ndisengaging the ADS  feature under test and bringing the vehicle to a minimal risk state, if the \\nexperiment approaches or reaches an unsafe state.  \\nThe experimenter observes and directs execution of each test trial and  would typically be in the \\nSV as the test is executed. The experimenter would also be knowledgeable of the operation of \\nthe ADS  feature under test to determine if it is functioning properly. The experimenter records \\ntest conditions and test trial notes, and judges apparent test trial validity. The experimenter might \\nalso operate the data acquisition system and other test equipment.  \\nThe POV operator w ould hold a valid driver ’s license and be comfortable operating the POVs. \\nThe POV operator would be responsible for positioning the POVs for each trial. If the POV is a \\nvehicle surrogate, the POV operator would be knowledgeable  of its construction and mobi lity \\nand be able to position and control the surrogate for the prescribed trials.  \\nThe other observers may be responsible for operating external data collection equipment ( e.g., \\nvideo recording of test execution, etc.). \\nTest Data and Equipment  \\nRelevant data  listed below should be collected to support the metrics identified for each test \\nscenario /trial. Options for equipment to collect the individual data elements are also provided.  \\n• Vehicle Positions (SV  and POVs ): GPS/ inertial n avigation s ystem (< X c m RMS, \\n95% confidence interval)  \\n• Vehicle Speeds (SV and POVs): GPS/INS, estimated from position information  \\n• Ranges (closest points between SV and POV): lidar, radar , estimated from position \\ninformation  \\n• Turn signal status  \\n• Ambient Conditions:  \\no Temperature: thermomete r (˚C, ˚F)  \\no Wind Speed: anemometer (mph, kph)  \\no Precipitation: range gauge (in/h , cm/h)  \\no Time: clock  \\no Sun position: manual observation  \\n• Test Documentation: c amera  \\n• Experimenter Notes118 Test Facility  \\nFor perform ing lane change competency tests, the test facility is a straight, flat, and level \\nroadway that includes one driving lane, whose surface is constructed of asphalt or concrete, and \\nwhose driving lane is at least 12 ft wide and delineated by lane markings visible to the vehicle operators. The only exceptions to this may be for tests where the roadway is curved instead of \\nstraight. The length of the roadway will be sufficient to allow the ADS  feature under test to \\nestablish and maintain a specified lane and speed, and to allow the SV to stop or exit the course, if applicable. The length of the test course is at least greater than the maximum SV perception \\nrange, or 105 m, whichever is greater. \\nScenario Test : PLC_Comp_15 – Straight Road, Complex, 15 mph  \\nScenario Description  \\nA vehicle equipped with an ADS  feature is driving along a straight urban street with multiple \\nlanes. It is approaching a necessary  turn and needs to change lanes to position itself in the \\nappropriate lane to make the turn.  \\nTest Subject and Purpose  \\nThe subject of this test is an ADS  feature whose  specified ODD includes operation on improved \\nurban roads with other traffic vehicles. The test determines the ability of the ADS  feature to \\nchange lanes in the presence of other traffic vehicles.  \\nInitial Conditions  \\nThe SV will initially be sta tic in the prescribed positions  and orientations . \\nThe POV s will initially be static in the prescribed positions ahead of the SV in an adjacent lane. \\nThe leading edge of POV_2 will be approximately 3 m  behind the trailing edge of POV_1. \\nTest Velocities  \\nThe steady  state velocities of the SV and POV are specified for each trial or set of trials.  \\nMetrics  \\nDisengagements \\nA disengagement is defined as the SV safety driver deactivating the ADS  feature being evaluated \\nand taking manual control of the SV. The locati on and manner of the disengagement should be \\nincluded in the experimenter ’s notes.119 Separation Distances  \\nThe separation distances are the distances between the SV and each of the POVs. The minimum \\nseparation distances (closest approach) should be identified , as well as the separation distances \\nbeing observed as a continuum.  \\nSignal Status  \\nSignal status is t he activation state of the SV turn signal, to be measured at a periodic rate to \\ndetermine when the signal is activated and deactivated.  \\nExecution of Proced ure \\n1. The POVs are positioned in the center of the right lane of the test road at their specified \\nlocations . \\n2. The SV is positioned in the center of a left  lane of the test road immediately adjacent to \\nPOV_2 .  \\n3. The SV is given a target destination in the right lane at the end of the test course.  \\n4. The SV ’s navigation system is activated to begin traversing the course.  \\n5. As the SV begins moving, the POVs simultaneously begin accelerating to the specified steady  state velocity while maintaining the approximate separat ion distance.  \\n6. Each trial ends when the SV successfully changes lanes to merge between POV_1 and POV_2 and stops at the target destination, or the SV driver must  intervene.  \\n7. After the end of the trial, the SV driver disengages the ADS  feature (if it is not already \\ndisengaged).  \\nTrial Validity  \\nAn individual tri al is valid if during the trial: \\n1. The velocity of the POVs did not exceed ±X kph f rom the specified steady  state \\nvelocities.  \\n2. The separation distance between the POVs did not exceed ±X m from the specified  \\nseparation distance.  \\n3. The POVs did not deviate from the specified lane.  \\nNOTE: Other trial validity requirements might include GPS coverage requirements.  \\nEvaluation Metrics  \\nA trial is successful if the SV: \\n• Successfully accelerates and merges between the two  POVs with a minimum \\nseparation distance of ≥X m with each POV . \\n• Successfully decelerates and merges behind POV_2 with a minimum separation \\ndistance of ≥X m with POV_2.  \\n• Successfully accelerates and merges ahead of POV_1 with a minimum separation \\ndistance of  ≥X m with POV_1 and does not exceed Y kph of the specified speed  limit .120 PERFORM VEHICLE FOLLOWING  \\nODD Characteristics  \\n• Multi -lane divided highway (or similar)  \\n• Asphalt or concrete  \\n• Straight/curved, flat  \\n• Clear lane markers  \\n• Clear sky, dry, daylight  \\nOEDR Charac teristics  \\n• Lead object vehicle  \\nFailure Behavior s \\n• None  \\nTest Protocol  \\nVehicle Platforms  \\nSubject Vehicle– T he vehicle equipped with the ADS  feature being tested.  \\nPrincip al Other Vehicle – The primary object vehicle for which the detection and response of the \\nSV are being tested.  \\nVehicle Roles \\nThe SV is a light -duty vehicle equipped with an ADS  feature that is being evaluated.  \\nThe POV is another fully functional (operational brake lights, etc.) light- duty vehicle ( e.g., \\nsedan, SUV, pickup truck, etc.) or vehicl e surrogate. If a vehicle surrogate is used, it would \\nideally be frangible and should possess similar mobility and detection characteristics as a regular \\nlight-duty vehicle . \\n• Able to be towed or remotely controlled to follow the test course  \\n• Able to achieve test  speeds  \\n• Similar visual appearance  \\n• Similar radar and/or lidar reflectivity121 Test Scenarios  \\nTable 61. Vehicle Following Test Scenarios  \\nManeuver  SV Speed  \\nkph (mph)  POV Speed  \\nkph (mph)  Initial Headway; m (ft)1 \\nStraight 25, slower \\nspeed  \\nVF_S_25_Slow  40 \\n(25) 32 \\n(20) > 30 \\n(> 100) \\nStraight 45, slower \\nspeed  \\nVF_S_45_Slow  72 \\n(45) 64 \\n(40) > 68 \\n(> 225 ) \\nStraight 65, slower \\nspeed  \\nVF_S_55_Slow  105 \\n(65) 96 \\n(60) > 105 \\n(> 345) \\nCurve 25, slower speed  \\nVF_C_25_Slow  40 \\n(25) 32 \\n(20) > 30 \\n(> 100) \\nCurve 45, slower speed  \\nVF_C_45_Slow  72 \\n(45) 64 \\n(40) > 68 \\n(> 225 ) \\nCurve 65, slower speed  \\nVF_C_65_Slow  105 \\n(65) 96 \\n(60) > 105 \\n(> 345 ) \\n \\nTest Scenario Sample Visualizations  \\n \\nFigure 32. Vehicle Following Test Scenario122 General Procedures  \\nAmbient Conditions  \\n• The ambient temperature shall be between 0  ˚C (32 ˚F) and 38 ˚C (100 ˚F).  \\n• The maximum wind speed shall be no greater than 10 m/s (22 mph). \\n• Tests should not be performed during periods of inclement weather. This includes, but \\nis not limited to, rain, snow, hail, fog, smoke, or ash. \\n• Unless specified otherwise, the tests shall be conducted during daylight hours with \\ngood atmospheric visibility (defined as an absence of fog and the ability to see clearly for more than 5,000 m). The  test shall not be conducted with the vehicle oriented into \\nthe sun during very low sun angle conditions (the sun is oriented 15 degrees or less from horizontal) , where low sun angles degrade forward visibility for the test vehicle \\noperators.  \\n• Unless stated  otherwise, all tests shall be conducted such that there are no overhead \\nsigns, bridges, or other significant structures over, or near, the testing site. Each trial shall be conducted with no vehicles, obstructions, or stationary objects within one lane width of either side the vehicle path.  \\nPersonnel  \\nA test execution team would include a n SV  safety driver, an experimenter, a POV operator, and \\npotentially external observers. The team would typically coordinate using person- to-person \\nradios for communication . \\nThe SV safety driver would be skilled in the operation of the ADS  feature under test. This skill \\nand knowledge would include familiarity with the ADS  feature user interface, activation and \\ndeactivation procedures, and potential failure modes. The safety driver must be capable of \\ndisengaging the ADS  feature under test and bringing the vehicle to a minimal risk state, if the \\nexperiment approaches or reaches an unsafe state.  \\nThe experimenter observes and directs execution of each test trial and  would typically be in the \\nSV as the test is executed. The experimenter would also be knowledgeable of the operation of the ADS  feature under test to determine if it is functioning properly. The experimenter records \\ntest conditions and test trial notes and  judges apparent test trial validity. The experimenter might \\nalso operate the data acquisition system and other test equipment.  \\nThe POV operator would hold a valid driver ’s license and be comfortable operating the POV. \\nThe POV operator would be responsible  for following the prescribed lane at the prescribed speed \\nfor each trial. If the POV is a vehicle surrogate, the POV operator would be knowledgeable  of its \\nconstruction and mobility and be able to position and control the surrogate for the prescribed trials. \\nThe other observers may be responsible for operating external data collection equipment ( e.g., \\nvideo recording of test execution, etc.).123 Test Data and Equipment  \\nRelevant data listed below should be collected to support the metrics identified for each test \\nscenario/trial. Options for equipment to collect the individual data elements are also provided:  \\n• Vehicle Positions (SV and POV): GPS/INS (< X cm root mean square ( RMS ) error, \\n95% confidence interval)  \\n• Vehicle Speeds (SV and POV): GPS/INS, estimated from  position information  \\n• Ranges (following distance between SV and POV): l idar, radar , estimated from \\nposition information \\n• Ambient Conditions:  \\no Temperature: thermometer (˚C, ˚F)  \\no Wind Speed: anemometer (mph, kph)  \\no Precipitation: range gauge (in/h, cm/h) \\no Time: cl ock \\no Sun position: manual observation  \\n• Test Documentation: c amera  \\n• Experimenter Notes  \\nTest Facility  \\nFor vehicle -following competency tests, the test facility is a straight, flat, and level roadway that  \\nincludes one driving lane, whose surface is constructed of asphalt or concrete, and whose driving lane is at least 12  ft wide and delineated by lane markings visible to the vehicle operators. The \\nonly exceptions to this may be for tests where the roadway is curved instead of straight. The length of the roadway will be sufficient to allow the ADS  feature under test to establish and \\nmaintain a specified lane and speed before encountering the POV, and to allow the SV to stop or exit the course, if applicable. The length of the test course is at least greater than t he maximum \\nSV perception range, or 105 m, whichever is greater. The test course should be a single lane so as not to allow the SV to change lanes to maneuver around the POV (if that is a capability of the ADS  feature.)  \\nScenario Tests: VF_S_25_Slow – Straig ht Road, POV Slower than SV  \\nScenario Description  \\nA vehicle equipped with an ADS  feature is driving along a straight highway or urban road with \\none or more lanes. It approaches a slower moving lead vehicle in the same lane from behind.  \\nTest Subject and Purpose  \\nThe subject of this test is an ADS  feature whose  specified ODD includes operation on improved \\nroads with other traffic vehicle s. The test determines the ability of the ADS  feature to maintain a \\nsafe following distance behind another traffic vehicle.124 Initial Conditions  \\nThe SV will initially be static in the prescribed positions and orientations.  \\nThe POV will initially be static in the prescribed positions ahead of the SV.  \\nTest Velocities  \\nThe steady  state velocities of the SV and POV are specified for each trial or set of trials.  \\nMetrics  \\nDisengagements \\nA disengagement is defined as the SV safety driver deactivating the ADS  feature being evaluated \\nand taking manual control of the SV. The location and manner of the disengagement should be \\nincluded in the experimenter ’s notes.  \\nFollowing Distance  \\nThe following distance is the distance between the leading edge (front bumper) of the SV and the trailing edge (rear bumper) of the POV. The minimum following di stance (closest approach) \\nshould be identified, as well as the following distance being observed as a continuum.  \\nDeceleration Rate \\nThe deceleration rate is the rate of change of speed of the vehicle (presum ing that the vehicle \\nslows down in this case). Ideally , the rate of change would be smooth, as opposed to an abrupt \\ndeceleration as the SV approaches the POV.  \\nExecution of Procedure  \\n1. The POV is positioned in the center of a lane of the test road at the specified starting \\nlocation.  \\n2. The SV is positioned in the center of a lane of the test road at the specified initial \\nheadway.  \\n3. The SV is given a target destination at the end of the test course such that it will remain in the lane as it traverses the course and reach es the specified speed.  \\n4. The SV ’s navigation system is activated to begin traversing the course.  \\n5. The POV accelerates to and maintains the specified speed while maintaining the specified lane.  \\n6. The SV approaches the POV at the specified speed (higher than the POV speed) in the specified lane.  \\n7. Each tri al ends when the SV successfully stops at the target destination, or the SV driver \\nmust  intervene. \\n8. After the end of the trial, the SV driver disengages the ADS  feature (if it is not already \\ndisengaged).125 Trial Validity  \\nAn individual tri al is valid if during the trial: \\n1. The velocity of the SV did not exceed ±X kph from the specified steady  state velocity \\nbefore the POV came within its perception horizon. \\n2. The velocity of the POV did not exceed ±X kph from the specified steady  state velocity.  \\n3. The POV did not deviate from the specified lane.  \\n4. The yaw rate of the POV did not exceed ±X degrees/s.  \\nNOTE: Other trial validity requirements might include GPS coverage requirements.  \\nEvaluation Metrics  \\nA trial is successful if the SV remains within its prescribed lane  and reduces its speed to maintain \\na safe, speed -dependent following distance behind the POV for the remaining length and \\nduration of the trial.126 MOVE OUT OF TRAVEL LANE/PARK  \\nODD Characteristics  \\n• Multi -lane arterial street (or similar)  \\n• Asphalt or concrete  \\n• Straight, flat  \\n• Clear lane markers  \\n• Clear sky, dry, daylight  \\nOEDR Characteristics  \\n• Optional object vehicle s \\nFailure Behavior s \\n• None  \\nTest Protocol  \\nVehicle Platforms  \\nSubject Vehicle– T he vehicle equipped with the ADS  feature being tested.  \\nPrincip al Other Vehicles – The primary object vehicles for which the detection and response of \\nthe SV  are being tested.  \\nVehicle Roles \\nThe SV is a light -duty vehicle equipped with an ADS  feature that is being evaluated.  \\nThe POVs are other fully functional (operational  brake lights, etc.) light- duty vehicle s (e.g., \\nsedan, SUV, pickup truck, etc.) or vehicle surrogates. If a vehicle surrogate is used, it would \\nideally be frangible and should possess similar mobility and detection characteristics as a regular light-duty vehicle:  \\n• Ability to be towed or remotely controlled to follow the test course  \\n• Ability to achieve test speeds  \\n• Similar visual appearance  \\n• Similar radar  and/or lidar reflectivity127 Test Scenarios  \\nTable 62. Move Out of Travel Lane Test Scenarios  \\n Maneuver  SV Speed  \\nkph (mph)  POV Speed  \\nkph (mph)  # \\nof \\nPOVs  Location  \\nof \\nPOV_1  Location  \\nof \\nPOV_n  Length of \\n“Parking” Zone \\nm (ft)  \\nSimple Positive 15  \\nMOTL_Simp_15  24 \\n(15) 0 \\n(0) 1 Rear bump.  \\n12 m (40 ft)  \\nbeyond Int_1  Front bump.  \\n≥24 m (80 ft ) \\nbefore Int_2  24 \\n(80) \\nSimple Positive 25  \\nMOTL_Simp_15  40 \\n(25) 0 \\n(0) 1 Rear bump.  \\n12 m (40 ft)  \\nbeyond Int_1  Front bump.  \\n≥24 m (80 ft)  \\nbefore Int_2  24 \\n(80) \\nComplex Positive 15  \\nMOTL_Comp_15  24 \\n(15) 0 \\n(0) ≥ 2 Rear bump.  \\n11 m (35 ft)  \\nbeyond Int_1  Front bump.  \\n6 m (20 ft)  \\nbefore Int_2  24 \\n(80) \\nComplex Positive 25  \\nMOTL_Comp_25  40 \\n(25) 0 \\n(0) ≥ 2 Rear bump.  \\n11 m (35 ft)  \\nbeyond Int_1  Front bump.  \\n6 m (20 ft) \\nbefore Int_2  24 \\n(80) \\nNegative 15  \\nMOTL_Neg_15  24 \\n(15) 0 \\n(0) ≥ 2 Rear bump.  \\n6 m (20 ft)  \\nbeyond Int_1  Front bump.  \\n6 m (20 ft) \\nbefore Int_2  ≤ 3 \\n(10) \\nNegative 25  \\nMOTL_Neg_25  40 \\n(25) 0 \\n(0) ≥ 2 Rear bump.  \\n6 m (20 ft) \\nbeyond Int_1  Front bump.  \\n6 m (20 ft)  \\nbefore Int_2  ≤ 3 \\n(10) \\n*Int = Intersection, bump. = bumper128 Test Scenario Sample Visualizations  \\n \\nFigure 33. Move Out of Travel Lane/Park Test Scenario  \\n \\nGeneral Procedures  \\nAmbient Conditions  \\n• The ambient temperature shall be between 0  ˚C (32 ˚F) and 38 ˚C (100 ˚F).  \\n• The maximum wind speed shall be no greater than 10 m/s (22 mph). \\n• Tests should not be performed during periods of inclement weather. This includes, but \\nis not limited to, rain, snow, hail, fog, smoke, or ash. \\n• Unless specified otherwise, the tests shall be conducted during daylight hours with \\ngood atmospheric visibility (define d as an absence of fog and the ability to see clearly \\nfor more than 5,000 m). The test shall not be conducted with the vehicle oriented into \\nthe sun during very low sun angle conditions (the sun is oriented 15 degrees or less from horizontal) , where low su n angles degrade forward visibility for the test vehicle \\noperators.  \\n• Unless stated otherwise, all tests shall be conducted such that there are no overhead signs, bridges, or other significant structures over, or near, the testing site. Each trial shall be conducted with no vehicles, obstructions, or stationary objects within one lane width of either side the vehicle path.129 Personnel  \\nA test execution team would include a n SV  safety driver, an experimenter, a POV operator, and \\npotentially external observers. The team would typically coordinate using person- to-person \\nradios for communication. \\nThe SV safety driver would be skilled in the operation of the ADS  feature under test. This skill \\nand knowledge would include familiarity with the ADS  feature user interface, activation and \\ndeactivation procedures, and potential failure modes. The safety driver must be capable of \\ndisengaging the ADS  feature under test and bringing the vehicle to a minimal risk state, if the \\nexperiment approaches or reache s an unsafe state.  \\nThe experimenter observes and directs execution of each test trial and  would typically be in the \\nSV as the test is executed. The experimenter would also be knowledgeable of the operation of \\nthe ADS  feature under test to determine if it i s functioning properly. The experimenter records \\ntest conditions and test trial notes, and judges apparent test trial validity. The experimenter might \\nalso operate the data acquisition system and other test equipment.  \\nThe POV operator would hold a valid dr iver’s license and be comfortable operating the POVs. \\nThe POV operator would be responsible for positioning the POVs for each trial. If the POV is a \\nvehicle surrogate, the POV operator would be knowledgeable  of its construction and mobility \\nand be able to position and control the surrogate for the prescribed trials.  \\nThe other observers may be responsible for operating external data collection equipment ( e.g., \\nvideo recording of test execution).  \\nTest Data and Equipment  \\nRelevant data listed below should be collected to support the metrics identified for each test \\nscenario/trial. Options for equipment to collect the individual data elements are also provided:  \\n• Vehicle Positions (SV and POVs): GPS/INS (< X cm root mean square error , 95% \\nconfidence interval)  \\n• Vehic le Speeds (SV and POVs): GPS/INS, estimated from position information  \\n• Ranges (closest points between SV and POV): l idar, radar , estimated from position \\ninformation  \\n• Turn signal status  \\n• Ambient Conditions:  \\no Temperature: thermometer (˚C, ˚F)  \\no Wind Speed: anemometer (mph, kph)  \\no Precipitation: range gauge (in/h, cm/h) \\no Time: clock  \\no Sun position: manual observation  \\n• Test Documentation: c amera  \\n• Experimenter Notes130 Test Facility  \\nFor moving out of travel lane competency tests, the test facility is a straig ht, flat, and level \\nroadway that  includes one driving lane, whose surface is constructed of asphalt or concrete, and \\nwhose driving lane is at least 3.6 m ( 12 ft) wide and delineated by lane markings visible to the \\nvehicle operators. The only exceptions to this may be for tests where the roadway is curved \\ninstead of straight. A curb of standard height 0.09 to 0.18 m (4 to 8 in) shall be located on the \\nright edge of the right lane of the test road. The length of the roadway will be sufficient to allow the ADS  feature under test to establish and maintain a specified lane and speed before \\nencountering the parking area, and to allow the SV to stop or exit the course, if applicable. The length of the test course is at least greater than the maximum SV perception r ange, or 105 m, \\nwhichever is greater.  \\nScenario Tests: MOTL_Comp_15 – Straight Road, Complex, 15 mph  \\nScenario Description  \\nA vehicle equipped with an ADS  feature is driving along a straight urban street with one or more \\nlanes. It needs to move out of the act ive travel lanes to a parking area to allow passengers to \\nembark  or disembark.  \\nTest Subject and Purpose  \\nThe subject of this test is an ADS  feature whose  specified ODD includes operation on improved \\nurban roads with other vehicle traffic. The test determines the ability of the ADS  feature to move \\nout of active travel lanes to park in a safe and timely manner.  \\nInitial Conditions  \\nThe SV will initially be static in the prescribed positions and orientations.  \\nThe POV s will initially be static in the prescribed positions ahead of the SV. The leading edge of \\nPOV_2 will be approximately 80 ft behind the trailing edge of POV_1, allowing sufficient space for the SV to maneuver and park.  \\nTest Velocities  \\nThe steady  state velo cities of the SV and POV are specified for each trial or set of trials.  \\nMetrics  \\nDisengagements \\nA disengagement is defined as the SV safety driver deactivating the ADS  feature being evaluated \\nand taking manual control of the SV. The location and manner of the disengagement should be included in the experimenter ’s notes.131 Separation Distances  \\nThe separation distances are the distances between the SV and each of the POVs. The minimum \\nseparation distances (closest approach) should be identified, as well as the separation distances \\nbeing observed as a continuum.  \\nThe separation distance at  stop is also measured and represents the distance between the SV and \\neach of the POVs when the SV has come to a complete stop in its parking position.  \\nDeceleration Rate \\nThe dec eleration rate is the rate of change of speed of the vehicle (presumed that the vehicle \\nslows down in this case). Ideally the rate of change would be smooth, as opposed to an abrupt \\ndeceleration as the SV reaches the parking location.  \\nExecution of Procedur e \\n1. The POVs are positioned in the center of the parking lane (right lane) of the test road at \\ntheir specified locations . \\n2. The POVs ’ engines are turned off and are placed in park with their emergency brakes \\nactivated.  \\n3. The SV is positioned in the center of a l ane of the test r oad at the specified initial \\nheadway.  \\n4. The SV is given a target “park”  destination between the leading edge of POV_1 and the \\ntrailing edge of POV_2.  \\n5. The SV ’s navigation system is activated to begin traversing the course.  \\n6. The SV approaches the POV s at the specified speed (higher than the POV speed) in the \\nspecified lane.  \\n7. Each trial ends when the SV successfully stops at or near the target destination (between the POVs) and shifts to park, or the SV driver must  intervene.  \\n8. After the end of the  trial, the SV driver disengages the ADS  feature (if it is not already \\ndisengaged).  \\n \\nTrial Validity  \\nAn individual tri al is valid if during the trial: \\n1. The velocity of the SV did not exceed ±X kph from the specified steady  state velocity \\nbefore the POV came within its perception horizon. \\n2. The velocity of the POVs did not exceed ±X kph f rom the specified steady  state \\nvelocities.  \\nNOTE: Other trial validity requirements might include GPS coverage requirements.132 Evaluation Metrics  \\nA trial is successful if the SV: \\n• Remains within its prescribed lane before reaching the parking area.  \\n• Enters  the parking lane with a moving separation distance of ≥X m with each POV . \\n• Stops with separation distance at  stop of ≥X m with each POV . \\n• Shifts to park upon stopping in the parking lane.133 DETECT AND RESPOND TO SCHOOL BUSES  \\nODD Characteristics  \\n• Multi -lane divided highway (or similar)  \\n• Asphalt or concrete  \\n• Straight, flat  \\n• Clear lane markers  \\n• Clear sky, dry, daylight  \\nOEDR Characteristics  \\n• Object school bus  \\nFailure Behavior s \\n• None  \\nTest Protocol  \\nVehicle Platforms  \\nSubject Vehicle– T he vehicle equipped with ADS  feature being tested.  \\nPrincip al Other Vehicle – The primary object vehicle for which the detection and response of the \\nSV are being tested.  \\nVehicle Roles \\nThe SV is a light -duty vehicle equippe d with an ADS  feature that is being evaluated.  \\nThe POV is a “ Type C ” school bus, also known as a “ conventional ” school bus, with a gross \\nvehicle weight rating of more than 4,535 kg ( 10,000 pounds ), designed to carry more than ten \\npersons. The bus has functioning onboard traffic control devices, including warning lights and \\narticulating stop signs. Alternatively, a school bus surrogate can be used. If a bus surrogate is used, it would ideally be frangible and should possess similar  mobility and detection \\ncharacteristics as a regular light -duty vehicle . \\n• Similar visual appearance  \\n• Similar radar  and/or lidar reflectivity  \\n• Similar traffic control devices134 Test Scenarios  \\nTable 63. School Bus Test Scenarios  \\nManeuver  SV Speed  \\nkph (mph)  POV Speed  \\nkph (mph)  Initial Headway; m (ft)1 \\nSame Direction 25  \\nSB_SD_25  40 \\n(25) 0 > 30 \\n(> 100) \\nSame Direction 45  \\nSB_SD_45  72 \\n(45) 0 > 68 \\n(> 225) \\nSame Direction 65  \\nSB_SD_55  105 \\n(65) 0 > 105 \\n(> 345) \\nOpposing Direction 25  \\nSB_OD_25  40 \\n(25) 0 > 30 \\n(> 100) \\nOpposing Direction 45  \\nSB_OD_45  72 \\n(45) 0 > 68 \\n(> 225) \\nOpposing Direction 65  \\nSB_OD_65  105 \\n(65) 0 > 105 \\n(> 345) \\n \\nTest Scenario Sample Visualizations  \\n \\nFigure 34. School Bus Test Scenarios  \\n \\nGeneral Procedures  \\nAmbient Conditions  \\n• The ambient temperature shall be between 0  ˚C (32 ˚F) and 38 ˚C (100 ˚F).135 • The maximum wind speed shall be no greater than 10 m/s (22 mph). \\n• Tests should not be performed during periods of inclement weather. This includes, but \\nis not limited to, rain, snow, hail, fog, smoke, or ash. \\n• Unless specified otherwise, the tests shall be conducted during daylight hours with \\ngood atmospheric visibility (defined as an absence of fog and the ability to see clearly for more than 5,000 m). The test shall  not be conducted with the vehicle oriented into \\nthe sun during very low sun angle conditions (the sun is oriented 15 degrees or less from horizontal) , where low sun angles degrade forward visibility for the test vehicle \\noperators.  \\n• Unless stated otherwise,  all tests shall be conducted such that there are no overhead \\nsigns, bridges, or other significant structures over, or near, the testing site. Each trial shall be conducted with no vehicles, obstructions, or stationary objects within one lane width of eith er side the vehicle path.  \\nPersonnel  \\nA test execution team would include a n SV  safety driver, an experimenter, and a POV operator. \\nThe team would typically coordinate using person- to-person radios for communication. \\nThe SV safety driver would be skilled in the operation of the ADS  feature under test. This skill \\nand knowledge would include familiarity with the ADS  feature user interface, activation and \\ndeactivation procedures, and potential failure modes. The safety driver must be capable of \\ndisengaging t he A DS fe ature under test and bringing the vehicle to a minimal risk state, if the \\nexperiment approaches or reaches an unsafe state.  \\nThe experimenter observes and directs execution of each test trial and  would typically be in the \\nSV as the test is executed. Th e experimenter would also be knowledgeable of the operation of \\nthe ADS  feature under test to determine if it is functioning properly. The experimenter records \\ntest conditions and test trial notes, and judges apparent test trial validity. The experimenter m ight \\nalso operate the data acquisition system and other test equipment.  \\nThe POV operator would be skilled in the operation of the other object vehicle s, in this case a \\nClass C school bus. The POV operator would position the POV for each trial and would act ivate \\nand deactivate the necessary  POV features (bus lights and signs ). If the POV is a vehicle \\nsurrogate, the POV operator would be knowledgeable  of its construction and mobility and be \\nable to position the surrogate and operate its traffic control devices for the prescribed trials.  \\nTest Data and Equipment  \\nRelevant data listed below should be collected to support the metrics identified for each test scenario/trial. Options for equipment to collect the individual data elements are also provided.  \\n• Vehic le Positions (SV and POV): GPS/INS (< X cm root mean square error , 95% \\nconfidence interval)  \\n• Ranges (closest points between SV and POVs): l idar, radar136 • Ambient Conditions:  \\no Temperature: thermometer (˚C, ˚F)  \\no Wind Speed: anemometer (mph, kph)  \\no Precipitation: ra nge gauge (in/h, cm/h)  \\no Time: clock  \\no Sun position: manual observation  \\n• Test Documentation: c amera  \\n• Experimenter Notes  \\nTest Facility  \\nFor school bus competency tests, the test facility is a straight, flat, and level roadway that \\nincludes two or more adjacent driving lanes and one or more opposing driving lanes, whose \\nsurface is constructed of asphalt or concrete, and whose driving lanes are at least 3.6 m ( 12 ft) \\nwide and delineated by lane markings visible to the vehicle operators. The only exceptions to this may be for tests where the roadway is curved instead of straight. The length of the roadway will \\nbe sufficient to allow the ADS  feature under test to establish and maintain a specified lane and \\nspeed before interaction with the POV and to allow the SV to stop or exit the course after passing the POV, if applicable. The length of the test course is at least greater than the maximum SV perception range, or 105 m, whichever is greater.  \\nSCENARIO TESTS : SB_OD_25_Straight – Opposing Direction in Adjacent Lanes, \\nStraight Road  \\nScenario Description  \\nA vehicle equipped with an ADS  feature is driving along a straight, undivided, multilane \\nhighway. It approaches a school bus that is stopped in an opposing lane, with lights and signs \\nactivated, to allow students to disembark.  \\nTest Subject and Purpose  \\nThe subject of this test is an ADS  feature whose  specified ODD includes operation in areas \\nwhere interaction with a school bus with activated traffic control devices is reasonably expected. The test determines the ability of the ADS  feature to respond to the bus ’s traffic control devices \\nby stopping in a safe and timely manner.  \\nInitial Conditions  \\nThe SV and POV will initially be static in the prescribed positions and orientations.  \\nTest Velocities  \\nThe steady  state velocities of the SV and POV are specified for each trial or set of trials.137 Metrics  \\nDisengag ements  \\nA disengagement is defined as the SV safety driver deactivating the ADS  feature being evaluated \\nand taking manual control of the SV. The location and manner of the disengagement should be \\nincluded in the experimenter ’s notes.  \\nSeparation Distance at Stop  \\nSeparation distance at stop is defined as the distance between the leading edge of the SV and a plane extending from the leading edge of the POV when the SV has come to a complete stop.  \\nExecution of Procedure  \\n1. The POV is positioned in the center of the opposing lane of test road.  \\n2. The POV ’s engine remains running and the POV is placed in park with the emergency \\nbrake activated.  \\n3. The POV ’s traffic control devices are activated (lights on and signs extended).  \\n4. The SV is positioned in the center of the left lane of the test road at the specified initial \\nheadway distance behind the POV.  \\n5. The SV is given a target destination at the end of the test course such that it will remain \\nin the left lane as it traverses the course and reach es the specified speed.  \\n6. The SV ’s navigation system is activated to begin traversing the course.  \\n7. Each trial ends when the SV successfully stops,  or the SV driver must  intervene.  \\n8. After the end of the trial, the SV driver disengages the ADS  feature (if it is not already \\ndisengaged).  \\nTrial  Validity  \\nAn individual tri al is valid if during the trial: \\n1. The SV did not deviate from its specified lane (wheels crossing lane boundaries) . \\n2. The velocity of the SV did not exceed ±X kph from the specified velocity . \\n3. The yaw rate of the SV did not exceed ±X  degree s/s. \\n4. The POV did not deviate from the specified velocity by more than 0.1 kph . \\n5. The POV ’s traffic control devices remained active for the entirety of the trial.  \\nNOTE: Other trial validity requirements might include GPS coverage requirements.  \\nEvaluation Metrics (Performance Metrics – Pass/Fail Criteria)  \\nA trial is successful if the SV stops before its leading edge (front bumper) crosses a hypothetical \\nplan extending horizontally from the leading edge (front bumper) of the POV.138 DETECT AND RESPOND TO ENCROACHING ONCOMING VEHICLES  \\nTest Protocol  \\nVehicle Platforms  \\nSubject Vehicle– T he vehicle equipped with ADS  feature being tested.  \\nPrincip al Other Vehicle – The primary object vehicle for which the detection and response of the \\nSV are being tested.  \\nVehicle Roles \\nThe SV is a light -duty vehicle equipped with an ADS  feature that is being evaluated.  \\nThe POV is another fully functional (operational brake lights, etc.) light- duty vehicle (e.g., \\nsedan, SUV, pickup truck, etc.) or vehicle surrogate. If a vehic le surrogate is used, it would \\nideally be frangible and should possess similar mobility and detection characteristics as a regular \\nlight-duty vehicle:  \\n• Ability to be towed or remotely controlled to follow the test course  \\n• Ability to achieve test speeds  \\n• Similar visual appearance \\n• Similar radar  and/or lidar reflectivity  \\nTest Scenarios  \\nTable 64. Encroaching Opposing Vehicle Test Scenarios  \\nManeuver  SV Speed kph \\n(mph)  POV Speed  \\nkph (mph)  Initial Headway; m (ft)1 \\nStraight 25/20  \\nEOV_S_25_20  40 \\n(25) 32 \\n(20) > 30 \\n(> 100) \\nStraight 45/40  \\nEOV_S_45_40  72 \\n(45) 64 \\n(40) > 68 \\n(> 225) \\nStraight 65/60  \\nEOV_S_65_60  105 \\n(65) 96 \\n(60) > 105 \\n(> 345) \\nCurve 25/20  \\nEOV_C_25_20  40 \\n(25) 32 \\n(20) > 30 \\n(> 100) \\nCurve 45/40  \\nEOV_C_45_40  72 \\n(45) 64 \\n(40) > 68 \\n(> 225) \\nCurve 65/60  \\nEOV_C_65_60  105 \\n(65) 96 \\n(60) > 105 \\n(> 345)139 Test Scenario Sample Visualizations  \\n \\nFigure 35. Encroaching, Oncoming Vehicle Test Scenario  \\n \\nGeneral Procedures  \\nAmbient Conditions  \\n• The ambient temperature shall be between 0  ˚C (32 ˚F) and 38 ˚C (100 ˚F).  \\n• The maximum wind speed shall be no greater than 10 m/s (22 mph). \\n• Tests should not be performed during periods of inclement weather. This includes, but \\nis not limited to, rain, snow, hail, fog, smoke, or ash. \\n• Unless specified  otherwise, the tests shall be conducted during daylight hours with \\ngood atmospheric visibility (defined as an absence of fog and the ability to see clearly for more than 5,000 m). The test shall not be conducted with the vehicle oriented into the sun duri ng very low sun angle conditions (the sun is oriented 15 degrees or less \\nfrom horizontal) , where low sun angles degrade forward visibility for the test vehicle \\noperators.  \\n• Unless stated otherwise, all tests shall be conducted such that there are no overhead  \\nsigns, bridges, or other significant structures over, or near, the testing site. Each trial shall be conducted with no vehicles, obstructions, or stationary objects within one lane width of either side the vehicle path.140 Personnel  \\nA test execution team wou ld include a n SV  safety driver, an experimenter, a POV operator, and \\npotentially external observers. The team would typically coordinate using person- to-person \\nradios for communication. \\nThe SV safety driver would be skilled in the operation of the ADS  feature under test. This skill \\nand knowledge would include familiarity with the ADS  feature user interface, activation and \\ndeactivation procedures, and potential failure modes. The safety driver must be capable of \\ndisengaging the ADS  feature under test and bri nging the vehicle to a minimal risk state, if the \\nexperiment approaches or reaches an unsafe state.  \\nThe experimenter observes and directs execution of each test trial and  would typically be in the \\nSV as the test is executed. The experimenter would also be knowledgeable of the operation of \\nthe ADS  feature under test to determine if it is functioning properly. The experimenter records \\ntest conditions and test trial notes, and judges apparent test trial validity. The experimenter might \\nalso operate the data acquisition system and other test equipment.  \\nThe POV operator would hold a valid driver ’s license and be comfortable operating the POV. \\nThe POV operator would be responsible for following the prescribed lane at the prescribed speed \\nfor each trial. If the POV  is a vehicle surrogate, the POV operator would be knowledgeable  of its \\nconstruction and mobility and be able to position and operate the surrogate for the prescribed \\ntrials.  \\nThe other observers may be responsible for operating external data collection equipment (e.g., video recording of test execution).  \\nTest Data and Equipment  \\nRelevant data listed below should be collected to support the metrics identified for each test scenario/trial. Options for equipment to collect the individual data elements are also provided.  \\n• Vehicle Positions (SV and POV): GPS/INS (< X cm root mean square error , 95% \\nconfidence interval)  \\n• Vehicle Speeds (SV and POV): GPS/INS, estimated from position information  \\n• Ranges (following distance between SV and POV): lidar, radar , estimated from \\nposition information \\n• Ambient Conditions:  \\no Temperature: thermometer (˚C, ˚F)  \\no Wind Speed: anemometer (mph, kph)  \\no Precipitation: range gauge (in/h, cm/h) \\no Time: clock  \\no Sun position: manual observation  \\n• Test Documentation: c amera  \\n• Experimenter Notes141 Test Facility  \\nFor vehicle -following competency tests, the test facility is a straight, flat, and level roadway that  \\nincludes one or more driving lanes and one opposing lane, whose surface is constructed of \\nasphalt or concrete, and whose driving lanes are at lea st 3.6 m ( 12 ft) wide and delineated by lane \\nmarkings visible to the vehicle operators. The only exceptions to this may be for tests where the roadway is curved instead of straight. The length of the roadway will be sufficient to allow the ADS  feature unde r test to establish and maintain a specified lane and speed before encountering \\nthe POV, and to allow the SV to stop or exit the course, if applicable. The length of the test course is at least greater than the maximum SV perception range, or 105 m, whiche ver is greater.  \\nSCENARIO TESTS : EOV_S_45_40 – Straight Road, 45 mph, 40 mph Opposing Vehicle  \\nScenario Description  \\nA vehicle equipped with an ADS  feature is driving along a straight highway with one or more \\nlanes. Another moving vehicle is approaching in an opposing lane of travel and begins to drift into the SV ’s lane of travel such that a collision would occur if the SV did not react.  \\nTest Subject and Purpose  \\nThe subject of this test is an ADS  feature whos e specified operational design domain includes \\noperation on multidirectional, undivided, improved roads with other vehicle traffic. The test \\ndetermines the ability of the ADS  feature to detect an opposing vehicle that is encroaching into \\nits lane to the extent that a collision would occur if the SV did not  implement an avoidance \\nmaneuver. \\nInitial Conditions  \\nThe SV will initially be static in the prescribed positions and orientations.  \\nThe POV will be static in the prescribed positions and orientations.  \\nTest Velocities  \\nThe steady  state velocities of the SV an d POV are specified for each trial or set of trials.  \\nMetrics  \\nDisengagements \\nA disengagement is defined as the SV safety driver deactivating the ADS  feature being evaluated \\nand taking manual control of the SV. The location and manner of the disengagement should be included in the experimenter ’s notes.  \\nAvoidance Distance  \\nThe avoidance distance is the minimum distance between the SV and POV.142 Deceleration Rate \\nThe deceleration rate is the rate of change of speed of the vehicle (presumed that the vehicle \\nslows  down in this case).  \\nYaw Rate  \\nThe yaw rate is defined as the rate of change of the heading of the vehicle.  \\nExecution of Procedure  \\n1. The POV is positioned in the opposing lane of the test road with its left (driver ’s side) \\ntires entirely over the center dividing lane markers in the SV ’s lane.  \\n2. The SV is positi oned in the center of a lane of the test road at the specified initial \\nheadway.  \\n3. The SV is given a target destination at the end of the test course such that it will remain \\nin the lane as it traverses  the course and reach es the specified speed.  \\n4. The SV ’s navigation system is activated to begin traversing the course.  \\n5. The POV begins driving in the opposing direction and maintains a trajectory parallel to the center of the opposing lane, with its left (dri ver’s side) entirely over the center \\ndividing lane markers, in the SV ’s lane.  \\n6. The SV and POV approach each other in opposing directions at the specified speeds.  \\n7. Each trial ends when a collision occurs or is avoided, or if the SV driver disengages the ADS  Feature.  \\n8. After the end of the trial, the SV driver disengages the ADS  Feature (if it is not already \\ndisengaged).  \\nTrial Validity  \\nAn individual tri al is valid if during the trial: \\n1. The velocity of the SV did not exceed ±X kph from the specified steady  state velocity \\nbefore the POV came within its perception horizon. \\n2. The velocity of the POV did not exceed ±X kph from the specified velocity for the duration of the trial.  \\n3. The left (driver ’s side) wheels of the POV remained fully in the SV ’s lane for the \\nduration of the trial.  \\nNOTE: Other trial validity requirements might include GPS coverage requirements.  \\nEvaluation Metrics  \\nA trial is successful if the SV either:  \\n• Maneuvers fully into an available adjacent lane and avoids a collision with the POV.  \\n• Maneuvers fully onto an available shoulder and avoids a collision with the POV.  \\n• Maneuvers to shift within its lane (potentially partially entering an available adjacent lane or shoulder) and avoids a collision with the POV . \\n• Decelerates rapidly to mitigate an imminent collision with the POV.143 DETECT AND RESPOND TO PEDESTRIANS  \\nTest Protocol  \\nVehicle Platforms  \\nSubject Vehicle– T he vehicle equipped with ADS  feature being tested.  \\nVehicle Roles \\nThe SV is a light -duty vehicle equipped with an ADS  feature that is being evaluated.  \\nOther Definitions  \\nPedestrian Surrogate – A human surrogate that  is attached to a self -propelled or freewheeling \\nmobile base. The surrogate would ideally be frangible and with similar mobility and detection \\ncharacteristics. \\n• Ability to be towed or remotely co ntrolled to follow prescribed course  \\n• Similar articulation of joints (if applicable)  \\n• Similar visual appearance  \\n• Similar radar and/or lidar reflectivity144 Test Scenarios  \\nTable 65. Pedestrian Test Scenarios  \\nManeuver  SV Speed  \\nkph (mph)  PS Speed  \\nkph (mph)  Initial Headway; ft (m)1 \\nIn Crosswalk Straight 25  \\nPed_Crosswalk_S_25  40 \\n(25) 5 \\n(3) > 30 \\n(> 100) \\nIn Crosswalk Straight 45  \\nPed_Crosswalk _S_45  72 \\n(45) 5 \\n(3) > 68 \\n(> 225) \\nIn Crosswalk/Sign Straight 25  \\nPed_Crosswalk_Sign_S_25  40 \\n(25) 5 \\n(3) > 30 \\n(> 100) \\nIn Crosswalk/Sign Straight 45  \\nPed_Crosswalk_Sign _S_45  72 \\n(45) 5 \\n(3) > 68 \\n(> 225) \\nIn No Crosswalk Straight 25  \\nPed_NoCrosswalk _S_65  40 \\n(25) 5 \\n(3) > 30 \\n(> 100) \\nIn No Crosswalk Straight 45  \\nPed_NoCrosswalk _S_25  72 \\n(45) 5 \\n(3) > 68 \\n(> 225) \\nEntering Crosswalk Straight 25  \\nPed_Crosswalk_S_25  40 \\n(25) 5 \\n(3) > 30 \\n(> 100) \\nEntering Crosswalk Straight 45  \\nPed_Crosswalk _S_45  72 \\n(45) 5 \\n(3) > 68 \\n(> 225) \\nEntering Crosswalk/Sign \\nStraight 25  \\nPed_Crosswalk_Sign_S_25  40 \\n(25) 5 \\n(3) > 30 \\n(> 100) \\nEntering Crosswalk/Sign \\nStraight 45  \\nPed_Crosswalk_Sign _S_45  72 \\n(45) 5 \\n(3) > 68 \\n(> 225) \\n \\nNOTE: Further iterations of tests could have pedestrians coming from different \\ndirections.145 Test Scenario Sample Visualizations  \\n \\nFigure 36. Pedestrian  Test Scenario  \\nGeneral Procedures  \\nAmbient Conditions  \\n• The ambient temperature shall be between 0  ˚C (32 ˚F) and 38 ˚C (100 ˚F).  \\n• The maximum wind speed shall be no greater than 10 m/s (22 mph). \\n• Tests should not be performed during periods of inclement weathe r. This includes, but \\nis not limited to, rain, snow, hail, fog, smoke, or ash. \\n• Unless specified otherwise, the tests shall be conducted during daylight hours with \\ngood atmospheric visibility (defined as an absence of fog and the ability to see clearly \\nfor more than 5,000 m). The test shall not be conducted with the vehicle oriented into \\nthe sun during very low sun angle conditions (the sun is oriented 15 degrees or less from horizontal) , where low sun angles degrade forward visibility for the test vehicle \\noperators.  \\n• Unless stated otherwise, all tests shall be conducted such that there are no overhead signs, bridges, or other significant structures over, or near, the testing site. Each trial shall be conducted with no vehicles, obstructions, or stationary obj ects within one lane \\nwidth of either side the vehicle path.  \\nPersonnel  \\nA test execution team would include a n SV  safety driver, an experimenter, a PS operator, and \\npotentially external observers. The team would typically coordinate using person- to-person \\nradios for communication.146 The SV safety driver would be skilled in the operation of the ADS  feature under test. This skill \\nand knowledge would include familiarity with the ADS  feature user interface, activation and \\ndeactivation procedures, and potential fail ure modes. The safety driver must be capable of \\ndisengaging the ADS  feature under test and bringing the vehicle to a minimal risk state, if the \\nexperiment approaches or reaches an unsafe state.  \\nThe experimenter observes and directs execution of each test t rial, and would typically be in the \\nSV as the test is executed. The experimenter would also be knowledgeable of the operation of \\nthe ADS  feature under test to determine if it is functioning properly. The experimenter records \\ntest conditions and test trial notes, and judges apparent test trial validity. The experimenter might also operate the data acquisition system and other test equipment.  \\nThe PS operator would be responsible for positioning and controlling the pedestrian surrogate. The PS operator would b e knowledgeable  of its construction and mobility, and be able to \\nposition and operate the surrogate for the prescribed trials.  \\nThe other observers may be responsible for operating external data collection equipment (e.g., video recording of test execution, etc.).  \\nTest Data and Equipment  \\nRelevant data listed below should be collected to support the metrics identified for each test scenario/trial. Options for equipment to collect the individual data elements are also provided:  \\n• Vehicle Positions (SV): GPS/INS  (< X cm root mean square error , 95% confidence \\ninterval)  \\n• Pedestrian Surrogate Position: GPS/INS  (< X cm root mean square error , 95% \\nconfidence interval)  \\n• Vehicle Speeds (SV): GPS/ INS, estimated from position information  \\n• Pedestrian Surrogate Speed: GPS/ INS, estimated from position information  \\n• Ranges (between SV and PS): lidar, radar , estimated from position information \\n• Ambient Conditions:  \\no Temperature: thermometer (˚C, ˚F)  \\no Wind Speed: anemometer (mph, kph)  \\no Precipitation: range gauge (in/h, cm/h) \\no Time: clock  \\no Sun position: manual observation  \\n• Test Documentation: c amera  \\n• Experimenter Notes  \\nTest Facility  \\nFor pedestrian competency tests, the test facility is a straight, flat, and level roadway that \\nincludes one or more driving lanes, whose surface is constructed of asphalt or concrete, and whose driving lanes are at least 12  ft wide and delineated by lane markings visible to the vehicle147 operators. The only exceptions to this may be for tests where the roadway is curved instead of \\nstraight. The length of the roadway w ill be sufficient to allow the ADS  feature under test to \\nestablish and maintain a specified lane and speed before encountering the PS, and to allow the SV to stop or exit the course, if applicable. The length of the test course is at least greater than the maximum SV perception range, or 105 m, whichever is greater.  \\nFor some of the tests, crosswalk markings and pedestrian crossing signs will be present. The crosswalk markings will fully traverse the test road perpendicularly to the travel lanes. The signs will be installed outside of the travel lanes, on the shoulder or similar area. Signs and markings will adhere to the Manual on Uniform Traffic Control Devices  (MUTCD.)  \\nSCENARIO TESTS : Ped_Crosswalk_Sign_S_25 – Crosswalk Markings and Signs, \\nStraight, 25 mp h \\nScenario Description  \\nA vehicle equipped with an ADS  feature is driving along a straight urban road with one or more \\nlanes. The vehicle approaches a crosswalk in which a pedestrian is crossing the road.  \\nTest Subject and Purpose  \\nThe subject of this test is  an ADS  feature whose specified ODD includes operation on roadways \\nwhere it may reasonably be expected that pedestrians could enter the roadway. The test determines the ability of the ADS  feature to detect and yield to the pedestrian in the roadway \\n(levera ging markings and signs, if available ). \\nInitial Conditions  \\nThe SV will initially be static in the prescribed positions and orientations.  \\nThe PS will be static in the prescribed positions and orientations.  \\nTest Velocities  \\nThe steady  state velocities of the SV and PS are specified for each trial or set of trials.  \\nMetrics  \\nDisengagements \\nA disengagement is defined as the SV safety driver deactivating the ADS  feature being evaluated \\nand taking manual control of the SV. The location and manner of the disengagement should be included in the experimenter ’s notes.148 Separation Distance  \\nThe separation distances are the distances between the SV and the PS. The minimum separation \\ndistance (closest approach) should be identified, as well as the separation distance being \\nobserved as a continuum. \\nDeceleration Rate \\nThe deceleration rate is the rate of change of speed of the vehicle (presumed that the vehicle slows down in this case).  \\nExecution of Procedure  \\n1. The PS is positioned outside of the te st course travel lanes, adjacent to the marked \\ncrosswalk.  \\n2. The SV is positioned in the center of a lane of the test road at the specified initial \\nheadway.  \\n3. The SV is given a target destination at the end of the test course such that it will remain in the la ne as it traverses the course and reach es the specified speed.  \\n4. The SV ’s navigation system is activated to begin traversing the course.  \\n5. When the SV approaches within X meters of the crosswalk, the PS is set into motion to traverse the crosswalk, such that i t is fully in the crosswalk.  \\n6. Each trial ends when a collision occurs or is avoided by the SV slowing down and/or stopping, or if the SV driver disengages the ADS  feature.  \\n7. After the end of the trial, the SV driver disengages the ADS  feature (if it is not al ready \\ndisengaged).  \\nTrial Validity  \\nAn individual tri al is valid if during the course of the trial:  \\n1. The velocity of the SV did not exceed ±X kph from the specified steady  state velocity \\nbefore the PS came within its perception horizon.  \\n2. The velocity of the PS did not exceed ±X kph from the specified velocity for the duration of the trial.  \\n3. The PS was actively moving through the lanes of travel in the direction of the SV ’s \\ncourse (e.g., the PS was not still approaching the active travel lan es and had not already \\nexited the relevant side of the road) . \\n4. The PS remained inside of the crosswalk bounds for the duration of its traversal.  \\nNOTE: Other trial validity requirements might include GPS coverage requirements.  \\nEvaluation Metrics  \\nA trial is successful if the SV slows down and/or stops to yield to the PS until it has exited the \\nactive travel lanes. If multiple lanes are available, the SV should not attempt a lane change to go \\naround the PS (neither in front of, nor behind) .149 APPENDIX D.  BEHAVIOR COMPETENCY COMPARISO N \\nThis section describes an analysis conducted after the main body of research for this project had \\nbeen completed. This addendum seeks to clarify the concept of ADS Behavioral Competencies, \\ndue to the existence of several embodiments o f this concept found in the literature.  \\nSeveral pieces of research have sought to define and catalogue the behavioral competencies of ADS. In this document, we provide a framework for ADS behavioral c ompetencies in the \\ncontext of developing ADS t est scenarios. Furthermore, this document provides a notional \\ncondensed list of ADS b ehavioral c ompetencies that represents findings from research by the \\nNHTSA t estable c ases and s cenarios for ADS research project, Waymo’s Voluntary Safety Self -\\nAssessment, Californ ia PATH  at the Institute of Transportation Studies at University of \\nCalifornia, Berkeley, and NHTSA p re-crash s cenarios.  \\nIn this work, it was helpful to think of a test case in four dimensions . \\n• Tactical Maneuver Behaviors  \\n• ODD Elements  \\n• OEDR Behaviors  \\n• Failure Mode Behaviors  \\nThis summary uses the three categories for behaviors ( tactical m aneuvers, OEDR, and f ailure \\nmode) as a means of summarizing research findings. It should be noted that each behavioral \\ncompetency can be necessary in multiple ODDs. For example, lane changes may take place on \\nhighways or low speed urban environments. The development of a test scenario will depend both \\non the behavioral competency being tested, as well as the ODD in which that competency is expected to perform.  \\n It should also be noted that the SAE International ORAD Committee has an active task force on \\nbehaviors and maneuvers that is seeking to harmonize the terms and definitions for  behavioral \\ncompetencies. The work of this task force is intended to support the definition of ADS test scenarios, which will benefit from a harmonized approach to cataloguing behavioral competencies, and providing an ontology of OEDR, tactical maneuver, and failure mode behaviors, as well as ODD for each behavior.  \\n The multiple behavioral competencies based on the literature and analysis from this project  were \\ncondensed into a single list. This list may not be complete, but does attempt to incorporate all behavioral competencies from the four major literature sources that were reviewed. The behavioral competencies listed here provide a high -level description, but the development of a \\ntest scenario will require significant additional definition of ODD, narrative and purpose, trajectory information, traffic control devices, and other aspect s descr ibed in the full report.150 Table 66. Summary List of Behavioral Competencies  \\nCategories of Behavioral \\nCompetencies  Specific Behavioral Competencies  \\nTactical Maneuvers   \\nParking  \\n \\n(Note: ODD may include \\nparking garages, surface lots, \\nparallel parking ) • Navigate a parking lot, locate spaces, make appropriate \\nforward and reverse parking maneuvers  \\nLane Maintenance & Car \\nFollowing  \\n \\n(Note: ODD may include high \\nand low speed roads)  • Car following , including stop and go, lead vehicle changing \\nlanes, and responding to emergency braking  \\n• Speed m aintenance, including detecting changes in speed \\nlimits and speed advisories \\n• Lane c entering \\n• Detect and respond to encroaching vehicles  \\n• Enhancing c onspicuity ( e.g., headlights)  \\n• Detect and respond to vehicles  turning at non- signalized \\njunctions  \\nLane Change  \\n \\n(Note: ODD may include high \\nand low speed roads)  • Lane switching, including overtaking or to achieve a minimal \\nrisk condition  \\n• Merge for high and low speed \\n• Detect and respond to encroaching vehicles  \\n• Enhancing c onspicuity ( e.g., blinkers ) \\n• Detect and respond to vehicles turning at non- signalized \\njunctions  \\n• Detect and respond to no passing zones  \\nNavigate Intersection  \\n \\n(Note: ODD may include \\nsignalized and non- signalized \\njunctions)  • Navigate on/off ramps  \\n• Navigate roundabouts  \\n• Navigate signalized intersection  \\n• Detect and respond to traffic control devices  \\n• Navigate crosswalk  \\n• U-Turn  \\n• Car f ollowing  through intersections, including stop and go, \\nlead vehicle changing lanes, and responding to emergency \\nbraking  \\n• Navigate rail crossings  \\n• Detect and respond to vehicle running red light or stop sign  \\n• Vehicl es turning -  same direction  \\n• LTAP/OD at signalized junction and non-signalized junction  \\n• Navigate right turn at signalized and non -signalized junctions  \\nNavigate Temporary or  A-\\nTypical Condition  • Detect and respond to work zone or temporary traffic patterns, \\nincluding construction workers directing traffic151 • Detect and respond to relevant safety officials that are over -\\nriding traffic control devices  \\n• Detect and respond  to citizens directing traffic after an \\nincident   \\n• N-point turn \\nOEDR Capabilities   \\nOEDR:  \\nVehicles  • Detect and respond to encroaching, oncoming vehicles  \\n• Vehicle following \\n• Detect and respond to relevant stopped vehicle, including in \\nlane or on the side of the road  \\n• Detect and respond to lane changes, including unexpected cut -\\nins  \\n• Detect and respond to cut -outs, including unexpected reveals  \\n• Detect and respond to school buses  \\n• Detect and respond to emergency vehicles, including at \\nintersections  \\n• Detect and respo nd to vehicle roadway entry  \\n• Detect and respond to relevant adjacent vehicles  \\n• Detect and respond to relevant vehicles when in forward and \\nreverse  \\nOEDR:  \\nTraffic Control Devices and \\nInfrastructure  • Follow driving laws  \\n• Detect and respond to speed limit changes or advisories  \\n• Detect and respond to relevant access restrictions, including \\none-way streets, no- turn locations, b icycle l anes, t ransit lanes, \\nand pedestrian ways ( See MUTCD for more complete list)) \\n• Detect and respond to relevant traffic control devices, \\nincluding signalized intersections, stop signs, yield signs, \\ncrosswalks, and lane markings (potentially including faded \\nmarkings) ( See MUTCD for more complete list ) \\n• Detect and respond to infrastructur e elements, including \\ncurves, roadway edges, and guard rails ( See AASHTO Green \\nBook for more complete list ) \\nOEDR:  \\nVulnerable Road Users, \\nObjects, Animals  • Detect and respond to relevant static obstacles in lane  \\n• Detect and respond to pedestrians, pedalcyclists, animals in \\nlane or on side of road  \\nFailure Modes   \\nODD Boundary  \\n • Detect and respond to ODD boundary transition, including \\nunanticipated w eather or l ighting c onditions outside of \\nvehicle\\'s capability  \\n \\nDegraded Performance/ \\nHealth Monitoring, Including \\nAchieving Minimal Risk \\nCondition  • Detect degraded performance and respond with appropriate \\nfail-safe/fail -operational mechanisms, including d etect and \\nrespond to c onditions involving vehicle, s ystem, or \\ncomponent -level failures or faults (e.g. , power failure, sensing152 failure, sensing obstruction, computing failure,  fault handling \\nor response)  \\n• Detect and respond to vehicle control loss (e.g., reduced road \\nfriction)  \\n• Detect and respond to vehicle road departure  \\n• Detect and respond to vehicle being involved in incident with \\nanother vehicle, pedestrian, or animal   \\n• Non-collision s afety situations, including vehicle doors ajar, \\nfuel level, engine overheating  \\nFailure Mitigation Strategy  • Detect and respond to catastrophic event, for example \\nflooding or debilitating cyber attack  \\n \\nBased on the four literature sources reviewed, the research team developed a side by side \\ncomparison of the behavioral competencies identified in each. Table 67 is divided into categories \\nthat help compare similar competencies.  \\nTable 67. Comparison of Behavior Competency Analyses \\nCategories of \\nBehavioral \\nCompetencies  NHTSA Testable \\nCases  Waymo Voluntary Safety \\nSelf-Assessment  California PATH \\nBehavior \\nCompetencies  NHTSA Pre -Crash \\nScenarios  \\nTactical \\nManeuvers          \\nParking  • Parking  • Navigate a Parking Lot \\nand Locate Spaces  \\n• Make Appropriate \\nReversing Maneuvers  • Navigate a Parking \\nLot and Locate \\nOpen Spaces  • Vehicle s Parking  \\nLane \\nMaintenance \\n& Car \\nFollowing  • Car Following  \\n• Speed \\nMaintenance  \\n• Lane Centering  \\n• Enhancing \\nConspicuity \\n(headlights)  • Detect and Respond to \\nSpeed Limit Changes and \\nSpeed Advisories \\n• Detect and Respond to \\nEncroaching Oncoming \\nVehicles  \\n• Perform Car Following \\n(Including Stop and Go)  • Perform Car \\nFollowing \\nIncluding Stop & \\nGo and Emergency \\nBraking  \\n• Detect & Respond \\nto Speed Limit \\nChanges (Including \\nAdvisory Speed \\nZones)  • Lead Vehicle Stopped  \\n• Vehicles  Turning at \\nNon-Signalized \\nJunctions  \\n• Lead Vehicle \\nDecelerating  \\n• Vehicles  Changing \\nLanes  \\n• Straight Crossing paths \\nat Non -Signalized \\nJunctions153 Lane Change \\n(e.g., \\novertake, \\nmerge)  • Lane Switching/ \\nOvertaking  \\n• Enhancing \\nConspicuity \\n(e.g., blinkers)  \\n• Merge (high & \\nlow speed)  • Perform High -Speed \\nMerge (e.g., Freeway)  \\n• Perform Low -Speed \\nMerge \\n• Move Out of the Travel \\nLane and Park (e.g., to the \\nShoulder for Minimal \\nRisk)  \\n• Detect and Respond to \\nEncroaching Oncoming \\nVehicles  \\n• Detect Passing and No \\nPassing Zones and \\nPerform Pa ssing \\nManeuvers \\n• Perform Lane Changes  • Detect Passing and \\nNo Passing Zones \\n• Perform High \\nSpeed Freeway \\nMerge \\n• Perform a Lane \\nChange or Lower \\nSpeed Merge \\n• Park on the \\nShoulder or \\nTransition the \\nVehicle to a \\nMinimal Risk State \\n(Not Required for \\nSAE L3) • Vehicle s Turning at \\nNon-Signalized \\nJunctions  \\n• Vehicles  Changing \\nLanes  \\n• Straight Crossing paths \\nat Non -Signalized \\nJunctions  \\nNavigate \\nIntersection:  \\n• Type: \\nSignalized, \\nNon-\\nsignalized, \\nRoundabout, \\nRail Crossing  \\n• Turn: Left/ \\nRight/ \\nStraight • Navigate On/Off \\nRamps  \\n• Roundabouts  \\n• Intersection \\n(left, right, \\nstraight)  \\n• Crosswalk  \\n• U-Turn  • Perform Car Following \\n(Including Stop and Go)  \\n• Navigate Intersections \\nand Perform Turns  \\n• Navigate Roundabouts  \\n• Navigate Railroad \\nCrossings  • Navigate \\nIntersections & \\nPerform Turns  \\n• Detect and Respond \\nto Traffic Control \\nDevices  \\n• Navigate \\nIntersections & \\nPerform Turns  • Running Red Light  \\n• Vehicles  Turning - \\nSame Direction  \\n• LTAP/OD at Signalized \\nJunction  \\n• LTAP/OD at Non -\\nSignalized Junction  \\n• Running Stop Sign  \\n• Vehicle Turning Right \\nat Signalized \\nIntersecti on \\nNavigate \\nTemporary or \\nA-Typical \\nCondition  • Detect and \\nRespond to \\nWorkzone  \\n• N-Point Turn  \\n• Detect and \\nRespond to \\nRelevant Safety \\nOfficials  • Detect and Respond to \\nWork Zones and People \\nDirecting Traffic in \\nUnplanned or Planned \\nEvents  \\n• Follow Police/First \\nResponder Controlling \\nTraffic (Overriding or \\nActing as Traffic Control \\nDevice)  \\n• Follow Construction Zone \\nWorkers Controlling \\nTraffic Patterns \\n(Slow/Stop Sign Holders)  \\n• Respond to Citizens \\nDirecting Traffic After a \\nCrash  \\n• Detect/Respond to \\nDetours and/or Other  • Detect Work Zones, \\nTemporary Lane \\nShifts, or Safety \\nOfficials Manually \\nDirecting Traffic154 Temporary Changes in \\nTraffic Patterns  \\n• Navigate Around \\nUnexpected Road \\nClosures ( e.g., Lane, \\nIntersection, etc.)  \\nOEDR \\nCapabilities   \\n      \\nOEDR:  \\nVehicles  • Detect and \\nRespond to \\nEncroaching, \\nOncoming \\nVehicles  \\n• Vehicle \\nFollowing  \\n• Detect and \\nRespond to \\nRelevant \\nStopped Vehicle  \\n• Detect and \\nRespond to Lane \\nChanges/ Cut -\\nins  \\n• Detect and \\nRespond to Cut -\\nouts/ Reveals  \\n• Detect and \\nRespond to \\nSchool Buses  \\n• Detect and \\nRespond to \\nEmergency \\nVehicles  \\n• Detect and \\nRespond to \\nVehicle \\nRoadway Entry  \\n• Detect and \\nRespond to \\nRelevant \\nAdjacent \\nVehicles  • Detect and Respond to \\nEncroaching Oncoming \\nVehicles  \\n• Detect and Respond to \\nStopped Vehicles  \\n• Detect and Respond to \\nLane Changes \\n• Detect and Respond  to \\nEmergency Vehicles  \\n• Yield for Law \\nEnforcement, EMT, Fire, \\nand Other Emergency \\nVehicles at Intersections, \\nJunctions, and Other \\nTraffic Controlled \\nSituations  \\n• Provide Safe Distance \\nFrom Vehicles, \\nPedestrians, Bicyclists on \\nSide of the Road \\n• Detect and Respo nd to \\nLead Vehicle  \\n• Detect and Respond to a \\nMerging Vehicle  \\n• Detect and Respond to \\nMotorcyclists  \\n• Detect and Respond to \\nSchool Buses  \\n• Detect and Respond to \\nVehicles Parking in the \\nRoadway  • Detect Emergency \\nVehicles  \\n• Detect & Respond \\nto Stopped Vehicles  \\n• Detect & Respond \\nto Intended Lane \\nChanges /Cut-Ins \\n• Detect & Respond \\nto Encroaching \\nOncoming Vehicles  \\n • Running Red Light  \\n• Lead Vehicle Moving at \\nLower Constant Speed  \\n• Backing Up Into \\nAnother Vehicle  \\n• Vehicles s Not Making \\nA Maneuver - Opposite \\nDirection  \\n• Vehicles  Drifting  - \\nSame Direction  \\n• Following Vehicle \\nMaking Maneuver  \\n• Running Stop Sign  \\n• Lead Vehicle \\nAccelerating  \\n• Vehicles  Making a \\nManeuver - Opposite \\nDirection155 OEDR:  \\nTraffic \\nControl \\nDevices & \\nInfrastructure  • Follow Driving \\nLaws  \\n• Detect and \\nRespond to \\nSpeed Limit \\nChanges  \\n• Detect and \\nRespond to \\nRelevant Access \\nRestrictions  \\n• Detect and \\nRespond to \\nRelevant \\nDynamic Traffic \\nSigns  • Detect Traffic Signals and \\nStop/Yield Signs  \\n• Respond to Traffic \\nSignals and Stop/Yield \\nSigns  \\n• Detect and Respond to \\nAccess Restrictions (One-\\nWay, No Turn,  Ramps, \\netc.) \\n• Make Appropriate Right -\\nof-Way Decisions \\n• Follow Local and State \\nDriving Laws \\n• Detect and Respond to \\nTemporary Traffic \\nControl Devices  \\n• Detect/Respond to \\nDetours and/or Other \\nTemporary Changes in \\nTraffic Patterns  \\n• Detect and Respond to \\nFaded or Mi ssing \\nRoadway Markings or \\nSignage  • Detect and Respond \\nto Access \\nRestrictions such as \\nOne-Way Streets, \\nNo-Turn Locations, \\nBicycle Lanes, \\nTransit Lanes, and \\nPedestrian Ways  \\n• Detect and Respond \\nto Traffic Control \\nDevices    \\nOEDR:  \\nVulnerable \\nRoad Users \\n(VRU), \\nObjects, \\nAnimals  • Detect and \\nRespond to \\nRelevant Static \\nObstacles in \\nLane \\n• Detect and \\nRespond to \\nPedestrians, \\nPedalcyclists, \\nAnimals  • Detect and Respond to \\nStatic Obstacles in the \\nPath of the Vehicle  \\n• Yield to Pedestrians and \\nBicyclists at Intersections \\nand Cr osswalks \\n• Provide Safe Distance \\nFrom Vehicles, \\nPedestrians, Bicyclists on \\nSide of the Road \\n• Detect and Respond to \\nPedestrians in Road (Not \\nWalking Through \\nIntersection or Crosswalk)  \\n• Provide Safe Distance \\nfrom Bicyclists Traveling \\non Road (With or Without \\nBike Lane)  \\n• Detect and Respond to \\nAnimals  • Detect & Respond \\nto Static Obstacles \\nin Roadway  \\n• Detect & Respond \\nto Bicycles, \\nPedestrians, \\nAnimals, or Other \\nMoving Objects156 Failure Modes      \\nODD \\nBoundary \\n • Detect and \\nRespond to \\nODD Boundary \\nTransition  • Detect and Respond to \\nUnanticipated Weather or \\nLighting Conditions \\nOutside of Vehicle\\'s \\nCapability ( e.g., \\nrainstorm)  • Detect System \\nEngagement/Diseng\\nagement Conditions \\nIncluding \\nLimitations by \\nLocation, Operating \\nCondition, or \\nComponent \\nMalfunction  •  \\nDegraded \\nPerforma nce/ \\nHealth \\nMonitoring  • Fail-Safe/Fail -\\nOperational \\nMechanisms  • Detect and Respond to \\nNon-Collision Safety \\nSituations (e.g.,  vehicle \\ndoors ajar)  \\n• Detect and Respond to \\nConditions Involving \\nVehicle, System, or \\nComponent -Level \\nFailures or Faults (e.g.,  \\npower failure, sensing \\nfailure, sensing \\nobstruction, computing \\nfailure, fault handling or \\nresponse)  \\n• Detect and Respond to \\nVehicle Control Loss \\n(e.g., reduced road \\nfriction)  \\n• Moving to a Minimum \\nRisk Condition When \\nExiting the Travel Lane is \\nNot Possible  • Park on the \\nShoulder or \\nTransition the \\nVehicle to a \\nMinimal Risk State \\n(Not Required for \\nSAE L3) • Control Loss Without \\nPrior Vehicle Action  \\n• Evasive Action Without \\nPrior Vehicle Maneuver  \\n• Control Loss With  Prior \\nVehicle Action  \\n• Non-Collision Incident  \\n• Evasive Action With \\nPrior Vehicle Maneuver  \\n• Vehicle Failure \\n• Animal Crash Without \\nPrior Vehicle Maneuver  \\n• Road Edge Departure \\nWithout Prior Vehicle \\nManeuver  \\n• Pedestrian Crash \\nWithout Prior Vehicle \\nManeuver  \\n• Road Edge Departure \\nWith Prior Vehicle \\nManeuver  \\n• Pedestrian Cr ash With \\nPrior Vehicle Maneuver  \\n• Pedalcyclist Crash \\nWithout Prior Vehicle \\nManeuver157 REFERENCES  \\nAdaptIVe. (2017). AdaptIVe Automated Driving. Retrieved from The Project -  Objectives: \\nwww.adaptive -ip.eu/index.php/objectives.html  \\nAljaafreh, A., Khalel, M., Al -Fraheed, I., Almarahleh, K., Al -Shwaabkeh, R., Al -Etawi, S., & \\nShaqareen, W. (2011). Vehicular data acquisition system for fleet management \\nautomation. 2011 IEEE International Conference on Vehicular Electronics and Safety , \\n(pp. 130- 133). \\nAudi. (2015). Audi Q7 traffic jam assist . Retrieved from Audi Technology Portal: www.audi -\\ntechnology -portal.de/en/electrics -electronics/driver- assistant -systems/audi -q7-traffic -jam-\\nassist  \\nAustin, T. R. (2016, February). Letter to Dr. Steven E. Shladover. Retrieved from NSPE: \\nwww.nspe.org/sites/default/files/resources/pdfs/Shladover%20Ltr -2016- Feb5 -FINAL.pdf  \\nBarber, M. (2016). A self -driving truck just delivered beer in Colorado . Retrieved from Curbed: \\nwww.curbed.com/2016/10/26/13413992/self -driving- truck -anheuser -busch  \\nBarbera, T., Horst, J., Schlenoff, C., & Aha, D. (2004). Task Analysis of Autonomous On- road \\nDriving. Proceedings of SPIE Mobile Robots 2004 (pp. 61- 72). Bellingham, WA: SPIE. \\nBlanco, M., Atwood, J., Vasquez, H. M., Trimble, T. E., Fitchett, V. L., Radlbeck, J., ... & \\nMorgan, J. F. (2015, August). Human factors evaluation of level 2 and level 3 automated driving concepts  (Report No. DOT HS 812 182). Washington, DC: National Highway  \\nAvailable at www.nhtsa.gov/sites/nhtsa.dot.gov/files/812182_humanfactorseval -l2l3-\\nautomdrivingconcepts.pdf  \\nBojarski, M., Del Testa, D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., . . . Zhao, J. \\n(2016, April). End to End Learning for Self -Driving Cars. Retrieved  from arXiv.org: \\nhttps://arxiv.org/abs/1604.07316 \\nBomey, N., & Zambito, T. (2017, June). Regulators scramble to stay ahead of self -driving cars . \\nRetrieved from USA Today: www.usatoday.com/story/money/cars/2017/06/25/regulators -scramble- stay-ahead -self-\\ndriving-cars/100963150/  \\nBosch. (2017). Connected and Automated Parking. Retrieved from Bosch Mobility Solutions: \\nwww.bosch- mobility -solutions.de/en/highlights/connected -mobility/connected -and-\\nautomated -parking/  \\nBrewer, J., & Najm, W. (2015). Functional Safety Analysis of Automated Vehicle Lane \\nCentering Control Systems. Automated Vehicles Symposium. San Fransisco, CA.  \\nCalifornia Department of Motor Vehicles . (2017, November). Deployment of Autonomous \\nVehicles for Public Operation. Retrieved from State of California Department of Motor \\nVehicles: www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/auto  \\nCalifornia Department of Motor Vehicles. (2016). Autonomous Vehicle Disengagement Reports \\n2016. Retrieved from dmv.ca.gov: www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/disengagement_report_2016158 Caliper. (2017). TransModeler Traffic Simulation Software . Retrieved from Caliper: \\nwww.caliper.com/transmodeler/Simulation.htm  \\nChristensen, A., Cunningham, A., Engelman, J., Green, C., Kawashima, C., Kiger, S., . . . \\nBarickman, F. (2015). Key Considerations in the Development of Driving Automation \\nSystems. Enhanced Safety Vehicles Conference.  Gothenberg, Sweden. \\nCityMobil2. (2013, December). CityMobil2 Newsletter.  Retrieved from Cit yMobil2: \\nwww.citymobil2.eu/en/upload/public -docs/Citymobil2%20Newsletter%20No2.pdf  \\nCityMobil2. (2017). Cities Demonstrating Automated Road Passenger Transport . Retrieved \\nfrom CityMobil2: www.citymobil2.eu/en/  \\nDARPA. (2008). Urban Challenge . Retrieved from DARPA: \\nhttp://archive.darpa.mil/grandchallenge/  \\nEasyMile. (2017). Shared Driveless Vehicles. Retrieved from EasyMile: http://easymile.com/ \\nEllichipuram, U. (2016, October). HERE and Iowa DOT to develop automated vehicle \\ntechnologies on I -380 corridor . Retr ieved from Road Traffic Technology: \\nwww.roadtraffic -technology.com/uncategorised/newshere -and-iowa -dot-to-develop -\\nautomated -vehicle -technologies -on-i-380-corridor -5029332/  \\nElpern -Waxman, J. (2016, December). How Fast Should Autonomous Vehicles Be Allowed to \\nDrive?  Retrieved from Medium: https://medium.com/jordan- writes -about -cities/how -\\nfast-should -autonomous -vehicles -be-allowed -to-drive -1ee710063975 \\nErdman, J. (2015, March). Fog: Deadlier Driving Danger Than You Think . Retrieved from \\nWeather.com: https://w eather.com/news/news/fog -driving -travel -danger -20121127 \\nFederal H ighway A dministration . (2008). Managed Lanes: A Primer. Washington, DC: Author. \\nAvailable at \\nhttps://ops.fhwa.dot.gov/publications/managelanes_primer/managed_lanes_primer.pdf  \\nFHWA. (2012). Ma nual on Uniform Traffic Control Devices (MUTCD). Washington, DC: \\nAuthor. \\nFHWA. (2017, February). Low Visibility -  FHWA Road Weather Management . Retrieved from \\nFHWA: https://ops.fhwa.dot.gov/weather/weather_events/low_visibility.htm  \\nFHWA. (2017a). FHWA Road  Weather Management Best Practices.  Retrieved from FHWA: \\nhttps://ops.fhwa.dot.gov/weather/best_practices/1024x768/transform_param2.asp?xslname=pub.xsl&xmlname=publications.xml&keyname=453  \\nFHWA. (2017b, February). How Do Weather Events Impact Roads? -  FHWA Road Weather \\nManagement . Retrieved from FHWA: \\nhttps://ops.fhwa.dot.gov/weather/q1_roadimpact.htm  \\nFord Motor Company. (2015, December). New Ford Autonomous Tech Turns Traffic Jams into \\nChill Time and Parks Your Car by Remote Control . Retrieved from Ford: \\nhttps://media.ford.com/content/fordmedia/feu/en/news/2015/12/02/new -ford-\\nautonomous -tech-turns -traffic -jams -into-chill-time-and-.html159 General Motors. (2016, December). GM Corporate Newsroom . Retrieved from General Motors: \\nhttp://media.gm.com/media/us/en/gm/h ome.detail.html/content/Pages/news/us/en/2016/d\\nec/1215- autonomous.html  \\nGibbons, J. (1999). Pavements and Surface Materials  (Technical Paper No. 8). Haddam, CT: \\nUniversity of Connecticut Cooperative Extension. \\nGoreham, J. (2017). Tesla Autopilot Update Fore shadows Slower American Roads -  No \\nSpeeding with Autonomous Vehicles . Retrieved from BestRide.com: \\nhttp://bestride.com/news/safety -and-recalls/tesla- autopilot -update -foreshadows -slower -\\namerican -roads -no-speeding- with-autonomous -vehicles  \\nGuardian. (2015, Ma y). Self-driving Cars . Retrieved from The Guardian: \\nwww.theguardian.com/technology/2015/may/15/google -testing -purpose -built-self-\\ndriving -cars- public -roads  \\nHayhurst, K. J., Maddalon, J. M., Miner, P. S., DeWalt, M. P., & McCormick, G. F. (2006). \\nUnmanned ai rcraft hazards and their implications for regulation. IEEE/AIAA Digital \\nAvionics Systems Conference (pp. 2 -12). Portland, OR: IEEE. \\nHowe, G., Xu, G., Hoover, R., Elsasser, D., & Barickman, F. (2016, July). Commercial \\nconnectedvehicle test procedure develop ment and test results – Forward collision \\nwarning (Report No. DOT HS 812 298). Washington, DC: National Highway Traffic \\nSafety Administration.  Available at \\nwww.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/812298_connectedvehiclev2vreport.pdf \\nHuang, A. (2010). Lane Estimation for Autonomous Vehicles using Vision adn LIDAR. \\nCambridge, MA: Massachusetts Institute of Technology. \\nHungar, H. (2017, June). Test Specifications for Highly Automated Driving Functions: Highway \\nPilot.  Retrieved from PEGAS US Project: www.pegasusprojekt.de/en/lectures -\\npublications  \\nInside EVs.  (2015). Retrieved from Nissan to Offer \"Piloted Drive 1.0 in Japan by teh End of \\n2016: https://insideevs.com/nissan- to-offer -piloted -drive -1-0-in-japan -by-the-end-of-\\n2016/  \\nInsurance Ins titute for Highway Safety . (2016, March). Automakers agree to standard AEB by \\n2022. Retrieved from IIHS HLDI: www.iihs.org/iihs/news/desktopnews/u- s-dot-and-iihs-\\nannounce -historic -commitment -of-20-automakers -to-make -automatic -emergency -\\nbraking- standard -on-new-vehicles  \\nJaynes, N. (2016, August). Timeline: The future of driverless cars, from Audi to Volvo. Retrieved \\nfrom Mashable: http://mashable.com/2016/08/26/autonomous -car-timeline -and-tech/  \\nKallweit, R., Prescher, P., & Butenuth, M. (2017). Vehicle -in-the-Loop: Augmenting Real -\\nWorld Driving Tests with Virtual Scenarios in Order to Enhance Validation of Active Safety Systems. International Technical Conference on the Enhanced Safety of Vehicle s \\n(ESV).  Detroit, MI.160 Kalra, N., & Paddock, S. M.. (2016). Driving to Safety: How Many Miles of Driving Would It \\nTake To Demonstrate Autonomous Vehicle Reliability. Santa Monica, CA: RAND \\nCorporation. Available at www.rand.org/content/dam/rand/pubs/researc h_reports/RR1400/RR1478/RAND_RR147\\n8.pdf  \\nKoopman, P., & Wagner, M. (2016). Challenges in Autonomous Vehicle Testing and Validation. \\nSAE International Journal of Transportation Safety , (pp. 15 -24). \\nKrok, A. (2017, February). Roadshow . Retrieved from CNET: \\nwww .cnet.com/roadshow/news/tesla- is-now-testing -autonomous -vehicles- on-public -\\ncalifornia -roads/  \\nKyrouz, M. (2017). Medium . Retrieved from https://medium.com/smart- cars- a-podcast -about -\\nautonomous -vehicles/industry -comments -to-nhtsas -Federal -automated -vehicles- policy -\\n436e7e24911a  \\nLocal Motors. (2017). Meet Olli . Retrieved from Local Motors: https://localmotors.com/meet-\\nolli/ \\nLomas, N. (2017, March). Retrieved from Tech Crunch: \\nhttps://techcrunch.com/2017/03/27/ubers -autonomous -cars- return -to-the-road- in-san-\\nfrancisco -today/  \\nMarshall, A. (2017, February). Why Self -Driving Cars *Can\\'t Even* With Construction Zones . \\nRetrieved from Wired: www.wired.com/2017/02/self -driving- cars-cant-even -\\nconstruction -zones/  \\nMichel, P., Karbowski, D., & Rousseau, A. (2016). Impact of  Connectivity and Automation on \\nVehicle Energy Use.  Warrendale, PA: SAE International.  \\nNajm, W. G., Smith, J. D., &  Yanagisawa, M.. (2007). Pre -crash scenario typology for crash \\navoidance research  (Report No. DOT HS 810 767).  Washington, DC: Author. Availa ble \\nat www.nhtsa.gov/sites/nhtsa.dot.gov/files/pre -crash_scenario_typology-\\nfinal_pdf_version_5- 2-07.pdf  \\nNational Center for Statistics and Analysis. (2017, October). 2016 fatal motor vehicle crashes: \\nOverview . (Traffic Safety Facts Research Note. Report No . DOT HS 812 456). \\nWashington, DC: National Highway Traffic Safety Administration.   Available at \\nhttps://crashstats.nhtsa.dot.gov/Api/Public/Publication/812456 \\nNational Conference of State Legislatures. (2017, September). Autonomous Vehicles -  Self-\\nDriving  Vehicles Enacted Legislation . Retrieved from NCSL: \\nwww.ncsl.org/research/transportation/autonomous -vehicles -self-driving -vehicles-\\nenacted -legislation.aspx  \\nNavya . (2017). Navya Arma : 100% autonomous and electric . Retrieved from Navya . \\nNational H ighway T raffic Safety A dministraion . (2016a , September ). Federal automated \\nvehicles policy : Accelerating the next revolution in roadway safety. Washington, DC: \\nAuthor. Available at www.transportation.gov/sites/dot.gov/files/docs/AV%20policy%20guidance%20PDF.pdf161 NHTSA. ( 2016b). Budget Estimates - Fiscal Year 2017. Washington, DC: Author. Available at \\nwww.transportation.gov/sites/dot.gov/files/docs/NHTSA -FY-2017- CJ.pdf  \\nNHTSA. ( 2016c ). Automated Vehicle Research for Enhanced Safety - Final Report. NHTSA.  \\nWashington,  DC: Author.  \\nNHTSA. (2017a ). Automated Drivings Systems 2.0 -  A Vision for Safety.  Washington, DC: \\nAuthor. \\nNHTSA. (2017b). Traffic Safety Facts 2015: A compilation of motor vehicle crash data from the \\nFatality Analysis Reporting System and the General Esti mates System  (Report No. DOT \\nHS 812 384) . Washington, DC: Author. Available at \\nhttps://crashstats.nhtsa.dot.gov/Api/Public/Publication/812384 \\nNational Research Council. (2005). Autonomous Vehicles in Support of Naval Operations. \\nWashington, DC: The Nationa l Academies Press. doi:https://doi.org/10.17226/11379 \\nNishimoto, A. (2016). Volkswagen I.D. Concept Previews Autonomous Features Slated for 2025. \\nRetrieved from Motortrend: www.motortrend.com/news/volkswagen- i-d-concept -\\npreviews -autonomous -features -slated -for-2025/  \\nNissan. (2017). Concept of Nissan\\'s Autonomous Drive . Retrieved from Nissan Global: \\nwww.nissan -global.com/EN/TECHNOLOGY/OVERVIEW/autonomous_drive.html  \\nNowakowski, C., Shladover, S., Chan, C.- Y., & Tan, H.- S. (2015). Development of California \\nRegulations to Govern Testing and Operation of Automated Driving Systems. Journal of \\nthe Transportation Research Board, 137- 144. \\nSAE International. (2015). Guideline s for Safe On- Road Testing of SAE Level 3, 4, and 5 \\nPrototype Automated Driving Systems (ADS). Warrendale, PA: Author.  \\nSAE International. (2016). J3016: Taxonomy and Definitions for Terms Related to Driving \\nAutomation Systems for On- Road Motor Vehicles. Warrendale, PA: Author. \\nSage, A. (2016, March). Where\\'s the lane? Self -driving cars confused by shabby U.S. roadways . \\nRetrieved from Reuters: www.reuters.com/article/us -autos -autonomous -infrastructure -\\ninsig/wheres -the-lane-self-driving- cars- confused- by-shabby- u-s-roadways -\\nidUSKCN0WX131  \\nSalaani, M., Mikesell, D., Boday, C., & Elsasser, D. (2016). Heavy Vehicle Hardware -in-the-\\nLoop Automatic Emergency Braking Simulation with Experimental Validation. SAE International Journal of Commercial Vehicles , 57-62. \\nStoklosa, A. (2016, January). Bosch Shows Off Haptic Touchscreen, Autonomous Vehicles, More \\nat CES . Retrieved from Car and Driver: http://blog.caranddriver.com/bosch- shows -off-\\nhaptic -touchscreen -autonomous -features- more -at-ces/ \\nTesla. (2017). Accelerating the world to sustainable energy . Retrieved from Tesla: \\nwww.tesla.com/presskit/autopilot  \\nUnderwood, S. (2016, January 8). On Road Automated Vehicle (ORAV) Committee  \\n(PowerPoint presentation) Warrendale, PA: SAE International. Available at https://pdfs.seman ticscholar.org/presentation/0245/4487c3fb7121170f492b11b5fc9e09e1\\n98d8.pdf162 University of California PATH Program. (2016, February). Peer Reveiw of Behavioral \\nCompetencies for AVs.  Retrieved from NSPE: \\nwww.nspe.org/sites/default/files/resources/pdfs/Peer -Review-Report -IntgratedV2.pdf  \\nU.S. Department of Transportation. (2017, January 19). U.S. Department of Transportation \\nDesignates 10 Automated Vehicle Proving Grounds to Encourage Testing of New \\nTechnologies . Retrieved from Transportation.gov: www.transportat ion.gov/briefing-\\nroom/dot1717 \\nVolvo. (2017). IntelliSafe Autopilot. Retrieved from Volvo Cars: \\nwww.volvocars.com/us/about/our -innovations/intellisafe/intellisafe -autopilot  \\nWang, Y., & Hussein, I. (2012). Search and classification using multiple autonomous vehicles: \\ndecision- making and sensor management . London: Springer -Verlag .  \\nWaymo. (2017a ). A new way forward for mobility  (Web page) . Retrieved from Alphabet, Inc. \\n[parent corporation of Google] at  www.google.com/selfdrivingcar/  \\nWaymo. (2017b). Waymo Safety Report -  On the Road to Fully Self -Driving. Retrieved from \\nWaymo: https://waymo.com/safetyreport/  \\nWinner, H., Wachenfeld, W., & Junietz, P. (2016). Safety Assurance for Highly Automated \\nDriving -  The PEGASUS Approach. Automated Vehicles Symposium 2016. San \\nFrancisco, CA.DOT HS 812 623 \\nSeptember  2018  \\n \\n \\n13882 -092618 -v1a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Character"
      ],
      "metadata": {
        "id": "i-rkXdfSBo6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "h_eyJM28B0PZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")"
      ],
      "metadata": {
        "id": "St_KofttBYvO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "qqBIgoqSCBcV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBIzqctxCH-C",
        "outputId": "9803d311-230a-48eb-f867-31bd0b8dc2bb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "797"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "QgK3U5cLEgNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "M3JDBoNoEesp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-large\",\n",
        "    openai_api_key = OPENAI_API_KEY\n",
        "    )"
      ],
      "metadata": {
        "id": "so8qb6FxEppU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Store"
      ],
      "metadata": {
        "id": "H9oXCEUWE_wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "8I_WXpG4E3nc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_texts(texts, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRPRdw-mFEHp",
        "outputId": "ebb7774a-8eec-4909-dfc5-e134f85b9595"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_openai.embeddings.base:Warning: model not found. Using cl100k_base encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRLGDWnYFH3U",
        "outputId": "4edd7ec8-f93b-46ea-a2c0-35923d1fe06c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.faiss.FAISS at 0x7f6d78d1f190>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM"
      ],
      "metadata": {
        "id": "Ndsel8khFvPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "Rdn8awzpFfWG"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,\n",
        "                  temperature = 0.7)"
      ],
      "metadata": {
        "id": "CuEZLlYgF0Rb"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm=llm, chain_type=\"map_reduce\")"
      ],
      "metadata": {
        "id": "-mhSrHHxF-o8"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What stages involved in ADS feature identification?\"\n",
        "docs = db.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "75Y0x-IJGHDM",
        "outputId": "b81fc613-352d-414d-9f97-8269bea0d877"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_openai.embeddings.base:Warning: model not found. Using cl100k_base encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The stages involved in ADS feature identification are as follows:\\n\\n1) Review the literature, including popular media, press releases, technical journals, and conference proceedings, to identify concept ADS features proposed by major OEMs, technology companies, suppliers, and cities.\\n\\n2) Define a framework for describing ADS features, including a functional architecture.\\n\\n3) Define features and behaviors.\\n\\n4) Categorize the features.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}